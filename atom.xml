<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Xin Wang&#39;s Blog</title>
  <icon>https://www.gravatar.com/avatar/6b4384ed67fe8c02cbba591f86f804ef</icon>
  <subtitle>仅此一生，竭尽全力</subtitle>
  <link href="/blog/atom.xml" rel="self"/>
  
  <link href="http://tracyxinwang.site/blog/"/>
  <updated>2020-04-19T06:37:26.466Z</updated>
  <id>http://tracyxinwang.site/blog/</id>
  
  <author>
    <name>Tracy Xin Wang</name>
    <email>wangxin@link.cuhk.edu.hk</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>数字图像处理与分析 基础</title>
    <link href="http://tracyxinwang.site/blog/2020/04/15/digital_image_lds/"/>
    <id>http://tracyxinwang.site/blog/2020/04/15/digital_image_lds/</id>
    <published>2020-04-15T11:57:23.000Z</published>
    <updated>2020-04-19T06:37:26.466Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><p>图像的表示：</p><ul><li>二维离散函数：$I=f(x, y)$<ul><li>$x, y$ 表示图像像素的坐标</li><li>函数值$f$表示在坐标$(x,y)$处像素的亮度值</li></ul></li><li>二维矩阵：$A[m, n]$<ul><li>$m, n$ 表示图象的宽和高</li><li>矩阵元素$a(i,j)$表示图像在第 $i$ 行，第 $j$ 列的像素值</li></ul></li></ul><p>图像质量：</p><ul><li>对比度：反应图像中灰度方差的大小<ul><li>对比度 = 最大灰度值/最小灰度值</li></ul></li><li>传统客观评价方法:<ul><li>通过计算恢复图像偏离原始图像的误差来衡量恢复图像的质量</li><li>均方误差(MSE): $MSE = \frac1{NM} \sum^N_{i=1}\sum^M_{j=1} (f_{ij}-f’_{ij})^2$</li><li>峰值信噪比(PSNR): $PSNR = 10log_{10} \frac{L^2}{MSE}$</li><li>其中N、M分别是x方向、y方向图像像素点的个数， $f_{ij}$和$f’_{ij}$分别是原始图像和测试图像在$(i,j)$点上的取值， $L$是图像中灰度取值的范围，对8比特的灰度图像而言，$L=255$</li></ul></li></ul><p>图像的颜色:</p><ul><li>常用的颜色模型<ul><li>RGB（红、绿、蓝）</li><li>CMYK（青、品红、黄、黑） (Cyan, Magenta, Yellow, Black)<ul><li>用于印刷、绘画等</li></ul></li><li>HSI（色调、色饱和度、亮度） (Hue, Saturation, Intensity)<ul><li>用于调整颜色分量</li><li>H、S、I 可以分开处理而且相互独立</li></ul></li></ul></li><li>颜色模型之间的转换<ul><li>RGB to CMY:<ul><li>$C=1-R; Y=1-G; M=1-B$</li></ul></li><li>HSI to RGB:<ul><li>$0\le H\le 120^\circ$</li><li>$B=I(1-S)$</li><li>$R = I[1+\frac{S\cdot cosH}{cos(60^\circ -H)}]$</li><li>$G=3I-(R+B)$</li></ul></li><li>RGB to HSI:<ul><li>$\theta = cos^{-1}{\frac{[(R-G)+(R-B)]/2}{\sqrt{(R-G)^2+(R-B)(G-B)}}}$</li><li>$H = \left\lbrace \begin{matrix} \theta &amp; B \le G \\ 360-\theta &amp; B&gt;G \end{matrix} \right.$</li><li>$S=1-\frac{3\cdot min(R,G,B)}{R+G+B}$</li><li>$I=(R+G+B)/3$</li></ul></li></ul></li><li>颜色模型的应用 — 利用 HIS 模型特性消除红眼<ul><li>“红眼”—闪光灯照相的结果</li><li>在HIS空间可定义红眼为<ul><li>$-\pi/4&lt;$色度$&lt;\pi/4$ </li><li>色饱和度&gt;0.3</li></ul></li><li>算法：<ul><li>在脸部的特定区域进行色空间转换RGB→HSI测试每一点像素</li><li>如果：$-\pi/4&lt;H&lt;\pi/4$ and $S&gt;0.3$ 则该像素为红眼像素，使其成为灰色：S=0</li></ul></li></ul></li><li>灰度至RGB的转换 (伪彩色显示)：<ul><li>$R = a |sin(bx)|$<br>$G = a |sin(bx+c)|$<br>$B = a |sin(bx+2c)|$<br>where x = gray level intensity, $a = 255, b=2*\pi/255, c = \pi/5$</li></ul></li></ul><h2 id="基本运算"><a href="#基本运算" class="headerlink" title="基本运算"></a>基本运算</h2><h3 id="像素级运算"><a href="#像素级运算" class="headerlink" title="像素级运算"></a>像素级运算</h3><p><strong>点运算</strong></p><ul><li>线性点运算：<ul><li>$D_{out} = f(D_{in}) = aD_{in} + b$</li><li>$I_{out}(x,y) =a*I_{in}(x,y) + b$<ul><li>a=1,b=0: 恒等</li><li>a&lt;0: 黑白反转</li><li>|a|&gt;1: 增加对比度</li><li>|a|&lt;1: 减小对比度</li><li>b&gt;0: 增加亮度</li><li>b&lt;0: 减小亮度</li></ul></li></ul></li><li>非线性点运算<ul><li>$f(I(x,y)) = I(x,y) + C\times I(x,y)\times (I(x,y)_m - I(x,y))$<ul><li>C&gt;0: 增强中间部分亮度</li><li>C&lt;0: 减小中间部分亮度</li><li>what is $I(x,y)_m$?</li></ul></li></ul></li><li>映射表点运算</li><li>点运算特点<ul><li>点运算针对图像中的每一个像素灰度，独立地进行灰度值的改变</li><li>输出图像中每个像素点的灰度值，仅取决于相应输入像素点的值</li><li>点运算不改变图像内的空间关系</li><li>从像素到像素的操作</li><li>点运算可完全由灰度变换函数或灰度映射表确定</li></ul></li></ul><p><strong>代数运算</strong></p><ul><li>加法运算：<ul><li>$C(x,y) = A(x,y)+B(x,y)$</li><li>应用：去除叠加性噪音，生成图像叠加效果</li><li>去除叠加性噪音：对 M 幅加性噪声图像进行平均，可以使图像的平方信噪比提高 M 倍。（噪声互不相关，且均值为0，多个噪声图像相加后可以降低噪声的影响）</li><li>图像叠加：$g(x,y) = \alpha f(x,y) + \beta h(x,y)$, 其中 $\alpha+\beta=1$</li></ul></li><li>减法运算：<ul><li>$C(x,y) = A(x,y)-B(x,y)$</li><li>应用：去除不需要的叠加性图案（背景图像），检测同一场景两幅图像之间的变化</li></ul></li><li>乘法运算：<ul><li>$C(x,y) = A(x,y)\times B(x,y)$</li><li>应用：图像的局部显示：用二值蒙版图像与原图像做乘法</li></ul></li></ul><p><strong>逻辑运算</strong></p><ul><li>求反<ul><li>$g(x,y) = R-f(x,y)$, $R$ 为$f(x,y)$ 的灰度级</li><li>应用：获得一个图像的负像，获得一个子图像的补图像</li></ul></li><li>异或<ul><li>$g(x,y) = f(x,y) \oplus h(x,y)$</li><li>应用：获得相交子图像</li></ul></li><li>或</li><li>与</li></ul><h3 id="空域变换"><a href="#空域变换" class="headerlink" title="空域变换"></a>空域变换</h3><p>在图像空间，对图像的形状、像素值等进行变化、映射等处理。<br><strong>几何变换</strong></p><ul><li>改变图像的形状，大小，位置</li><li>二维图像几何变换的定义：<ul><li>对于原始图像f(x,y)，坐标变换函数 $x’ = a(x,y); y’ = b(x,y)$</li><li>唯一确定了几何变换：$g(x’,y’) = f(a(x,y), b(x,y))$, $g(x,y)$是目标图像</li></ul></li><li>二维基本变换：多项式变换，透视变换</li><li>多项式变换：<ul><li>基本公式：$x’=\sum_{i=0}^M\sum_{j=0}^N a_{ij}x_iy_j, y’=\sum_{i=0}^M\sum_{j=0}^N b_{ij}x_iy_j $</li><li>线性变换 - 多项式变换中的一阶变换：$x’=ax+by+e, y’=cx+dy+f$</li><li>原始图像与目标图像之间的坐标变换函数为线性函数，可以通过与之对应的线性矩阵变换来实现</li><li>齐次坐标表示法：用n+1维向量表示n维向量</li><li>仿射变换</li></ul></li><li>二维图像的基本几何变换具有特征：<ul><li>变换前图形上的每一点，在变换后的图形上都有一确定的对应点，如原来直线上的中点变换为新直线的中点</li><li>平行直线变换后仍保持平行，相交直线变换后仍相交</li><li>变换前直线上的线段比等于变换后对应的线段比</li></ul></li><li>常见几何变换：<ul><li>错切变换：<ul><li>景物在平面上的非垂直投影效果。</li><li>$x$方向错切：$x’=x+d_xy， y’=y$</li><li>$y$方向错切：$x’=x， y’= y+d_yx$</li></ul></li><li>伪仿射变换 — 双线性几何变换<ul><li>$x’=ax+by+gxy+e, y’=cx+dy+hxy+f$</li><li>特点：与xy平面上坐标轴平行的直线，变换为x’y’平面上的直线</li><li>与xy平面上坐标轴不平行的直线，变换为x’y’平面上的曲线</li></ul></li><li>非线性几何变换:<ul><li>在二维平面上， 实现图像几何形状的任意变换, 校正图像的几何失真</li><li>一般的，原始图像与目标图像之间，存在一一对应的特征点（ tiepoints, GCPs）</li><li>需用高阶多项式进行近似描述, 通过原始图像与目标图像之间多个对应特征点(GCP点)，可以确定多项式中的未知参数</li><li>多项式阶数与GCP数量的关系: $GCPs\ge \frac{(t+1)(t+2)}{2}$</li></ul></li><li>透视变换:<ul><li>将一个平面上的点P(x,y)，以投影中心O为基准，投影成另一个平面上的点P’(x,y)</li><li>二维图像透视变换函数及其齐次坐标表示为: $x’=\frac{ax+by+e}{mx+ly+1}; y’=\frac{cx+dy+f}{mx+ly+1}$ (跟齐次矩阵的第三个矩阵有关，实现透视变换)</li></ul></li></ul></li><li>基本几何变换的特征<ul><li>坐标空间的变化<ul><li>范围发生变化</li><li>大小发生变化</li></ul></li><li>像素值的变化<ul><li>像素值不发生变化——位置改变</li><li>像素值发生变化——旋转、缩放、变形变换        </li></ul></li></ul></li><li>灰度插值<ul><li>图像旋转之后，会出现许多的空洞点，对这些空洞点必须进行填充处理</li><li>最近邻插值法<ul><li>选择最临近点像素灰度值</li><li>特点： 简单快速，灰度保真性好，误差较大，视觉特性较差，有马赛克效应</li></ul></li><li>双线性插值（一阶插值）<ul><li>在x, y两个方向上分别进行一次线性插值，根据距离确定权重</li><li>应用双曲抛物面方程：$f(x,y)=ax+by+cxy+d$</li><li>归一化坐标值：$0&lt;x&lt;1,0&lt;y&lt;1$, 可有$f(x,y)=[f(1,0)-f(0,0)]x+[f(0,1)-f(0,0)]y+[f(1,1)+f(0,0)-f(0,1)-f(1,0)]xy+f(0,0)$</li><li>注意：双线性插值的结果不是线性的，它是两个线性函数的积</li><li>需得到四个未知参数——利用四个已知点</li><li>特点: 计算中较为充分地考虑相邻各点的特征，具有灰度平滑过渡特点; 一般情况下可得到满意结果; 具有低通滤波特性，使图像轮廓模糊; 平滑作用使图像细节退化，尤其在放大时; 不连续性会产生不希望的结果</li></ul></li><li>最佳插值函数:<ul><li>在满足Nyquist条件下，从离散信号$x(nTs)$可恢复连续信号x(t) ：$x(t) = \sum^{+\infty}_{i=-\infty}x(nT_s)sinc(\frac{\pi}{T_s}(t-nT_s))$</li></ul></li><li>高阶插值:<ul><li>如果将以上的sinc函数截断，仅取原点周围有限范围函数（-2，2）</li><li>同时利用三次多项式来近似理论上的最佳插值函数sinc(x)</li><li>由此形成常用的三次卷积插值算法，又称三次内插法，两次立方法(Cubic)。 CC插值法等。</li><li>三次卷积插值算法实现：利用待插值点周围的16个邻点像素值</li><li>三次卷积插值算法特点： 为满足二维Nyquist条件下，最佳重构公式的近似； 只有图像满足特定的条件，三次卷积插值算法才可获得最佳结果； 可使待求点的灰度值更好地模拟实际可能值； 可取得更好的视觉效果； 三次卷积内插突出的优点是高频信息损失少，可将噪声平滑； 4×4时，像元均值和标准差信息损失小； 计算量大为增加</li></ul></li><li>图像处理中内插方法的选择<ul><li>内插方法的选择除了考虑图像的显示要求及计算量，还要考虑内插结果对分析的影响</li><li>当纹理信息为主要信息时，最近邻采样将严重改变原图像的纹理信息</li><li>但灰度信息为主要信息时，双线性内插及三次卷积内插将减少图像异质性，增加图像同质性，其中，双线性内插方法使这种变化更为明显</li></ul></li></ul></li></ul><p><strong>非几何变换</strong><br>非几何变换属于像素值的变换，没有几何位置的改变—灰度变换。 灰度变换的目的是为了改善画质，使图像的显示效果更加清晰。</p><ul><li>基本非几何变换类型<ul><li>Negative：$s=L-1-r$</li><li>Log: $s=clog(1+r)$</li><li>Inverse log: $s=e^{cr}-1$</li><li>Power-law: $s=cr^{\gamma}$</li><li>r: input gray level; s: output gray level</li></ul></li><li>模板运算 (kernel)<ul><li>一个系数矩阵，经常是奇数</li></ul></li><li>灰度变换<ul><li>对于输入图像f(x, y)，灰度变换T将产生一个输出图像g(x, y)， g(x, y)的每一个像素值，均取决于f(x, y)中对应点的像素值</li><li>例子：<ul><li>图像求反</li><li>对比度拉伸</li><li>对比度展宽——突出图像中关心的部分</li><li>灰度窗——只显示指定灰度级范围内的信息</li><li>灰度级切片——只保留感兴趣的部分，其余部分置为0</li><li>图像输入输出的Gamma失真</li></ul></li></ul></li><li>直方图变换<ul><li>直方图是用来表达一幅图像灰度级分布情况的统计表</li><li>横坐标为灰度，纵坐标为某一灰度值的像素个数，或 出现的频率</li></ul></li></ul><h3 id="直方图变换"><a href="#直方图变换" class="headerlink" title="直方图变换"></a>直方图变换</h3><ul><li>基本理论</li><li>直方图均衡</li></ul><hr><p>Reference：<br><a href="https://www.bilibili.com/video/BV1Xb411U79J?t=3&amp;p=4" target="_blank" rel="noopener">https://www.bilibili.com/video/BV1Xb411U79J?t=3&amp;p=4</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;基本概念&quot;&gt;&lt;a href=&quot;#基本概念&quot; class=&quot;headerlink&quot; title=&quot;基本概念&quot;&gt;&lt;/a&gt;基本概念&lt;/h2&gt;&lt;p&gt;图像的表示：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;二维离散函数：$I=f(x, y)$&lt;ul&gt;
&lt;li&gt;$x, y$ 表示图像像素的坐
      
    
    </summary>
    
    
      <category term="CV" scheme="http://tracyxinwang.site/blog/tags/CV/"/>
    
      <category term="笔记" scheme="http://tracyxinwang.site/blog/tags/%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>LPR 贷款基础利率</title>
    <link href="http://tracyxinwang.site/blog/2020/02/05/LPR/"/>
    <id>http://tracyxinwang.site/blog/2020/02/05/LPR/</id>
    <published>2020-02-05T08:57:23.000Z</published>
    <updated>2020-02-05T08:56:17.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="为什么要实行LPR"><a href="#为什么要实行LPR" class="headerlink" title="为什么要实行LPR"></a>为什么要实行LPR</h2><ul><li>LPR (Loan Prime Rate)，全称 <strong>贷款基础利率</strong></li><li>引入LPR 是为了解决利率双轨制的问题，进一步推进利率市场化</li></ul><h3 id="利率双轨制"><a href="#利率双轨制" class="headerlink" title="利率双轨制"></a>利率双轨制</h3><p>指的是有两个利率：</p><ul><li>市场利率：<ul><li>指由资金市场上供求关系决定的利率</li><li>央行向各金融机构(商业银行，政策银行)发放货币，金融机构将一些抵押物抵押给央行，这个过程叫做中期借贷便利(MLF), 俗称麻辣粉。到期后(3/6/12个月)，商业银行将本金和利息再还给央行。这个利息，就是MLF的利率来的，是由央行决定的</li><li>但由于这个决定需要根据市场来调节，所以是一种市场化的调控手段</li></ul></li><li>政策利率：<ul><li>央行自己定的，跟市场无关，想定多少就多少</li><li>主要指 基准利率</li><li>基准利率是 央行规定的存贷款利率</li><li>商业银行贷款给个人、企业时，是在基准利率基础上，再加一个银行自己定的浮点</li></ul></li><li>这种双轨制会导致一个问题，就是货币政策传导不畅<ul><li>当央行想刺激经济时，会加大MLF的数目并减少MLF的利率</li><li>但钱到达商业银行时，由于基准利率没有变化，个人/企业实际贷款的利率依然不变，或者变化较为延迟(商业银行规定的上浮)，达不到货币政策的目标</li><li>另一个办法就是调节基准利率，这样的做法就造成 又用政策来主导市场了，不开放</li></ul></li></ul><h3 id="计算方式"><a href="#计算方式" class="headerlink" title="计算方式"></a>计算方式</h3><p>$$LPR = MLF + 加点 $$</p><ul><li>MLF 是央行决定的</li><li>加点是由商业银行决定的，但不是一家商业银行决定的<ul><li>目前是由18家银行(国有，私有，外资银行等)的报价来决定的</li><li>根据各报价行的报价，剔除最高、最低各1家报价，对其余报价进行算术平均计算后，得出贷款基础利率报价平均利率，每月更新(20号)。</li></ul></li></ul><p>而商业银行借贷给个人、企业的利率，则是在这个LPR上，再加个商业银行自己规定的加点，这个加点是根据个人/企业资产的优劣情况由商业银行自己决定的</p><h2 id="跟房贷的关系"><a href="#跟房贷的关系" class="headerlink" title="跟房贷的关系"></a>跟房贷的关系</h2><p>引入LPR后，房贷利率则为：$LPR + 政策利率 + 商业银行加点$</p><ul><li>目前最新公布的 LPR 5年为 4.8%，一年为4.15%</li><li>政策利率就 比如 首套政策利率为0， 二套政策利率上浮不低于60个点 等等</li></ul><p>以前的房贷利率计算方式：</p><ul><li>$基准利率x(1+浮动)$</li><li>转化为 LPR的话，需保证转化后当前的利率跟2019.12.20的利率一样<ul><li>如，2019.12.20的某人的房贷利率是5.39%, 由于LPR是4.8%，所以他政策利率和银行加点总和为5.39-4.8=0.59%</li><li>则此后，该人的房贷利率为 LPR+0.59%</li></ul></li></ul><p>总的来说，LPR会呈下降的趋势</p><hr><p>Reference：<br><a href="https://www.bilibili.com/video/av82411679?from=search&amp;seid=1074737621911846292" target="_blank" rel="noopener">https://www.bilibili.com/video/av82411679?from=search&amp;seid=1074737621911846292</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;为什么要实行LPR&quot;&gt;&lt;a href=&quot;#为什么要实行LPR&quot; class=&quot;headerlink&quot; title=&quot;为什么要实行LPR&quot;&gt;&lt;/a&gt;为什么要实行LPR&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;LPR (Loan Prime Rate)，全称 &lt;strong&gt;贷款基
      
    
    </summary>
    
    
      <category term="杂文" scheme="http://tracyxinwang.site/blog/tags/%E6%9D%82%E6%96%87/"/>
    
      <category term="经济" scheme="http://tracyxinwang.site/blog/tags/%E7%BB%8F%E6%B5%8E/"/>
    
  </entry>
  
  <entry>
    <title>Coursera Motion Planning for Self-Driving Cars 07</title>
    <link href="http://tracyxinwang.site/blog/2019/08/25/coursera_motion_pl07/"/>
    <id>http://tracyxinwang.site/blog/2019/08/25/coursera_motion_pl07/</id>
    <published>2019-08-25T09:30:23.000Z</published>
    <updated>2019-08-25T10:48:19.743Z</updated>
    
    <content type="html"><![CDATA[<p>From Coursera, State Estimation and Localization for Self-Driving Cars by University of Toronto<br><a href="https://www.coursera.org/learn/motion-planning-self-driving-cars" target="_blank" rel="noopener">https://www.coursera.org/learn/motion-planning-self-driving-cars</a></p><h2 id="Smooth-Local-Planning"><a href="#Smooth-Local-Planning" class="headerlink" title="Smooth Local Planning"></a>Smooth Local Planning</h2><h3 id="Parametric-Curves"><a href="#Parametric-Curves" class="headerlink" title="Parametric Curves"></a>Parametric Curves</h3><p>Boundary Conditions</p><ul><li>Boundary conditions must hold on either endpoint of a path<ul><li>The starting and ending conditions of the path</li></ul></li></ul><p>Kinematic Constraints</p><ul><li>Maximum curvature along path cannot be exceeded</li><li>Ensures that car can drive along path</li></ul><p>Parametric Curves</p><ul><li>Parametric curve r can be described by a set of parameterized equations</li><li>Parameter denotes path traversal,can be arc length or unitless</li><li>Example: Cubic spline formulation for x and y</li></ul><p>Path Optimization</p><ul><li>Want to optimize path according to cost functionalf</li><li>Parametric curves allow for optimizing over parameter space, which simplifies optimization formulation</li></ul><p>Non-Parametric Path</p><ul><li>Reactive planner used non-parametric paths underlying each trajectory<ul><li>Path was represented as a sequence of points rather than parameterized curves</li></ul></li></ul><p><strong>Path Parameterization Examples</strong></p><ul><li>Two common parameterized curves are quintic splines and cubic spirals</li><li>Both allow us to satisfy boundary conditions, and can be optimized parametrically</li><li>Quintic Splines<ul><li>x and y are defined by 5th order splines</li><li>Closed form solution available for (x,y,0,K) boundary conditions<br>$$x(u) = \alpha_5 u^5 + \alpha_4 u^4+ \alpha_3 u^3 + \alpha_2 u^2 + \alpha_1 u + \alpha_0 $$<br>$$y(u) = \beta_5 u^5 + \beta_4 u^4+ \beta_3 u^3 + \beta_2 u^2 + \beta_1 u + \beta_0 \quad u \in [0,1] $$</li><li>Challenging to constrain curvature due to nature of spline’s curvature<ul><li>Due to potential discontinuities in curvature or its derivatives</li></ul></li></ul></li><li>Polynomial Spirals<ul><li>Spirals are defined by their curvature as a function of arc length</li><li>Closed form curvature definition allows for simple curvature constraint checking<ul><li>Curvature is well-behaved between sampled points as well due to polynomial formulation</li></ul></li><li>Spiral position does not have a closed form solution</li><li>Fresnel integrals need to be evaluated numerically<ul><li>This can be done using Simpson’s rule</li></ul></li></ul></li></ul><h3 id="Path-Planning-Optimization"><a href="#Path-Planning-Optimization" class="headerlink" title="Path Planning Optimization"></a>Path Planning Optimization</h3><p>Position Integrals and Simpson’s Rule</p><ul><li>Simpson’s rule has improved accuracy over other methods</li><li>Divides the integrationinterval into n regions, and evaluates the function at each region boundary</li></ul><p>Applying Simpson’s Rule</p><ul><li>Applying Simpson’s rule with n=8</li><li>$\theta(s)$ has a closed form solution</li><li>Substituting our integrand for x(s) and y(s) into Simpson’s rule gives us our approximations $x_s(s)$ and $y_s(s)$</li></ul><p>Boundary Conditions via Simpson’s Rule</p><ul><li>Using our Simpson’s approximations, we can now write out the full boundary conditions in terms of spiral parameters</li><li>Can now generate a spiral that satisfies boundary conditions by optimizing its spiral parameters and its length, sy</li></ul><h3 id="Conformal-Lattice-Planning"><a href="#Conformal-Lattice-Planning" class="headerlink" title="Conformal Lattice Planning"></a>Conformal Lattice Planning</h3><p>Conformal Lattice</p><ul><li>Goal is to plan a feasible collision-free path to goal</li><li>Conformal lattice exploits road structure to speed up planning</li><li>Lattice paths are laterally offset from a goal point along road</li></ul><p>Goal Horizon</p><ul><li>Short lookahead improves computation time,but reduces ability to avoid obstacles</li><li>Goal point is dynamically calculated based on speed and other factors</li><li>Endpoints are sampled laterally offset from goal according to the heading along the road</li></ul><h3 id="Velocity-Profile-Generation"><a href="#Velocity-Profile-Generation" class="headerlink" title="Velocity Profile Generation"></a>Velocity Profile Generation</h3><p>Behavioural Planner Reference Velocity</p><ul><li>Need to compute reference velocity</li><li>Can use the speed limit of the road as a starting point</li><li>Behavioural planner maneuver will also influence reference velocity <ul><li>E.g. a stopping maneuver requires us to stop</li></ul></li></ul><p>Dynamic Obstacles</p><ul><li>Lead dynamic obstacles regulate our speed to prevent collisions</li><li>Time to collision is an important metric to preserve when driving with lead vehicles</li><li>Need to reach the red point at lead vehicle speed to ensure there is no collision</li></ul><p>Curvature and Lateral Acceleration</p><ul><li>Curvature recorded at intermediate points, $K_i$</li><li>Velocity bounded by maximum lateral acceleration from comfort rectangle</li><li>Final velocity selected as minimum of BP reference, lead vehicle speed and curvature speed limit</li></ul><p>Trapezoidal Profile</p><ul><li>Alternative profile is trapezoidal, car decelerates to slower speed before stopping <ul><li>Useful for stop sign scenarios</li></ul></li><li>Deceleration chosen to be well within comfort rectangle to maximize passenger comfort</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;From Coursera, State Estimation and Localization for Self-Driving Cars by University of Toronto&lt;br&gt;&lt;a href=&quot;https://www.coursera.org/lear
      
    
    </summary>
    
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
      <category term="Self-driving" scheme="http://tracyxinwang.site/blog/tags/Self-driving/"/>
    
  </entry>
  
  <entry>
    <title>Coursera Motion Planning for Self-Driving Cars 06</title>
    <link href="http://tracyxinwang.site/blog/2019/08/25/coursera_motion_pl06/"/>
    <id>http://tracyxinwang.site/blog/2019/08/25/coursera_motion_pl06/</id>
    <published>2019-08-25T04:30:23.000Z</published>
    <updated>2019-08-25T11:01:00.547Z</updated>
    
    <content type="html"><![CDATA[<p>From Coursera, State Estimation and Localization for Self-Driving Cars by University of Toronto<br><a href="https://www.coursera.org/learn/motion-planning-self-driving-cars" target="_blank" rel="noopener">https://www.coursera.org/learn/motion-planning-self-driving-cars</a></p><h2 id="Reactive-Planning-in-Static-Environments"><a href="#Reactive-Planning-in-Static-Environments" class="headerlink" title="Reactive Planning in Static Environments"></a>Reactive Planning in Static Environments</h2><h3 id="Trajectory-Propagation"><a href="#Trajectory-Propagation" class="headerlink" title="Trajectory Propagation"></a>Trajectory Propagation</h3><p>Varying Input for Obstacle Avoidance</p><ul><li>To avoid obstacles,we require more complex maneuvers</li><li>We can vary the steering input according to a steering function to navigate complex scenarios</li><li>Main objective of local planning is to compute the control inputs (or trajectory) required to navigate to goal point without collision</li></ul><h3 id="Collision-Checking"><a href="#Collision-Checking" class="headerlink" title="Collision Checking"></a>Collision Checking</h3><p><strong>Collision Checking Challenges</strong></p><ul><li>Computationally intensive</li><li>Requires perfect information to guarantee safety</li><li>Needs to be approximated,and must be robust to noise</li></ul><p><strong>Swath-based checking</strong></p><ul><li>Area occupied by car along path generated by rotating the car’s footprint by each $x, y, \theta$ along the path</li><li>Swath along path is the union of each rotated and translated footprint<br>$$S = \cup_{p\in P} F(x(p), y(p), \theta(p))$$<ul><li>$P$ is a path composed of a set of points $p$</li><li>$F$ denotes a function that returns the set points contained in a footprint rotated by theta, and translated by x and y. </li></ul></li><li>Swath can then be checked for collisions<ul><li>check this entire set to see if there are any obstacles inside it. If there are, the path contains a collision and otherwise it’s collision-free.</li></ul></li><li>Discretized Example<ul><li>Initial state of the vehicle in the occupancy grid, with base link at the origin</li><li>Will need to rotate and translate to get the new footprint at point $(1.0,2.0,\pi/2)$</li><li>To compute the occupancy grid index for each point in the footprint, add half the width/height of the occupancy grid,and divide by the grid resolution $\delta$</li><li>Swath is then the union of these indices<br>$$x_i = \frac{x(p)+\frac X2}{\delta} \qquad y_i = \frac{y(p)+\frac Y2}{\delta} \qquad S = S\cup (x_i,y_i)$$</li></ul></li><li>Lattice Planner Swaths<ul><li>Swath based methods are useful for lattice planners, as the swath sets can be computed offline</li><li>Online collision checking is then simplified using lookup tables</li></ul></li><li>Speed and Robustness<ul><li>Need to improve speed</li><li>Need to be robust to noise</li><li>Use conservative approximations to solve both of these problems</li><li>Want algorithmic speedup without sacrificing path quality</li></ul></li></ul><p><strong>Circle-based collision checking</strong></p><p>Conservative Approximations</p><ul><li>Conservative approximations may report a collision evenif there isn’t one,but will never miss a collision if it were to actually happen</li><li><p>The car can be completely encapsulated by three circles</p></li><li><p>Circle approximation is effective because it is fast to check if an occupancy grid point lies within a circle of radiusr centered at $(x_c,y_c)$</p></li><li>If obstacle in occupancy gridlies within circle, a collision is reported</li><li>Otherwise, due to conservative approximation, no collision is possible</li></ul><p><strong>Pitfalls posed by imperfect information and discretization errors</strong><br>Discretization Resolution</p><ul><li>Collision checking accuracy is impacted by the resolution of our discretization</li><li>Higher fidelity collision checking requires a finer resolution for occupancy grids and path points, and will require more computational resources</li></ul><h3 id="Trajectory-Rollout-Algorithm"><a href="#Trajectory-Rollout-Algorithm" class="headerlink" title="Trajectory Rollout Algorithm"></a>Trajectory Rollout Algorithm</h3><p>Trajectory rollout algorithm steps include:</p><ul><li>Trajectory propagation</li><li>Collision checking</li><li>Path selection</li></ul><p><strong>Trajectory Rollout Planner</strong></p><ul><li>Uses trajectory propagation to generate candidate set of trajectories </li><li>Among collision-free trajectories, select trajectory that makes the most progress to goal</li></ul><p><strong>Trajectory Set Generation</strong></p><ul><li>Each trajectory corresponds to a fixed control input to our model<ul><li>Typically uniformly sampled across range of possible inputs</li></ul></li><li>More sampled trajectories leads to more maneuverability</li><li>Fewer sampled trajectories improves computation time</li></ul><p><strong>Trajectory Propagation</strong></p><ul><li>Holding the velocity constant and varying the steering angle gives candidate set of trajectories</li></ul><p><strong>Objective Function</strong></p><ul><li>Rewarding progress to a goal point is the ultimate goal of motion planning<br>$$J = \alpha_1 |x_n - x_{goal} | + \alpha_2 \sum^n_{i=1} k^2_i + \alpha_3 \sum^n_{i=1} |x_i - P_{center}(x_i) |$$</li><li>where $k_i$ is the curvature, $P_{center}$ is the deviation from centerline</li></ul><p><strong>Receding Horizon Example</strong></p><ul><li>Steering angle bounded by $|\delta| \leq \pi/4$<ul><li>First trajectory corresponds to $\delta = -\pi/4$</li><li>Second trajectory corresponds to $\delta = -\pi/8$</li><li>Positive steering angle trajectories are symmetrical with the negative steering angle trajectories</li></ul></li><li>Time discretization of 0.1s, with a 2s planning horizon<ul><li>Using the vehicle footprint, compute the swath for each trajectory</li></ul></li><li>Only 1s of 2s trajectory is executed at each planning iteration<ul><li>Objective is evaluated across all collision-free trajectories</li><li>Only the most progress one will be chosed to execute</li></ul></li><li>Planning horizon end time recedes towards time point when goal is reached</li><li>This process is continued until goal is reached</li><li>This planner is greedy and sub-optimal, but is fast enough to allow for online planning</li></ul><h3 id="Dynamic-Windowing"><a href="#Dynamic-Windowing" class="headerlink" title="Dynamic Windowing"></a>Dynamic Windowing</h3><p>Bicycle Model + Acceleration Constraints</p><ul><li>Higher order terms handled by adding constraints</li><li>More comfort for passengers，but less maneuverability</li></ul><p>Constraint in Terms of Steering Angle</p><ul><li>Angular acceleration constraint may prevent us from selecting certain maneuvers based on current angular velocity</li><li>Change in steering angle between planning cycles is bounded</li><li>Similar logic applies for changes in linear velocity inputs between planning cycles</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;From Coursera, State Estimation and Localization for Self-Driving Cars by University of Toronto&lt;br&gt;&lt;a href=&quot;https://www.coursera.org/lear
      
    
    </summary>
    
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
      <category term="Self-driving" scheme="http://tracyxinwang.site/blog/tags/Self-driving/"/>
    
  </entry>
  
  <entry>
    <title>Coursera Motion Planning for Self-Driving Cars 05</title>
    <link href="http://tracyxinwang.site/blog/2019/08/24/coursera_motion_pl05/"/>
    <id>http://tracyxinwang.site/blog/2019/08/24/coursera_motion_pl05/</id>
    <published>2019-08-24T04:30:23.000Z</published>
    <updated>2019-08-24T08:23:43.027Z</updated>
    
    <content type="html"><![CDATA[<p>From Coursera, State Estimation and Localization for Self-Driving Cars by University of Toronto<br><a href="https://www.coursera.org/learn/motion-planning-self-driving-cars" target="_blank" rel="noopener">https://www.coursera.org/learn/motion-planning-self-driving-cars</a></p><h2 id="Principles-of-Behaviour-Planning"><a href="#Principles-of-Behaviour-Planning" class="headerlink" title="Principles of Behaviour Planning"></a>Principles of Behaviour Planning</h2><h3 id="Behaviour-Planning"><a href="#Behaviour-Planning" class="headerlink" title="Behaviour Planning"></a>Behaviour Planning</h3><ul><li>A behavior planning system plans the set of high level driving actions, or maneuvers to safely achievethe driving mission under various driving situations</li><li>Behavior planner considers:<ul><li>Rules of the road</li><li>Static objects around the vehicle</li><li>Dynamic objects around the vehicle</li></ul></li><li>Planned path must be safe and efficient</li></ul><p>Driving maneuvers</p><ul><li>Track Speed: maintain current speed of the road</li><li>Follow leader: match the speed of the leading vehicle and maintain a safe distance</li><li>Decelerate to stop: begin decelerating and stop before a given space</li><li>Stop: remain stopped in the current position</li><li>Merge: join or switch onto a new drive lane</li></ul><p>Output of Behavior Planner</p><ul><li>Driving maneuver to be executed</li><li>Set of constraints which must be obeyed by the planned trajectory of the self driving car which include:<ul><li>ldeal path</li><li>Speed limit</li><li>Lane boundaries</li><li>Stop locations</li><li>Set of interest vehicles</li></ul></li></ul><p>Input Requirements</p><ul><li>High definition road map</li><li>Mission path</li><li>Localization information</li><li>Perception Information:<ul><li>All observed dynamic objects<ul><li>Prediction of future movement</li><li>Collision points and time to collision</li></ul></li><li>All observed static objects<ul><li>Road signs</li></ul></li><li>Occupancy grid</li></ul></li></ul><h3 id="Handling-an-Intersection-Scenario-Without-Dynamic-Objects"><a href="#Handling-an-Intersection-Scenario-Without-Dynamic-Objects" class="headerlink" title="Handling an Intersection Scenario Without Dynamic Objects"></a>Handling an Intersection Scenario Without Dynamic Objects</h3><p>Scenario Evaluation</p><ul><li>4 way Intersection</li><li>Two lane</li><li>Stop Sign for every direction</li><li>Be able to travel:<ul><li>Through the intersection</li><li>Left at the intersection</li><li>Right at the intersection</li></ul></li><li>No other dynamic vehicles</li></ul><p>Behavior Planning Testing</p><ul><li>Code based tests</li><li>Simulation tests</li><li>Private track tests</li><li>Limited scoped close supervision road tests</li></ul><h3 id="Handling-an-Intersection-Scenario-with-Dynamic-Objects"><a href="#Handling-an-Intersection-Scenario-with-Dynamic-Objects" class="headerlink" title="Handling an Intersection Scenario with Dynamic Objects"></a>Handling an Intersection Scenario with Dynamic Objects</h3><p>Interaction With Dynamic Objects</p><ul><li>Distance to dynamic object<ul><li>distance to the center of any dynamic object</li></ul></li><li>Distance to collision point<ul><li>distance to the collision point with another dynamic object</li></ul></li><li>Time to collision(TTC)<ul><li>time to collision between any two dynamic objects</li></ul></li></ul><p><strong>State Machine States</strong></p><ul><li>Track Speed<ul><li>Follow the current speed limit</li></ul></li><li>Follow Leader<ul><li>Match the speed of the dynamic object in front</li></ul></li><li>Decelerate to Stop<ul><li>Stop to a particular point</li></ul></li><li>Stop<ul><li>Stay stopped at the current location</li></ul></li></ul><h3 id="Handling-Multiple-Scenarios"><a href="#Handling-Multiple-Scenarios" class="headerlink" title="Handling Multiple Scenarios"></a>Handling Multiple Scenarios</h3><p><strong>Hierarchical state machine includes multiple scenarios</strong></p><p>Single State Machine</p><ul><li>Single state machine method<ul><li>Add transitions</li><li>Add additional transition conditions</li></ul></li><li>Issues with single state machine method:<ul><li>Rule explosion</li><li>Increase in computational time</li><li>Complicated to create and maintain</li></ul></li></ul><p>Hierarchical State Machine-Advantages and Disadvantages<br>-Advantages:</p><pre><code>- Decrease in computational time- Simpler to create and maintain</code></pre><ul><li>Disadvantages:<ul><li>Rule Explosion</li><li>Repetition of many rules in the low level state machines</li></ul></li></ul><h3 id="Advanced-Methods-for-Behaviour-Planning"><a href="#Advanced-Methods-for-Behaviour-Planning" class="headerlink" title="Advanced Methods for Behaviour Planning"></a>Advanced Methods for Behaviour Planning</h3><ul><li>Fuzzy system</li><li>Reinforcement learning<ul><li>Hierarchical Reinforcement Learning</li><li>Model-based Reinforcement Learning</li></ul></li><li>Machine learning<ul><li>Inverse Reinforcement Learning</li><li>End-to-End Approaches    </li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;From Coursera, State Estimation and Localization for Self-Driving Cars by University of Toronto&lt;br&gt;&lt;a href=&quot;https://www.coursera.org/lear
      
    
    </summary>
    
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
      <category term="Self-driving" scheme="http://tracyxinwang.site/blog/tags/Self-driving/"/>
    
  </entry>
  
  <entry>
    <title>Pytorch Example line by line - MNIST</title>
    <link href="http://tracyxinwang.site/blog/2019/08/22/pytorch_mnist/"/>
    <id>http://tracyxinwang.site/blog/2019/08/22/pytorch_mnist/</id>
    <published>2019-08-22T04:30:23.000Z</published>
    <updated>2019-08-22T08:57:13.603Z</updated>
    
    <content type="html"><![CDATA[<p>The code is from the Pytorch example<br><a href="https://github.com/pytorch/examples/blob/master/mnist/main.py" target="_blank" rel="noopener">https://github.com/pytorch/examples/blob/master/mnist/main.py</a></p><p>I just add some annotations for better understanding the whole process.</p><p>First, let’s have a look at the things we need to define before the real training:</p><ul><li>define some default <strong>parameter settings</strong>:<ul><li>batch size</li><li>test batch size</li><li>number of epochs</li><li>learning rate</li><li>cuda setting</li><li>seed setting</li><li>momentum setting</li></ul></li><li>prepare the date<ul><li>into training/testing tensor format, normalize</li><li>into batch </li></ul></li><li>the <strong>network model/achitecture</strong><ul><li>layers defination (e.g. conv, fully connected)</li><li>forward layer connection (e.g. relu, max pooling)</li></ul></li><li>the <strong>setting for training</strong><ul><li>selection of loss function</li><li>do backpropagation</li><li>update the parameters</li><li>show the batch progress</li></ul></li><li>the <strong>setting for testing</strong><ul><li>get the prediction from the model   </li><li>compute the loss </li><li>show the correction/accuracy</li><li>show the progress of testing if you have many testing data</li></ul></li><li>train the model in epoches</li></ul><p>Codes are as follows:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets, transforms</span><br><span class="line"></span><br><span class="line"><span class="comment"># the input size of mnist image is 28x28</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Net, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">1</span>, <span class="number">20</span>, <span class="number">5</span>, <span class="number">1</span>)     <span class="comment"># input channel of mnist is 1, output_channel = 20, kernel size is 5x5, stride=1</span></span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">20</span>, <span class="number">50</span>, <span class="number">5</span>, <span class="number">1</span>)    <span class="comment"># input channel equals the output channel of last layer=20, out_channel in this layer=50, kernel size is 5x5, stride=1</span></span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">4</span>*<span class="number">4</span>*<span class="number">50</span>, <span class="number">500</span>)       <span class="comment"># after maxpooling of the previous layers, the size of the image becomes 4x4 (see the following model structure), convert all these voxels into fully connect neurons</span></span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">500</span>, <span class="number">10</span>)           <span class="comment"># fully connected to 10 classes</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = F.relu(self.conv1(x))</span><br><span class="line">        x = F.max_pool2d(x, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">        x = F.relu(self.conv2(x))</span><br><span class="line">        x = F.max_pool2d(x, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">        x = x.view(<span class="number">-1</span>, <span class="number">4</span>*<span class="number">4</span>*<span class="number">50</span>)      <span class="comment"># convert the size for the later use</span></span><br><span class="line">        x = F.relu(self.fc1(x))</span><br><span class="line">        x = self.fc2(x)</span><br><span class="line">        <span class="keyword">return</span> F.log_softmax(x, dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(args, model, device, train_loader, optimizer, epoch)</span>:</span></span><br><span class="line">    model.train()       <span class="comment"># tell torch that now it is training mode</span></span><br><span class="line">    <span class="keyword">for</span> batch_idx, (data, target) <span class="keyword">in</span> enumerate(train_loader):</span><br><span class="line">        data, target = data.to(device), target.to(device)</span><br><span class="line">        optimizer.zero_grad()       <span class="comment"># initial all gradient at zero for each batch iteration as pytorch will accumulate the gradient defaultly </span></span><br><span class="line">        output = model(data)        <span class="comment"># generate output from the current model</span></span><br><span class="line">        loss = F.nll_loss(output, target)   <span class="comment"># use negative log likelihood as loss function</span></span><br><span class="line">        loss.backward()             <span class="comment"># do backpropagation</span></span><br><span class="line">        optimizer.step()            <span class="comment"># update the parameters</span></span><br><span class="line">        <span class="keyword">if</span> batch_idx % args.log_interval == <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">'Train Epoch: &#123;&#125; [&#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)] \t Loss: &#123;:.6f&#125;'</span>.format(</span><br><span class="line">                epoch, batch_idx*len(data), len(train_loader.dataset), <span class="number">100.</span>*batch_idx/len(train_loader), loss.item()))      <span class="comment"># .item() convert the tensor type to real value</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span><span class="params">(args, model, device, test_loader)</span>:</span></span><br><span class="line">    model.eval()        <span class="comment"># tell torch that now is testing mode</span></span><br><span class="line">    test_loss = <span class="number">0</span></span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    <span class="comment"># no need to do gradient calculation so that can save time</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> data, target <span class="keyword">in</span> test_loader:</span><br><span class="line">            data, target = data.to(device), target.to(device)</span><br><span class="line">            output = model(data)</span><br><span class="line">            test_loss += F.nll_loss(output, target, reduction=<span class="string">'sum'</span>).item()</span><br><span class="line">            pred = output.argmax(dim=<span class="number">1</span>, keepdim=<span class="keyword">True</span>)</span><br><span class="line">            correct += pred.eq(target.view_as(pred)).sum().item()</span><br><span class="line">    </span><br><span class="line">    test_loss /= len(test_loader.dataset)</span><br><span class="line">    print(<span class="string">'\nTest set: Average loss: &#123;:.4f&#125;, Accuracy: &#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)\n'</span>.format(</span><br><span class="line">        test_loss, correct, len(test_loader.dataset),</span><br><span class="line">        <span class="number">100.</span> * correct / len(test_loader.dataset)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">### training settings</span></span><br><span class="line">    <span class="comment"># argparse makes the command line interface</span></span><br><span class="line">    parser = argparse.ArgumentParser(description=<span class="string">'Pytorch MNIST Example'</span>)   <span class="comment"># create the parser</span></span><br><span class="line">    parser.add_argument(<span class="string">'--batch-size'</span>, type=int, default=<span class="number">64</span>, metavar=<span class="string">'N'</span>,</span><br><span class="line">                        help=<span class="string">'input batch size for training (default: 64)'</span>) <span class="comment"># add argument of the conmmand line</span></span><br><span class="line">    parser.add_argument(<span class="string">'--test-batch-size'</span>, type=int, default=<span class="number">1000</span>, metavar=<span class="string">'N'</span>,</span><br><span class="line">                        help=<span class="string">'input batch size for testing (default: 1000)'</span>)</span><br><span class="line">    parser.add_argument(<span class="string">'--epochs'</span>, type=int, default=<span class="number">10</span>, metavar=<span class="string">'N'</span>, </span><br><span class="line">                        help=<span class="string">'number of epochs to train (default: 10)'</span>)</span><br><span class="line">    parser.add_argumnet(<span class="string">'--lr'</span>, type=float, default=<span class="number">0.01</span>, metavar=<span class="string">'LR'</span>, </span><br><span class="line">                        help=<span class="string">'learning rate (default: 0.01)'</span>)</span><br><span class="line">    parser.add_argument(<span class="string">'--momentum'</span>, type=float, default=<span class="number">0.5</span>, metavar=<span class="string">'M'</span>,</span><br><span class="line">                        help=<span class="string">'SGD momentum (default: 0.5)'</span>)</span><br><span class="line">    parser.add_argument(<span class="string">'--no-cuda'</span>, action=<span class="string">'store_true'</span>, default=<span class="keyword">False</span>,</span><br><span class="line">                        help=<span class="string">'disables CUDA training'</span>)</span><br><span class="line">    parser.add_argument(<span class="string">'--seed'</span>, type=int, default=<span class="number">1</span>, metavar=<span class="string">'S'</span>, </span><br><span class="line">                        help=<span class="string">'random seed (default: 1)'</span>)</span><br><span class="line">    parser.add_argument(<span class="string">'--log-interval'</span>, type=int, default=<span class="number">10</span>, metavar=<span class="string">'N'</span>, </span><br><span class="line">                        help=<span class="string">'how many batches to wait before logging training status'</span>)</span><br><span class="line">    parser.add_argument(<span class="string">'--save-model'</span>, action=<span class="string">'store_true'</span>, default=<span class="keyword">False</span>, </span><br><span class="line">                        help=<span class="string">'For saving the current Model'</span>)</span><br><span class="line"></span><br><span class="line">    args = parser.parse_args()  <span class="comment"># call the parser and transmit to args</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># create cuda flag if existing</span></span><br><span class="line">    use_cuda = <span class="keyword">not</span> args.no_cuda <span class="keyword">and</span> torch.cuda.is_available()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># set the seed for reproducible results</span></span><br><span class="line">    torch.manual_seed(args.seed)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># set the device</span></span><br><span class="line">    device = torch.device(<span class="string">"cuda"</span> <span class="keyword">if</span> use_cuda <span class="keyword">else</span> <span class="string">"cpu"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">### load and prepare the training and testing data</span></span><br><span class="line">    <span class="comment"># loader args setting</span></span><br><span class="line">    kwargs = &#123;<span class="string">'num_workers'</span>: <span class="number">1</span>, <span class="string">'pin_memory'</span>: <span class="keyword">True</span>&#125; <span class="keyword">if</span> use_cuda <span class="keyword">else</span> &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># as the tensor defination in pytorch is different from tensorflow, therefore we need to use "ToTensor" to convert first, the format should be C*H*W</span></span><br><span class="line">    <span class="comment"># the value in normalize is the mean of the MNIST data, which is specific here. If using another dataset, we need to calculate this mean by ourselves first  </span></span><br><span class="line">    train_loader = torch.utils.data.Dataloader(</span><br><span class="line">        datasets.MNIST(<span class="string">'../data'</span>, train=<span class="keyword">True</span>, download=<span class="keyword">True</span>, </span><br><span class="line">                        transform=transforms.Compose([</span><br><span class="line">                            transforms.ToTensor(),                transforms.Normalize((<span class="number">0</span>,<span class="number">1307</span>,), (<span class="number">0.3081</span>))</span><br><span class="line">                            ])</span><br><span class="line">                        ),</span><br><span class="line">        batch_size=args.batch_size, shuffle=<span class="keyword">True</span>, **kwargs</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    test_loader = torch.utils.data.Dataloader(</span><br><span class="line">        datasets.MNIST(<span class="string">'../data'</span>, train=<span class="keyword">False</span>,  </span><br><span class="line">                        transform=transforms.Compose([</span><br><span class="line">                            transforms.ToTensor(),                transforms.Normalize((<span class="number">0</span>,<span class="number">1307</span>,), (<span class="number">0.3081</span>))</span><br><span class="line">                            ])</span><br><span class="line">                        ),</span><br><span class="line">        batch_size=args.test_batch_size, shuffle=<span class="keyword">True</span>, **kwargs</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="comment">### initial the model and set the optimizer</span></span><br><span class="line">    model = Net().to(device)</span><br><span class="line">    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)</span><br><span class="line"></span><br><span class="line">    <span class="comment">### train the model and test for several epochs</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">1</span>, args.epochs + <span class="number">1</span>):</span><br><span class="line">         train(args, model, device, train_loader, optimizer, epoch)</span><br><span class="line">         test(args, model, device, test_loader)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (args.save_model):</span><br><span class="line">        torch.save(model.state_dict(), <span class="string">"mnist_cnn.pt"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ = <span class="string">'__main__'</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure><p>That’s it!</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;The code is from the Pytorch example&lt;br&gt;&lt;a href=&quot;https://github.com/pytorch/examples/blob/master/mnist/main.py&quot; target=&quot;_blank&quot; rel=&quot;noop
      
    
    </summary>
    
    
      <category term="Deep learning" scheme="http://tracyxinwang.site/blog/tags/Deep-learning/"/>
    
      <category term="Python" scheme="http://tracyxinwang.site/blog/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Coursera Motion Planning for Self-Driving Cars 03</title>
    <link href="http://tracyxinwang.site/blog/2019/08/21/coursera_motion_pl03/"/>
    <id>http://tracyxinwang.site/blog/2019/08/21/coursera_motion_pl03/</id>
    <published>2019-08-21T04:30:23.000Z</published>
    <updated>2019-08-21T06:56:37.920Z</updated>
    
    <content type="html"><![CDATA[<p>From Coursera, State Estimation and Localization for Self-Driving Cars by University of Toronto<br><a href="https://www.coursera.org/learn/motion-planning-self-driving-cars" target="_blank" rel="noopener">https://www.coursera.org/learn/motion-planning-self-driving-cars</a></p><h2 id="Mission-Planning-in-Driving-Environments"><a href="#Mission-Planning-in-Driving-Environments" class="headerlink" title="Mission Planning in Driving Environments"></a>Mission Planning in Driving Environments</h2><h3 id="Creating-a-Road-Network-Graph"><a href="#Creating-a-Road-Network-Graph" class="headerlink" title="Creating a Road Network Graph"></a>Creating a Road Network Graph</h3><p>Graph:</p><ul><li>The edges is defined by the segments of the road that connect each sample point according to the rules of the road.</li><li>the edges of the graph are directed</li><li>When the graph is unweighted, a good candidate algorithm is the Breadth-First Search or BFS.</li></ul><p>BFS:</p><ul><li>At a high level, BFS can be thought of as iterating through all of the vertices in the graph but doing so in a manner such that all adjacent vertices are evaluated first before proceeding deeper into the graph.</li></ul><h3 id="Dijkstra’s-Shortest-Path-Search"><a href="#Dijkstra’s-Shortest-Path-Search" class="headerlink" title="Dijkstra’s Shortest Path Search"></a>Dijkstra’s Shortest Path Search</h3><p>Dijkstra’s Algorithm </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">Algorithm Dijkstra<span class="string">'s (G,s,t)</span></span><br><span class="line"><span class="string">    open &lt;- MinHeap()</span></span><br><span class="line"><span class="string">    closed &lt;- Set()</span></span><br><span class="line"><span class="string">    predecessors &lt;- Dict()</span></span><br><span class="line"><span class="string">    open.push(s.0)</span></span><br><span class="line"><span class="string">    while !open.isEmpty() do</span></span><br><span class="line"><span class="string">        if isGoal(u) then</span></span><br><span class="line"><span class="string">            return extractPath(u, predecessors)</span></span><br><span class="line"><span class="string">        for all v $\in$ u.successors() </span></span><br><span class="line"><span class="string">            if v $\in$ closed then</span></span><br><span class="line"><span class="string">                continue</span></span><br><span class="line"><span class="string">            uvCost &lt;- edgeCost(G,u,v)</span></span><br><span class="line"><span class="string">            if v $\in$ open then</span></span><br><span class="line"><span class="string">                if uCost + uvCost &lt; open[v] then</span></span><br><span class="line"><span class="string">                    open[v] &lt;- uCost + uvCost</span></span><br><span class="line"><span class="string">                    predecessors[v] &lt;- u</span></span><br><span class="line"><span class="string">            else</span></span><br><span class="line"><span class="string">                open.push(v, uCost + uvCost)</span></span><br><span class="line"><span class="string">                predecessors[v] &lt;- u</span></span><br><span class="line"><span class="string">        closed add(u)</span></span><br></pre></td></tr></table></figure><h3 id="A-Shortest-Path-Search"><a href="#A-Shortest-Path-Search" class="headerlink" title="A* Shortest Path Search"></a>A* Shortest Path Search</h3><p>Heuristic:</p><ul><li>a search heuristic is an estimate of the remaining cost to reach the destination vertex from any given vertex in the graph. </li><li>in this case, a useful estimate on the cost or length between any two vertices is the straight line or Euclidean distance between them</li></ul><p><strong>Euclidean Heuristic</strong></p><ul><li>Exploits structure of the problem</li><li>Fast to calculate</li><li>Straight-line distance between two vertices is a useful estimate of true distance along the graph<br>$$h(v) = |t-v|$$</li></ul><p><img src="/blog/images/motion_pl02.jpg" width="80%" height="80%"></p><p>Extensions to Other Factors</p><ul><li>Traffic, speed limits, and weather affect mission planning</li><li>Time rather than distance is better at capturing these factors</li><li>Replace distance edge weights with time estimates</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;From Coursera, State Estimation and Localization for Self-Driving Cars by University of Toronto&lt;br&gt;&lt;a href=&quot;https://www.coursera.org/lear
      
    
    </summary>
    
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
      <category term="Self-driving" scheme="http://tracyxinwang.site/blog/tags/Self-driving/"/>
    
  </entry>
  
  <entry>
    <title>Coursera Motion Planning for Self-Driving Cars 04</title>
    <link href="http://tracyxinwang.site/blog/2019/08/21/coursera_motion_pl04/"/>
    <id>http://tracyxinwang.site/blog/2019/08/21/coursera_motion_pl04/</id>
    <published>2019-08-21T04:30:23.000Z</published>
    <updated>2019-08-22T05:23:23.146Z</updated>
    
    <content type="html"><![CDATA[<p>From Coursera, State Estimation and Localization for Self-Driving Cars by University of Toronto<br><a href="https://www.coursera.org/learn/motion-planning-self-driving-cars" target="_blank" rel="noopener">https://www.coursera.org/learn/motion-planning-self-driving-cars</a></p><h2 id="Dynamic-Object-Interactions"><a href="#Dynamic-Object-Interactions" class="headerlink" title="Dynamic Object Interactions"></a>Dynamic Object Interactions</h2><h3 id="Motion-Prediction"><a href="#Motion-Prediction" class="headerlink" title="Motion Prediction"></a>Motion Prediction</h3><p><strong>Definition</strong></p><ul><li>Motion prediction of the dynamic object’s attempts to estimate the future position, heading and velocity</li><li>Important as it allows: <ul><li>Planning a set of maneuvers to correctly interact with dynamic objects</li><li>Avoid collisions on a planned trajectory</li></ul></li></ul><p><strong>Requirements for Motion Prediction Models</strong></p><ul><li>Mandatory Requirements:<ul><li>Class of the Dynamic Object </li><li>Current dynamic object states: position, heading and velocity</li></ul></li><li>Optional Requirements: <ul><li>History of Vehicle states: the position, heading and velocity <ul><li>Requires object tracking States between identifications over a set amount of time</li></ul></li><li>Current high definition roadmap</li><li>Image of the current dynamic object</li></ul></li></ul><p><strong>Assumptions in Motion Prediction for simplification</strong></p><ul><li>Cars<ul><li>Physics-based prediction: vehicles must follow a set of physical constraints governing their movement, e.g. Vehicle Kinematics and Dynamics</li><li>Maneuver-based assumptions: all motions by a vehicle on the road are made up of a finite set of maneuvers in a restricted domain in the environment, e.g. vehicles on the road will stay on the road and follow the driving rules like unlikely to drive over sidewalks or lawns or through obstacles</li><li>Interactions-aware Assumptions: incorporate the assumption that the dynamic objects will react and interact with each other. e.g. the vehicle in the destination lane will slow down to make more room for the incoming vehicle to maintain a safe following distance.</li></ul></li><li>Pedestrians:<ul><li>the same three categories assumptions as the cars</li><li>Pedestrians are unpredictable</li><li>Can rapidly change speed and heading</li><li>Pedestrians use crossings Pedestrians use sidewalks</li><li>Pedestrians have right of way, but will stop if threatened</li></ul></li></ul><p><strong>Constant Velocity Prediction Model</strong></p><ul><li>Simple</li><li>Computationally efficient</li><li>Assumption is that the dynamic object will maintain its <ul><li>velocity</li><li>Magnitude</li><li>Heading<br>Algorithm:</li></ul></li><li>Input:<ul><li>$T$: time horizon to predict over</li><li>$dt$: time between predictions</li><li>$x_{obj}$: current dynamic object state<ul><li>Position: $x_{obj}.pos$</li><li>Velocity: $x_{obj}.vel$</li></ul></li></ul></li><li>Output:<ul><li>$x_{1:T}$: list of future vehicle states</li></ul></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$t &lt;- 0$</span><br><span class="line">$x_o = x_&#123;obj&#125;$</span><br><span class="line">while $t*dt &lt; T$ do</span><br><span class="line">    $t = t + 1$</span><br><span class="line">    $x_t.pos &lt;- x_&#123;t-1&#125;.pos + dt*x_&#123;t-1&#125;.vel$</span><br><span class="line">    $x_t.vel &lt;- x_&#123;t-1&#125;.vel$</span><br><span class="line">end while</span><br><span class="line">return $x_&#123;1:T&#125;$</span><br></pre></td></tr></table></figure><p>Issues</p><ul><li>Don’t account for Vehicle Dynamics fully</li><li>Don’t account for the Road (Position,adjustment)</li><li>Don’t account for Road Signs(Velocity adjustment)</li><li>Assumptions are too Strong and Incorrect for most Dynamic Object Motion</li></ul><h3 id="Map-Aware-Motion-Prediction"><a href="#Map-Aware-Motion-Prediction" class="headerlink" title="Map-Aware Motion Prediction"></a>Map-Aware Motion Prediction</h3><p><strong>Assumptions to Improve Prediction</strong></p><ul><li>Positional Assumptions<ul><li>Vehicles on driving lane usually follow the given drive lane</li><li>Changing drive lanes is usually prompted by an indicator signal</li></ul></li><li>Velocity Assumptions<ul><li>Vehicles usually modify their velocity when approaching restrictive geometry(tight turns)</li><li>Vehicles usually modify the velocity when approaching regulatory elements</li></ul></li></ul><p><strong>Improvement of Position Estimation</strong></p><ul><li>Roadways with natural curvature</li><li>Vehicles on drive lane usually follow the given drive lane</li><li>The predicted path is set to follow the center of the driving lane which the dynamic vehicle is on</li></ul><p><strong>Improvement of Path Prediction</strong></p><ul><li>Problems with the model:<ul><li>Difficult to predict lane change maneuvers without extra information</li><li>Multiple possible lanelets such as when on an intersection</li></ul></li><li>Solution with the model:<ul><li>Most likely prediction</li><li>Multi-hypothesis prediction</li></ul></li></ul><p><strong>Multi-hypothesis Approach</strong></p><ul><li>Consider the range of all possible motions <ul><li>Left, right, stay stopped</li></ul></li><li>Provides more information to local planner</li><li>Safer due to human error (forgotten turn signal)</li></ul><p><strong>Improvements to Velocity Prediction</strong></p><ul><li>Road curvature can be used to improve the velocity prediction over the path</li><li>Improve the velocity prediction based on regulatory elements in the environment <ul><li>Stop locations, deceleration profiles </li><li>Lanelet priors</li></ul></li></ul><h3 id="Time-to-Collision"><a href="#Time-to-Collision" class="headerlink" title="Time to Collision"></a>Time to Collision</h3><p><strong>Definition of Time to Collision</strong></p><ul><li>Assuming all dynamic object continue along their predicted path: <ul><li>Will then be a collision between any of the objects?</li><li>If so how far into the future?</li></ul></li><li>Time to Collision is comprised of: <ul><li>Collision point between the two dynamic objects </li><li>Prediction of the time to arrive to the collision point</li></ul></li><li>Requirements for Accuracy: <ul><li>Accurate predicted trajectories for all dynamic objects (position, heading and velocity)</li><li>Accurate dynamic objects geometries</li></ul></li></ul><p><strong>Approaches to calculate time to collision</strong></p><ul><li>Two basic approaches to calculating time to collision:<ul><li>Simulation approach</li><li>Estimation approach</li></ul></li><li>Simulation approach<ul><li>Simulate the movement of each vehicle as time passes</li><li>Taking account of the vehicle model over time</li><li>Checking if any part of the two dynamic object has collided</li></ul></li><li>Estimation approach<ul><li>Geometries of the vehicles are approximated over duration of the predicted path</li><li>Collision point is estimated based the cars predictions</li><li>Many assumptions are usually made by this method usually to estimate time to collision</li></ul></li></ul><p><strong>Relative Strengths and Weaknesses</strong></p><ul><li>Simulation Approach Estimation Approach<ul><li>Computationally expensive</li><li>Higher accuracy if simulated with high fidelity</li><li>Offline Applications (Dataset evaluation or Simulations)</li></ul></li><li>Estimation Approach<ul><li>Computationally inexpensive<ul><li>Memory footprint</li><li>Computational time</li></ul></li><li>Less accurate due to approximations and estimations</li><li>Real Time Applications(In Car Prediction)</li></ul></li></ul><p><strong>Simulation approach Pseudocode</strong><br>Inputs:</p><ul><li>$D$: list of all dynamic objects<ul><li>Predicted paths</li></ul></li><li>$dt$: time between simulation steps</li><li>$N_c$: number of circles for collision approximation<br>Outputs:</li><li>$P_{coll}$: list of all collision points</li><li>$TTC$: list of all times to collision points<br><img src="/blog/images/motion_pl03.jpg" width="80%" height="80%"></li></ul><p><strong>Estimation of Dynamic Object State</strong></p><ul><li>Each predicted vehicle state has a predicted time at each location</li><li>Find the closest vehicle state along the predicted path to the current simulation time</li><li>Efficient Collision Detection Method<ul><li>Represent each car as a set of circles</li><li>Check if a collision will occur between two circles $$d_{i,j} = \sqrt{(x_j - x_i)^2+(y_j -y_i)^2} \quad r_i + r_j \gt d_{i,j}$$</li><li>Calculate collision point $$C_x = \frac{(x_i<em>r_j)+(x_j</em>r_i)}{(r_i+r_j)}, C_y = \frac{(y_i<em>r_j)+(y_j</em>r_i)}{(r_i+r_j)} $$</li><li>Tradeoff between:<ul><li>Accuracy</li><li>Number of computations</li></ul></li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;From Coursera, State Estimation and Localization for Self-Driving Cars by University of Toronto&lt;br&gt;&lt;a href=&quot;https://www.coursera.org/lear
      
    
    </summary>
    
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
      <category term="Self-driving" scheme="http://tracyxinwang.site/blog/tags/Self-driving/"/>
    
  </entry>
  
  <entry>
    <title>Coursera Motion Planning for Self-Driving Cars 02</title>
    <link href="http://tracyxinwang.site/blog/2019/08/19/coursera_motion_pl02/"/>
    <id>http://tracyxinwang.site/blog/2019/08/19/coursera_motion_pl02/</id>
    <published>2019-08-19T13:30:23.000Z</published>
    <updated>2019-08-19T12:34:27.651Z</updated>
    
    <content type="html"><![CDATA[<p>From Coursera, State Estimation and Localization for Self-Driving Cars by University of Toronto<br><a href="https://www.coursera.org/learn/motion-planning-self-driving-cars" target="_blank" rel="noopener">https://www.coursera.org/learn/motion-planning-self-driving-cars</a></p><h2 id="Mapping-for-Planning"><a href="#Mapping-for-Planning" class="headerlink" title="Mapping for Planning"></a>Mapping for Planning</h2><p>two environmental maps: the occupancy grid map and the high-definition road map.</p><h3 id="Occupancy-Grids"><a href="#Occupancy-Grids" class="headerlink" title="Occupancy Grids"></a>Occupancy Grids</h3><ul><li>discretized fine grain grid which surrounds the current ego vehicle position.<ul><li>can be 2D or 3D</li></ul></li><li>Each grid square of the occupancy grid indicates if a static or stationary object is present in that grid location. If so, that grid location is classified as occupied. <ul><li>Trees and buildings</li><li>Curbs and other non drivable surfaces: lawns or sidewalks. </li></ul></li><li>Each cell is a binary value denoted by $m^i \in {0,1}$, where 1 indicates that the square is occupied by a static object, and 0 indicates that it is not.</li><li>Assumption of Occupancy Grid<ul><li>Static environment: all dynamic objects or moving objects must be removed from the sensor data before it is used for occupancy grid mapping</li><li>Independence of each cell: to simplify the update functions needed to create the occupancy grid</li><li>Known vehicle state at each time step</li></ul></li><li>LIDAR sensor is used most frequently<ul><li>Several components of the LIDAR data need to be filtered out before this data can be used to construct an occupancy grid. </li><li>filter all LIDAR points which comprise the ground plane. In this case, the ground plane is the road surface which the autonomous car can safely drive on. </li><li>filter all points which appear above the highest point of the vehicle: they can be ignored as they will not impede the progression of the autonomous vehicle. </li><li>filter all non-static objects which had been captured by the LIDAR. This includes all vehicles, pedestrians, bicycles, and animals. </li><li>Once all filtering of the LIDAR data is complete, the 3D LIDAR data will need to be projected down to a 2D plane to be used to construct our occupancy grid. </li></ul></li><li>To handle the environmental and sensor noise, the occupancy grid will be modified to be probabilistic. <ul><li>the occupancy grid can now be represented as a belief map: $bel_t(m^i) = p(m^i|(y,x))$</li><li>$m^i$ represents a single square of the occupancy grid, where i can be constructed from measurements y, and the vehicle location x. </li><li>$m^i$ is equal to the probability that the current cell $m^i$ is occupied given the sensor measurements gathered for that cell location.</li><li>Threshold of certainty will be used to establish occupancy to get the binary map</li></ul></li><li>Bayesian Update of the Occupancy Grid<ul><li>To improve robustness multiple timesteps are used to produce the current map: $bel_t(m^i) = p(m^i|(y,x)_{1:t})$</li><li>we can update beliefs in a recursive manner so that at each time step t, we use all prior information from time one onwards to define our belief.</li><li>Bayes’theorem is applied for at each update step for each cell: $bel_t(m^i) = \eta p(y_t|m^i) bel_{t-1}(m^i)$</li><li>The distribution $p(y_t|m^i)$, is the probability of getting a particular measurement given a cell $m^i$ is occupied. This is known as the measurement model</li><li>The belief at time t-1 $bel_{t-1}(m^i)$ corresponds to the prior belief stored in our occupancy grid from the previous time step. </li><li>rely on the Markov assumption, that all necessary information for estimating cell occupancy is captured in the belief map at each time step. So no earlier history needs to be considered in the cell update equations.</li><li>$\eta$ in this case corresponds to a normalizing constant applied to the belief map. </li></ul></li></ul><h3 id="Populating-Occupancy-Grids-from-LIDAR-Scan-Data-Part-1"><a href="#Populating-Occupancy-Grids-from-LIDAR-Scan-Data-Part-1" class="headerlink" title="Populating Occupancy Grids from LIDAR Scan Data (Part 1)"></a>Populating Occupancy Grids from LIDAR Scan Data (Part 1)</h3><p><strong>lssue With Standard Bayesian Update</strong></p><ul><li>Multiplication of numbers close to zero is hard for computers: lead to significant rounding error when multiplying small numbers, which in turn can lead to instability in the estimate of the probabilities.</li><li>The multiplication of probabilities turns out to be an inefficient way to perform the belief update. </li><li>Solution: Instead of storing the belief map with the values ranging from 0-1, we can convert the beliefs into log odds probabilities using the logit function: $log(\frac{p}{1-p})$</li><li>This leads to cell values ranging from $-/infty$ to $+/infty$ avoiding the issue with numbers close to zero.</li></ul><p><strong>Bayesian Log Odds Single Cell Update Derivation</strong></p><ul><li>Applying Bayes’rule: $$p(m^i|y_{1:t})$$<ul><li>where $m^i$ is the current occupancy grid map square at location $i$ and $y_{1:t}$ are the sensor measurements of that cell from time one to time t. </li></ul></li><li>The full Bayesian update for incorporating the latest measurements into our occupancy belief: $$p(m^i|y_{1:t}) = \frac{p(y_t|y_{1:t-1},m^i)p(m^i|y_{1:t-1}}{p(y_t|y_{1:t-1})} $$</li><li>Next applying the Markov assumption: $$p(m^i|y_{1:t}) = \frac{p(y_t|m^i)p(m^i|y_{1:t-1})}{p(y_t|y_{1:t-1})}$$<ul><li>this ensures the current measurement is independent of previous measurements if the map state $m^i$ is known. </li></ul></li><li>Next is to expand the measurement model $p(y_t|m^i)$ by the application of Bayes’ rule once again $$p(y_t|m^i) = \frac{p(m^i|y_t)p(y_t)}{p(m^i)} $$</li><li>Substitute the expanded measurement model in blue into the main Bayesian inference equation:<br>$$p(m^i|y_{1:t}) = \frac{p(m^i|y_t)p(y_t)p(m^i|y_{1:t-1})}{p(m^i)p(y_t|y_{1:t-1})}$$</li><li>After logit function: $$logit(p(m^i|y_{1:t})) = logit(p(m^i|y_t)) + logit(p(m^i|y_{1:t-1})) - logit(p(m^i)) $$<ul><li>rewrite it as: $l_{t,i} = logit(p(m^i|y_t)) + l_{t-1,i} - l_{0,i}$ </li><li>$l_{t-1,i}$ is the previous belief</li><li>$l_{0,i}$ is the initial belief</li></ul></li><li>Advantages over directly updating probabilities<ul><li>Numerically stable</li><li>Computationally efficient</li></ul></li></ul><h3 id="Populating-Occupancy-Grids-from-LIDAR-Scan-Data-Part-2"><a href="#Populating-Occupancy-Grids-from-LIDAR-Scan-Data-Part-2" class="headerlink" title="Populating Occupancy Grids from LIDAR Scan Data (Part 2)"></a>Populating Occupancy Grids from LIDAR Scan Data (Part 2)</h3><p><strong>Inverse Measurement Module</strong></p><ul><li>Relative change: $$r^i = \sqrt((m^i_x - x_{1,t})^2 + (m^i_y - x_{2,t})^2)$$<ul><li>the Euclidean distance from the sensor to the cell</li><li>where $r^i$ is the range to grid cell i </li><li>$m^i_x$ and $m^i_y$ are the x and y coordinates of the center of the grid cell.</li><li>$x_{1,t}$ and $x_{2,t}$ are the sensor location at the current time t</li></ul></li><li>Relative bearing: $$\phi^i = \tan^{-1} (\frac{m^i_y - x_{2,t}}{m^i_x - x_{1,t}}) - x_{3,t}$$</li><li>Closest relative bearing: $$k = argmin(|\phi^i - \phi^s_j|)$$<ul><li>For each cell, we associate the most relevant lidar beam by finding the measurement with the minimum error between its beam angle and the cell bearing.</li></ul></li><li>Then define two parameters $\alpha$ and $\beta$, which define a sector around each beam in which cell occupancy should be determined based on the beam range.<ul><li>$\alpha$ defines the affected range for high probability</li><li>$\beta$ defines the affected angle for low and high probability</li><li>This essentially creates a region around each beam which will get assigned the measurement information of that particular beam.</li></ul></li><li>We are now ready to assign a probability that any cell is occupied given the lidar measurements received based on these three types of cells:<ul><li>no information zone: if $r^i &gt; min(r^s_{max}) $ or $ |\phi^i -\phi^s_k| &gt; \beta/2$</li><li>high information zone: if $r^s_k &lt; r^s_{max}$ and $|r^i - r^s_k| &gt; \alpha/2$</li><li>low information zone: if $r_i &lt; r^s_k$</li></ul></li></ul><p><strong>Inverse Measurement Module With Ray Tracing</strong></p><ul><li>However, this simple inverse measurement model can be computationally expensive:<ul><li>It requires a full update of every cell in the measurement map</li><li>and relies on multiple floating-point operations to identify which measurements correspond to which cells. </li></ul></li><li>Alternative is to use Ray tracing algorithm <ul><li>using Bresenham’s line algorithm</li><li>Rasterized line algorithm</li><li>Uses very cheap fixed point operations for fast calculations</li></ul></li></ul><h3 id="Occupancy-Grid-Updates-for-Self-Driving-Cars"><a href="#Occupancy-Grid-Updates-for-Self-Driving-Cars" class="headerlink" title="Occupancy Grid Updates for Self-Driving Cars"></a>Occupancy Grid Updates for Self-Driving Cars</h3><p>Downsampling</p><ul><li>Up to ~1.2 million points per second</li><li>Removal of redundant points</li><li>Improves computation</li></ul><p>Removal of overhanging objects</p><ul><li>Removing all Lidar points that are above a given threshold of the height limit of the car</li></ul><p>Removal of ground plane</p><ul><li>Difficult to estimate due to several complications o Differing road geometries oCurbs,lane boundaries oDon’t want to miss small objects</li><li>Ground plane Classification<ul><li>Utilize segmentation to remove points of road elements</li><li>Keep points from no drivable surfaces</li></ul></li></ul><p>Removal of Dynamic Objects</p><ul><li>Not all vehicles are dynamic, so they should be included</li><li>History of dynamic object location can be used to identify parked vehicle</li><li>The dynamic objects are identified from the previous LIDAR frame</li><li>Predicted future location improvement</li></ul><p>Projection of LIDAR Onto a 2D Plane</p><ul><li>Collapse all points by Zeroing the Z coordinate</li><li>Sum up the number of LIDAR points in each grid location<ul><li>More points indicated greater chance of occupation of that grid cell</li></ul></li></ul><h3 id="High-Definition-Road-Maps"><a href="#High-Definition-Road-Maps" class="headerlink" title="High Definition Road Maps"></a>High Definition Road Maps</h3><p>High Definition Road Maps stores </p><ul><li>the precise road locations including all lanes down to a few centimeters accuracy. </li><li>all of the locations of road signs and signals which might effect the autonomous vehicle.</li></ul><p><strong>Lanelet map</strong></p><ul><li>Due to the detailed and interconnected nature of the data, an effective method is required to store all information contained within the map.</li><li>Due to this method’s effectiveness in storage and communication of the complex set of information needed for HD mapping, it is widely used</li><li>The lanelet map has two main components<ul><li>Lanelet element: stores all information connected to a small longitudinal segment of a lane on a road which it represents</li><li>Intersection element: stores all lanelet elements which are part of a single intersection for simple retrieval during motion planning tasks. </li></ul></li></ul><p><strong>Lanelet element</strong></p><ul><li>Defines the following:<ul><li>Left and Right Boundaries</li><li>Regulation<ul><li>Elements: e.g. a stop sign line or a static sign line</li><li>Attributes: attributes that might affect that segment of the road e.g. speed limit</li><li>Note that we only store a line for any regulatory element as this is the point that the autonomous vehicle treats as the active location for that regulatory element.</li></ul></li><li>Connectivity to other lanelets<ul><li>This allows for easy traversal and calculations through the graph created by the set of lanelets in an HD map.</li></ul></li></ul></li><li>A new lanelet is created when a new regulatory element is encountered or ends<ul><li>Boundaries of the lanelet are represented as the edges of the lanelet.</li><li>These boundaries capture either marked lane boundaries or curves which inhibit driving. </li><li>Lane boundaries are stored as a set of points creating a continuous polygonal line. Each point stores its x, y, and z GPS coordinates. The distance between points can be as fine as a few centimeters, or as course as a few meters depending on the smoothness of the polyline in question. </li><li>The ordering of the points defines the direction of travel and heading for the lanelet.</li></ul></li><li>The entire lanelet structure is connected in a directed graph, which is the base structure of the HD map</li><li>Operations Done On Lanelets<ul><li>Path planning through complex road networks</li><li>Localize Dynamic Objects</li><li>Interactions with other Dynamic Objects</li></ul></li></ul><p><strong>Creations Of Lanelets</strong><br>3 methods to create the lanelet map</p><ul><li>Offline creation</li><li>Online creation: highly computationally expensive</li><li>Offline creation with online updating</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;From Coursera, State Estimation and Localization for Self-Driving Cars by University of Toronto&lt;br&gt;&lt;a href=&quot;https://www.coursera.org/lear
      
    
    </summary>
    
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
      <category term="Self-driving" scheme="http://tracyxinwang.site/blog/tags/Self-driving/"/>
    
  </entry>
  
  <entry>
    <title>Coursera Motion Planning for Self-Driving Cars 01</title>
    <link href="http://tracyxinwang.site/blog/2019/08/16/coursera_motion_pl01/"/>
    <id>http://tracyxinwang.site/blog/2019/08/16/coursera_motion_pl01/</id>
    <published>2019-08-16T13:30:23.000Z</published>
    <updated>2019-08-17T06:47:59.347Z</updated>
    
    <content type="html"><![CDATA[<p>From Coursera, State Estimation and Localization for Self-Driving Cars by University of Toronto<br><a href="https://www.coursera.org/learn/motion-planning-self-driving-cars" target="_blank" rel="noopener">https://www.coursera.org/learn/motion-planning-self-driving-cars</a></p><h2 id="The-Planning-Problem"><a href="#The-Planning-Problem" class="headerlink" title="The Planning Problem"></a>The Planning Problem</h2><h3 id="Driving-Missions-Scenarios-and-Behaviour"><a href="#Driving-Missions-Scenarios-and-Behaviour" class="headerlink" title="Driving Missions, Scenarios, and Behaviour"></a>Driving Missions, Scenarios, and Behaviour</h3><p><strong>Autonomous Driving Mission</strong></p><ul><li>Mission is to navigate from point A to point B on the map</li><li>Mission planning is higher-level planning</li><li>Low-level details are abstracted away</li><li>Goal is to find most efficient path (in terms of time or distance)</li></ul><p><strong>Road Structure Scenarios</strong></p><ul><li>Road structure influences driving scenario through lane boundaries and regulatory elements</li><li>Simplest case is driving straight, following the center of the lane<ul><li>Minimize deviation from centerline</li><li>Attain reference speed for efficiency</li></ul></li><li>Lane changes are more complex<ul><li>Different shapes for different situations</li><li>Shape depends on vehicle speed, acceleration limitations</li><li>Time horizon of execution affects the aggressiveness of the lane change</li></ul></li><li>Left and right turn scenarios are common in intersections and drivelanes<ul><li>Shape of turn varies, similar to lane changes</li><li>State of surrounding environment impacts the ability of the vehicle to make turns</li></ul></li><li>U-turns are useful for efficient direction changes<ul><li>Shape of U-turn will depend on car’s speed and acceleration limits</li><li>Not always possible at all intersections</li></ul></li></ul><p><strong>Obstacle Scenarios</strong></p><ul><li>Static and dynamic obstacles also impact the driving scenario</li><li>Static obstacles restrict which locations our path can occupy</li><li>Most important dynamic obstacle is often the leading vehicle in front of the ego vehicle<ul><li>Need to maintain time gap for safety</li></ul></li><li>Dynamic obstacles impact turns/lane changes as well</li><li>Depending on locations and speed, differenttime windows of execution are available for the autonomous vehicle</li><li>Need to use estimation and prediction to calculate these windows of opportunity</li><li>Different dynamic obstacles in the scenario have different characteristics and behaviours</li></ul><p><strong>Behaviours</strong></p><ul><li>Speed Tracking</li><li>Decelerate to Stop</li><li>Stay Stopped</li><li>Yield</li><li>Emergency Stop<ul><li>Not an exhaustive list</li></ul></li></ul><p><strong>Hierarchical Planning Introduction</strong></p><ul><li>Driving mission and scenarios are complex problems</li><li>Break them into a hierarchy of optimization problems</li><li>Each optimization problem tailored to the correct scope and level of abstraction</li><li>Higher in the hierarchy means more abstraction</li><li>Each optimization problem will have constraints and objective functions<br><img src="/blog/images/motion_pl01.jpg" width="80%" height="80%"></li></ul><h3 id="Motion-Planning-Constraints"><a href="#Motion-Planning-Constraints" class="headerlink" title="Motion Planning Constraints"></a>Motion Planning Constraints</h3><p><strong>Constrains from vehicle’s kinematics and dynamics</strong></p><p>Bicycle Model</p><ul><li>Kinematics simplified to bicycle model</li><li>Bicycle model imposes curvature constraint on our path planning process</li><li>$\dot \theta = \frac{V \tan(\delta)}{L}$</li><li>$|\kappa \le \kappa_{max}|$<ul><li>there is a maximum magnitude of curvature that can be executed when traversing a given path. </li></ul></li><li>Curvature constraint is non-holonomic<ul><li>Non-holonomic constraints reduce the directions a mobile robot can travel at any point</li><li>Makes motion planning challenging</li><li>curvature computation: $\kappa = \frac{x’y’’ - y’x’’}{(x’^2+y’^2)^{3/2}}$</li></ul></li></ul><p>Vehicle Dynamics</p><ul><li>Recall: friction ellipse denotes maximum magnitude of tire forces before stability loss</li><li>Friction forces are extreme limit; more useful constraint is accelerations tolerable by passengers <ul><li>Given by “comfort rectangle”range of lateral and longitudinal accelerations</li></ul></li></ul><p>Dynamics and Curvature</p><ul><li>Friction limits and comfort restrict lateral acceleration<ul><li>Lateral acceleration is a function of instantaneous turning radius of<br>path and velocity</li><li>$a_{lat} = \frac{v^2}{r}, \quad a_{lat} \le a_{lat_{max}}$</li></ul></li><li>Recall: instantaneous curvature is inverse of instantaneous turning radius</li><li>Substituting, velocity is constrained by path curvature and lateral acceleration<ul><li>$v^2 \le \frac{a_{lat_{max}}}{\kappa}$</li></ul></li></ul><p><strong>Constrains from static and dynamic obstacles</strong><br>Static Obstacles</p><ul><li>Static obstacles block portions of workspace<ul><li>Occupancy grid encoding stores obstacle locations</li></ul></li><li>Static obstacle constraints satisfied by performing collision checking<ul><li>Can check for collisions using the swath of the vehicle’s path</li><li>Can also check for closest obstacle along ego vehicle’s path</li></ul></li></ul><p>Dynamic Obstacles</p><ul><li>dynamic obstacles will constrain both our behavior planning process, where we make maneuver decisions, as well as the local planning process, where it will affect our velocity profile planning.</li></ul><p><strong>Impact of regulatory elements</strong> </p><ul><li>Lane constraints restrict path locations</li><li>Signs, traffic lights influence vehicle behaviour</li></ul><h3 id="Objective-Functions-for-Autonomous-Driving"><a href="#Objective-Functions-for-Autonomous-Driving" class="headerlink" title="Objective Functions for Autonomous Driving"></a>Objective Functions for Autonomous Driving</h3><p><strong>Efficiency</strong></p><ul><li>Path length:<ul><li>Minimize the arc length of a path to generate the shortest path to the goal</li><li>the arc length of the path is the total accumulated distance the car will travel as it traverses the path. </li><li>$s_f = \int^{x_f}_{x_i} \sqrt{1+(\frac{dy}{dx})^2} dx$</li></ul></li><li>Travel time:<ul><li>Minimize time to destination while following the planned path</li><li>$T_f = \int^{s_f}_0 \frac {1}{v(s)} ds$</li></ul></li></ul><p><strong>Reference Tracking</strong></p><ul><li>In path planning for autonomous driving, we may be given a reference path we’d like to follow</li><li>we can penalize deviation from the reference path or speed profile</li><li>$\int^{s_f}<em>0 |x(s) - x</em>{ref}(s)| ds$</li><li>$\int^{s_f}<em>0 |v(s) - v</em>{ref}(s)| ds$</li><li>For velocity: Hinge loss to penalize speed limit violations severely</li><li>$\int^{s_f}<em>0 (v(s) - v</em>{ref}(s))_+ ds$</li></ul><p><strong>Smoothness</strong><br>$$\int^{s_f}_0 | \dddot x(s) |^2 ds$$</p><ul><li>focus to minimize the jerk along our trajectory</li><li>Jerk is the rate of change of acceleration with respect to time, or the third derivative of position. </li><li>The jerk along the car’s trajectory greatly impacts the user’s comfort while in the car. So when planning our velocity profile, we would like to keep the accumulated absolute value of jerk as small as possible.</li></ul><h3 id="Hierarchical-Motion-Planning"><a href="#Hierarchical-Motion-Planning" class="headerlink" title="Hierarchical Motion Planning"></a>Hierarchical Motion Planning</h3><p>Hierarchical Planner</p><ul><li>Motion planning broken into hierarchy of subproblems</li><li>Mission planner: the highest level, focuses on map-level navigation</li><li>Behavioural planner focuses on other agents, rules of the road, driving behaviours</li><li>Local planner focuses on generating feasible, collision-free paths</li></ul><p><strong>Mission Planner</strong></p><ul><li>Highest level planner</li><li>Focuses on autonomous driving mission<ul><li>Navigate to destination at the map level</li></ul></li><li>Abstract away lower level details</li><li>Can be solved with graph-based methods (Dijkstra’s, A*)</li></ul><p><strong>Behavioural Planner</strong></p><ul><li>Behavioural planner decides when it is safe to proceed</li><li>Takes pedestrians, vehicles, cyclists into consideration</li><li>Also looks at regulatory elements, such as traffic lights and stop signs</li><li>Finite State Machines<ul><li>Composed of states and transitions </li><li>States are based on perception of surroundings </li><li>Transitions are based on inputs to the driving scenario (e.g.stop lights changing colour)</li><li>FSM is memoryless: Transitions only depend on input and current state, and not on past state sequence</li></ul></li><li>Rule-based System<ul><li>Rule-based systems use a hierarchy of rules to determine output behaviour</li><li>Rules are evaluated based on logical predicates<ul><li>Higher priority rules have precedence</li></ul></li><li>Example scenario with two rules<ul><li>green light A intersection → drive straight</li><li>pedestrian A driving straight → emergency stop</li></ul></li></ul></li><li>Reinforcement learning<ul><li>$R = \sum^\infty_{t=0} \gamma^t R_{a_t}(s_t, s_{t+1})$</li></ul></li></ul><p><strong>Local Planner</strong></p><ul><li>Local planning generates feasible, collision-free paths and comfortable velocity profiles</li><li>Decomposed into <em>path planning</em> and <em>velocity profile generation</em></li></ul><p>Path planner:</p><ul><li>The key ingenuity behind developing a good path planning algorithm is reducing the search space for optimization</li><li>Three main categories of path planners: sampling-based planners, variational planners and lattice planners</li><li>Sampling-based Planners:<ul><li>Randomly sample the control inputs to quickly explore the workspace</li><li>One of the most iconic sampling-based algorithms is the Rapidly Exploring Random Tree or RRT</li><li>These algorithms construct the branches of the tree of paths by generating points in randomly sampled locations and planning a path to the point, from the nearest point in the tree. </li><li>If the path is free from collisions with any static obstacles, that path is added to the tree. </li><li>This tree quickly explores the workspace with many potential paths and when a goal region is reached, the path that terminates in that region is returned.</li><li>Often very fast, but can generate poor-quality paths</li></ul></li><li>Variational planners:<ul><li>rely on the calculus of variations to optimize a trajectory function which maps points in time to positions in the workspace according to some cost-functional that takes obstacles and robot dynamics into consideration. $min_{\delta x} J(x+\delta x)$</li><li>are usually trajectory planners, which means they combine both path planning and velocity planning into a single-step.</li><li>Can be slower, and less likely to converge to a feasible solution</li><li>a variational method is the chomp algorithm</li></ul></li><li>Lattice Planners<ul><li>Constrain the search space by limiting actions available to the robot <ul><li>Set of actions known as control set</li></ul></li><li>This control set, when paired with a discretization of the workspace, implicitly defines a graph. This graph can then be searched using a graph search algorithm such as Dijkstra’s or A*, which results in fast computation of paths</li><li>While the lattice planner is often quite fast, the quality of paths are sensitive to the selected control set. </li><li>A common variance on the lattice planner is known as the conformal lattice planner, where goal points are selected some distance ahead of the car, laterally offset from one another with respect to the direction of the road and a path is optimized to each of these points. </li><li>Conformal lattice planner fits the control actions to the road structure</li></ul></li></ul><p>Velocity profile generation:</p><ul><li>is usually set up as a constrained optimization problem. </li><li>we would combine many of the velocity profile objectives such as the goals of minimizing jerk or minimizing deviation from a desired reference, the rectangle of comfortable acceleration</li><li>Once the objectives and constraints are formalized, it becomes a matter of solving the problem efficiently. One way to do this is to calculate convex approximations to the optimization domain and objectives, which helps ensure that our optimizer doesn’t get stuck in local minima.</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;From Coursera, State Estimation and Localization for Self-Driving Cars by University of Toronto&lt;br&gt;&lt;a href=&quot;https://www.coursera.org/lear
      
    
    </summary>
    
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
      <category term="Self-driving" scheme="http://tracyxinwang.site/blog/tags/Self-driving/"/>
    
  </entry>
  
  <entry>
    <title>Coursera Visual Perception for Self-Driving Cars 05</title>
    <link href="http://tracyxinwang.site/blog/2019/08/08/coursera_visual_percep05/"/>
    <id>http://tracyxinwang.site/blog/2019/08/08/coursera_visual_percep05/</id>
    <published>2019-08-08T12:30:23.000Z</published>
    <updated>2019-08-09T02:19:09.154Z</updated>
    
    <content type="html"><![CDATA[<p>From Coursera, State Estimation and Localization for Self-Driving Cars by University of Toronto<br><a href="https://www.coursera.org/learn/visual-perception-self-driving-cars" target="_blank" rel="noopener">https://www.coursera.org/learn/visual-perception-self-driving-cars</a></p><h2 id="Semantic-Segmentation"><a href="#Semantic-Segmentation" class="headerlink" title="Semantic Segmentation"></a>Semantic Segmentation</h2><h3 id="The-Semantic-Segmentation-Problem"><a href="#The-Semantic-Segmentation-Problem" class="headerlink" title="The Semantic Segmentation Problem"></a>The Semantic Segmentation Problem</h3><ul><li>Given an input image, we want to classify each pixel into a set of preset categories. The categories can be static road elements e.g. roads, sidewalk, traffic lights or dynamic obstacles e.g. cars, pedestrians, and cyclists or a background class that encompasses any category we do not include in our preset categories.</li><li>Semantic segmentation is still through a function estimator<ul><li>Given an image, we take every pixel as an input and output a vector of class scores per pixel. </li><li>A pixel belongs to the class with the highest class score.</li></ul></li></ul><p><strong>Performance of semantic segmentation</strong></p><ul><li>True Positive(TP): The number of correctly classified pixels belonging to classX</li><li>False Positive(FP): The number of pixels that do not belong to class X in ground truth but are classified that class by the algorithm</li><li>False Negative(FN): The number of pixels that do belong to class X in ground truth,but are not classified as that class by the algorithm<br>$$IOU_{class} = \frac{TP}{TP+FP+FN}$$</li><li>Class lOU over all the data is calculated by computing the sum of TP, FP, FN for all images first</li><li>Averaging the class IOU is usually not a very good idea!</li><li>CityScapes Segmentation Dataset</li></ul><h3 id="ConvNets-for-Semantic-Segmentation"><a href="#ConvNets-for-Semantic-Segmentation" class="headerlink" title="ConvNets for Semantic Segmentation"></a>ConvNets for Semantic Segmentation</h3><ul><li>Semantic segmentation takes a camera images input and provides a category classification for every pixel in that image as output. This problem can be modeled as a function approximation problem, and ConvNets can once again be used to approximate the required function.</li><li>The ConvNet model can be chosen as the same ConvNet model we used for object detection. That is, a feature extractor followed by an output layer. We do not need anchors here as we are not trying to localize objects. </li><li>In VGG architecture, <ul><li>the input image is the size of MxNx3</li><li>As with object detection, the resolution will be reduced by half after every pooling layer. On the other hand, the depth will increase due to the convolutional layers. </li><li>The output feature map of the convolutional feature extractor will be downsampled by 16 times.</li><li>We can add as many convolutional pooling blocks as needed, but that will further shrink our feature map.</li></ul></li><li>However, output for semantic segmentation is to have a classification for every pixel in the image. How can we achieve this given a down sampled feature map that is 16 times smaller than our original input?</li><li>A simple solution would be the following:<ul><li>first compute the output by passing the 16 times downsampled output feature map through a softmax layer.</li><li>We can then determine the class of every pixel in the subsampled output by taking the highest class score obtained by the softmax layer.</li><li>The final step would be to proceed to upsample, the downsampled output back to the original image resolution. </li><li>however, this naive upsampling might produce inadequate results</li></ul></li><li>one of the most challenging problems in semantic segmentation is attaining smooth and accurate boundaries around the objects. <ul><li>Smooth boundaries are hard to attain as in general boundaries in the image space are ambiguous, especially for thin objects such as pools, similar looking objects such as roads and sidewalks, and far away objects.</li></ul></li><li>Naive upsampling also induces two additional problems:<ul><li>Any object less than 16 pixels in width or height usually fully disappears in their upsampled image. This affects both thin objects such as pools and far away objects. As they are below the minimum dimensions required for the pixels to appear from the original image.</li></ul></li><li>To remedy these problems, researchers have formulated what is commonly referred to as a feature decoder. <ul><li>The feature decoder can be thought of as a mirror image of the feature extractor. </li><li>Instead of using the convolution pooling paradigm to downsample the resolution, it uses upsampling layers followed by a convolutional layer to upsample the resolution of the feature map.</li><li>The upsampling usually using nearest neighbor methods achieves the opposite effect to pooling, but results in an inaccurate feature map.</li><li>The following convolutional layers are then used to correct the features in the upsampled feature map with learnable filter banks.</li><li>This correction usually provides the required smooth boundaries as we go forward through the feature decoder.</li></ul></li><li>Similar to the feature extractor, each upsampling convolution block is referred to as a deconvolution.<ul><li>As we go through the first deconvolution block, the input feature map is upsampled to twice the input resolution. </li><li>The depth is controlled by how many filters are defined for each successive convolutional layer. </li><li>As we go forward through the rest of the decoder, we finally arrive at a feature map of similar resolution to the input image. </li></ul></li><li>The output can be a linear output layer, followed by a softmax function. This layer is very similar to the classification output layer in object detection. <ul><li>this layer provides a k-dimensional vector per pixel with the kth element being how confident the neural network is that the pixel belongs to the kth class.</li></ul></li><li>Classification Loss: $L_{cls}=\frac 1{N_{total} \, \sum_i CrossEntropy(s^*_i,s_i)}$<ul><li>$N_{total}$ is the total number of classified pixels in all the images of a mini-batch. Usually, a mini-batch would comprise of 8 to 16 images, and the choice of this number depends on how much memory your GPU has.</li><li>$s_i$ is the output of the neural network</li><li>$s^*_i$ is the ground truth classification</li></ul></li></ul><h3 id="Semantic-Segmentation-for-Road-Scene-Understanding"><a href="#Semantic-Segmentation-for-Road-Scene-Understanding" class="headerlink" title="Semantic Segmentation for Road Scene Understanding"></a>Semantic Segmentation for Road Scene Understanding</h3><p><strong>3D Drivable Surface Estimation</strong><br>Steps:</p><ol><li>Generate semantic segmentation output</li><li>Associate 3D point coordinates with 2D image pixels</li><li>Choose 3D points belonging to the Drivable Surface category</li><li>Estimate 3D drivable surface model</li></ol><p>Plane Model: $$ax+by+z=d$$<br>Least squares formulation: $$p=[a,b,d], \; argmin_A(Ap-B)$$ $$A = [x_1 \; y_1 \; -1; x_2 \; y_2 \; -1; …; x_N \; y_N \; -1], \quad B = [-z_1; -z_2; … ; -z_N]$$<br>Solution: $p=(A^TA)^{-1}A^TB$</p><ul><li>Minimum number of points to estimate model: 3 non-collinear points</li><li>RANSAC Algorithm:<ul><li>From the data, randomly select 3 points.</li><li>Compute model parameters a, b, and d using least squares estimation.</li><li>Compute number of inliers, N.</li><li>If N &gt; threshold, terminate and return the computed plane parameters. Else, go back to step 1.</li><li>Recompute the model parameter using all the inliers in the inlier set.</li></ul></li></ul><p>Semantic Lane Estimation</p><ul><li>Estimate the lane, the area where the car can drive on the drivable surface</li><li>Estimate what is at the boundaries of the lane:<ul><li>Curb</li><li>Road</li><li>Car</li></ul></li><li>Steps:<ul><li>Extract segmentation mask from pixels belonging to lane separators such as lane markings or curbs.</li><li>Extract edges from this segmentation mask using an edge detector.</li><li>Linear Lane Model:Use the Hough transform to detect lines in the output edge map.</li><li>Filter lines based on slope to remove horizontal lines.</li><li>Remove any line that does not belong to the drivable space.</li><li>Determine which classes occur at the boundary of the lane.</li></ul></li><li>Materials:<ul><li>Hough Transform Line Detection: <a href="https://docs.opencv.org/3.4.3/d9/dbo/tutorial_hough_lines.html" target="_blank" rel="noopener">https://docs.opencv.org/3.4.3/d9/dbo/tutorial_hough_lines.html</a></li><li>Canny Edge Detection: <a href="https://docs.opencv.org/3.4.3/da/d22/tutorial_py_canny.html" target="_blank" rel="noopener">https://docs.opencv.org/3.4.3/da/d22/tutorial_py_canny.html</a></li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;From Coursera, State Estimation and Localization for Self-Driving Cars by University of Toronto&lt;br&gt;&lt;a href=&quot;https://www.coursera.org/lear
      
    
    </summary>
    
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
      <category term="Self-driving" scheme="http://tracyxinwang.site/blog/tags/Self-driving/"/>
    
  </entry>
  
  <entry>
    <title>Coursera Visual Perception for Self-Driving Cars 04</title>
    <link href="http://tracyxinwang.site/blog/2019/08/08/coursera_visual_percep04/"/>
    <id>http://tracyxinwang.site/blog/2019/08/08/coursera_visual_percep04/</id>
    <published>2019-08-08T02:30:23.000Z</published>
    <updated>2019-08-09T02:14:49.377Z</updated>
    
    <content type="html"><![CDATA[<p>From Coursera, State Estimation and Localization for Self-Driving Cars by University of Toronto<br><a href="https://www.coursera.org/learn/visual-perception-self-driving-cars" target="_blank" rel="noopener">https://www.coursera.org/learn/visual-perception-self-driving-cars</a></p><h2 id="2D-Object-Detection"><a href="#2D-Object-Detection" class="headerlink" title="2D Object Detection"></a>2D Object Detection</h2><h3 id="The-Object-Detection-Problem"><a href="#The-Object-Detection-Problem" class="headerlink" title="The Object Detection Problem"></a>The Object Detection Problem</h3><p><strong>2D object detection task problem</strong></p><ul><li>Object detection can be defined as a function estimation problem</li><li>Given an input image x, we want to find the function $f(x;\theta)$ that produces an output vector that includes the coordinates of the top-left of the box, and the coordinates of the lower right corner of the box, and a class score: $f(x;\theta) = [x_{min}, y_{min}, x_{max}, y_{max}, S_{class_1},…S_{class_k}]$</li></ul><p><strong>Evaluating performance measures</strong></p><ul><li>The first step of the evaluation process is to compare the detector localization output to the ground truth boxes via the Intersection-Over-Union metric (IOU).<ul><li>area of intersection of predicted box with a ground truth box, divided by the area of their union</li></ul></li><li>To account for class scores, we define true positives (TP),  False positive (FP) and False Negative (FN). <ul><li>TP: Object class score &gt; score threshold, and IOU &gt; IOU threshold</li><li>FP: Object class score &gt; score threshold, and IOU &lt; IOU threshold</li><li>FN: Number of ground truth objects not detected by the algorithm</li><li>Precision: TP/(TP+FP)</li><li>Recall: TP/(TP+FN)</li><li>Precision Recall Curve (PR-Curve): Use multiple object class score thresholds to compute precision and recall. Plot the values with precision on y-axis, and recall on x-axis</li><li>Average Precision (AP): Area under PR-Curve for a single class. Usually approximated using 11 recall points</li></ul></li></ul><h3 id="2D-Object-detection-with-Convolutional-Neural-Networks"><a href="#2D-Object-detection-with-Convolutional-Neural-Networks" class="headerlink" title="2D Object detection with Convolutional Neural Networks"></a>2D Object detection with Convolutional Neural Networks</h3><p>The Feature Extractor</p><ul><li>Feature extractors are the most computationally expensive component of the 2D object detector</li><li>The output of feature extractors usually has much lower width and height than those of the input image, but much greater depth</li><li>Very active area of research, with new extractors proposed on regular basis</li><li>Most common extractors are: VGG, ResNet, and Inception</li></ul><p>VGG Feature Extractor</p><ul><li>Alternating convolutional and pooling layers</li><li>All convolutional layers are of size 3×3xK, with stride 1 and 1 zero-padding</li><li>All pooling layers use the max function, and are of size 2x2, with stride 2 and no padding.</li></ul><p>Prior boxes/anchor boxes:</p><ul><li>To generate 2D bounding boxes, we usually do not start from scratch and estimate the corners of the bounding box without any prior. </li><li>We assume that we do have a prior on where the boxes are in image space and how large these boxes should be. These priors are called anchor boxes and are manually defined over the whole image usually on an equally-spaced grid. </li><li>During training, the network learns to take each of these anchors and tries to move it as close as possible to the ground truth bounding box in both the centroid location and box dimensions. This is termed <em>residual learning</em> and it takes advantage of the notion that it is easier to nudge an existing box a small amount to improve it rather than to search the entire image for possible object locations.</li><li>Residual learning has proven to provide much better results than attempting to directly estimate bounding boxes without any prior. </li></ul><p>Faster R-CNN:</p><ul><li>For every pixel in the feature map, we associate k anchor boxes. </li><li>We then perform a 3x3xD star convolution operation on that pixels neighborhood. This results in a 1x1xD star feature vector for that pixel. </li><li>We use this one by 1x1xD star feature vector as the feature vector of every one of the k anchors associated with that pixel. </li><li><p>We then proceed to feed the extracted feature vector to the output layers in the neural network.</p></li><li><p>The output layers of a 2D object detector usually comprise of a regression head and a classification head. </p></li><li>The regression head usually includes multiple fully-connected hidden layers with a linear output layer. The regressed output is typically a vector of residuals that need to be added to the anchor that hand to get the ground truth bounding box.</li><li>Another method to update the dimension of the anchors is to regress a residual from the center of the anchor to the center of the ground truth bounding box in addition to two scale factors that correct the ground truth bounding box width and height when multiplied with an anchor’s width and height. </li><li>The classification head is also comprised of multiple fully-connected hidden layers, but with a final softmax output layer. The softmax output is a vector with a single score per class. The highest score usually defines the class of the anchor at hand.</li></ul><h3 id="Training-vs-Inference"><a href="#Training-vs-Inference" class="headerlink" title="Training vs. Inference"></a>Training vs. Inference</h3><p><strong>Minibatch selection</strong></p><ul><li>Negative anchors target:<ul><li>Classification:Background</li><li>Regression:None</li></ul></li><li>Positive anchors target:<ul><li>Classification:Category of the ground truth bounding box</li><li>Regression:Align box parameters with highest IOU ground truth bounding box</li></ul></li><li>Problem: Majority of anchors are negatives results in neural network will label all detections as background</li><li>Solution: Sample a chosen minibatch size,with 3:1 ratio of negative to positive anchors to eliminate bias towards the negative class</li><li>Choose negatives with highest classification loss(online hard negative mining) to be included in the minibatch</li><li>Classification loss: $L_{cls} = \frac 1{N_{total}} \sum_i crossentropy(s^*_i, s_i)$<ul><li>$N_{total}$ is the size of the minibatch</li><li>$s_i$ is the output of the nerual network</li><li>$s^*_i$ is the anchor classification target:<ul><li>Background if anchor is negative</li><li>Ground truth box class if anchor is positive</li></ul></li></ul></li><li>Regression Loss: $L_{reg} = \frac 1{N_{total}} \sum_i p_iL_2(b^*_i, b_i) $<ul><li>$p_i$ is 0 if anchor is negative and 1 if anchor is positive</li><li>$N_p$ is the number of positive anchors in the minibatch</li><li>$b^*_i$ the ground truth bounding box</li><li>$b_i$ is the estimated bounding box, applying the regressed residuals to the anchor box parameters</li></ul></li></ul><p><strong>Non-maximum suppression(NMS)</strong></p><ul><li>an extremely powerful approach to improving inference output for anchor based neuron networks. </li><li>Non-max suppression takes as an input a list of predicted boundary boxed b, and each bounding blocks is comprised of the regressed coordinates in the class output score.</li><li>It also needs as an input a predefined IOU threshold which we’ll call ada.</li><li>Algorithm goes as follows<ul><li>first sort the bounding boxes in list B according to their output score. We also initialize an empty set D to hold output bounding boxes.</li><li>then proceed to iterate overall elements in the sorted box list B bar. Inside the for loop, we first determine the box B max with the highest score in the list B, which should be the first element in B bar.</li><li>then remove this bounding box from the bounding box set D bar and add it to the output set D.</li><li>Next, find all boxes remaining in the set B bar that have an IOU greater than ada with the box B max. These boxes significantly overlap with the current maximum box, B max. Any box that satisfies this condition gets removed from the list B bar. We keep iterating through the list B bar until is empty, and then we return the list D.</li><li>D now contains a single bounding box per object.</li></ul></li></ul><h3 id="Using-2D-Object-Detectors-for-Self-Driving-Cars"><a href="#Using-2D-Object-Detectors-for-Self-Driving-Cars" class="headerlink" title="Using 2D Object Detectors for Self-Driving Cars"></a>Using 2D Object Detectors for Self-Driving Cars</h3><p><strong>3D Object Detection</strong></p><ul><li>Estimating the: <ul><li>Category Classification: Car, pedestrian, cyclist </li><li>Position of the centroid in 3D: $[x,y,z]$</li><li>Extent in 3D: $[l,w,h]$ </li><li>Orientation in 3D Y: $[\phi,\psi,\theta]$</li></ul></li><li>The most common and successful way to extend 2D object detection results in 3D is to use LiDAR point clouds.<ul><li>Given a 2D bounding box in an image space and a 3D LiDAR point cloud, we can use the inverse of the camera projection matrix to project the corners of the bounding box as rays into the 3D space. </li></ul></li><li>Advantages:<ul><li>Allows exploitation of mature 2D object detectors, with high precision and recall </li><li>Class already determined from 2D detection. There is no need to use LiDAR data or pass 3D information into the network to determine whether we are looking at a car or a post.</li><li>Does not require prior scene knowledge,such as ground plane location</li></ul></li><li>Disadvantages:<ul><li>The performance of the 3D estimator is bounded by the performance of the 2D detector</li><li>Occlusion and truncation are hard to handle from 2D only</li><li>3D estimator needs to wait for 2D detector, inducing latency in our system</li></ul></li></ul><p><strong>2D object tracking</strong></p><ul><li>Detection: We detect the object independently ineach frame and can record its position over time</li><li>Tracking: We use image measurements to estimate position of object, but also incorporate position predicted by dynamics, i.e., our expectation of object’s motion pattern</li><li>Tracking Assumptions: <ul><li>Camera is not moving instantly to new viewpoint </li><li>Objects do not disappear and reappear in different places in the scene </li><li>If the camera is moving,there is a gradual change in pose between camera and scene</li></ul></li><li>Object Tracking: Prediction<ul><li>Each object will have a predefined motion model in image space, e.g. $p_k = p_{k-1} +v_k\Delta t + N(0,\Sigma)$</li></ul></li><li>Object Tracking: correlation<ul><li>Get Measurement Bounding Boxes from 2D detector.</li><li>Correlate prediction with the highest IOU measurement</li></ul></li><li>Object Tracking: Update<ul><li>The prediction and measurement are fused as part of the Kalman Filter Framework</li></ul></li><li>For each frame, we start new track if a measurement has no correlated prediction</li><li>We also terminate inconsistent tracks, if a predicted object does not correlate with a measurement for a preset number of frames</li><li>The same methodology can be used to track objects in 3D!</li></ul><p><strong>Traffic signs and signals detection</strong></p><ul><li>Traffic signs and signals appear smaller in size compared to cars, two-wheelers, and pedestrians.</li><li>Traffic signs are highly variable with many classes to be trained on.</li><li>Traffic signals have different states that are required to be detected.</li><li>In addition, traffic signals change state as the car drives</li><li>2D object detectors can be used to perform traffic sign and traffic signal detection without any modifications</li><li>However, multi-stage hierarchical models have been shown to outperform the standard single stage object detectors Prior Boxes</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;From Coursera, State Estimation and Localization for Self-Driving Cars by University of Toronto&lt;br&gt;&lt;a href=&quot;https://www.coursera.org/lear
      
    
    </summary>
    
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
      <category term="Self-driving" scheme="http://tracyxinwang.site/blog/tags/Self-driving/"/>
    
  </entry>
  
  <entry>
    <title>Coursera Visual Perception for Self-Driving Cars 03</title>
    <link href="http://tracyxinwang.site/blog/2019/08/07/coursera_visual_percep03/"/>
    <id>http://tracyxinwang.site/blog/2019/08/07/coursera_visual_percep03/</id>
    <published>2019-08-07T13:30:23.000Z</published>
    <updated>2019-08-09T02:12:31.668Z</updated>
    
    <content type="html"><![CDATA[<p>From Coursera, State Estimation and Localization for Self-Driving Cars by University of Toronto<br><a href="https://www.coursera.org/learn/visual-perception-self-driving-cars" target="_blank" rel="noopener">https://www.coursera.org/learn/visual-perception-self-driving-cars</a></p><h2 id="Feedforward-Neural-Networks"><a href="#Feedforward-Neural-Networks" class="headerlink" title="Feedforward Neural Networks"></a>Feedforward Neural Networks</h2><h3 id="Feed-Forward-Neural-Networks"><a href="#Feed-Forward-Neural-Networks" class="headerlink" title="Feed Forward Neural Networks"></a>Feed Forward Neural Networks</h3><p>A Feedforward Neural Network defines a mapping from input x to output y as: $y=f(x;0)$</p><ul><li>We define:<ul><li>$x$ is called the input layer</li><li>The final function $f^{(N)}$ is called the output layer</li><li>The functions $f^{(1)}$ to $f^{(N-1)}$ are called the hidden layers</li></ul></li><li>Functions to estimate:<ul><li>Object Classification: Image → Label</li><li>Object Detection: Image → Label+Location</li><li>Depth Estimation: Image → Depth for every pixel</li><li>Semantic Segmentation: Image → Label for every pixel</li></ul></li><li>Mode Of Action Of Neural Networks<ul><li>Training: Give neural network examples of $f^*(x)$.<br>for a wide variation of the input $x$. Then, optimize its parameters $0$ to force $f(x;0) \approx f^\ast(x)$</li><li>Pairs of $x$ and $f^*(x)$ are called training data</li><li>Only output is specified by training data! Network is free to do anything with its hidden layers</li></ul></li><li>Hidden Units: $h_n = g(W^Th_{n-1} + b)$<ul><li>Activation function $g$</li><li>Input $h_{n-1}$</li><li>Weight matrix $W$</li><li>Bias $b$</li><li>Parameters $\theta$ are the weights and biases of all the layers of the network</li><li>Transformed parameters passed through activation function $g$</li></ul></li><li>The Rectified Linear Unit: ReLU<ul><li>The ReLU hidden unit is currently the default choice of activation function for Feedforward Neural Networks $g(z)=max(0, z)$ </li></ul></li></ul><h3 id="Output-Layers-and-Loss-Functions"><a href="#Output-Layers-and-Loss-Functions" class="headerlink" title="Output Layers and Loss Functions"></a>Output Layers and Loss Functions</h3><p><strong>General process of designing machine learning algorithm</strong></p><ul><li>Inference:<ul><li>a feed-forward neural network takes an input $x$, passes it through a sequence of hidden layers, then passes the output of the hidden layers through an output layer.</li></ul></li><li>Training:<ul><li>pass the predicted output through the loss function, then use an optimization procedure to produce a new set of parameters data that provide a lower value for the loss function.</li></ul></li><li>Tasks in self-driving: Classification and Regression<ul><li>Classification: Given input x map it to one of k classes or categories.<ul><li>Image classification, semantic segmentation</li></ul></li><li>Regression: Given input x map it to a real number:<ul><li>Depth prediction, bounding box estimation</li></ul></li></ul></li></ul><p><strong>Loss functions in different tasks</strong></p><ul><li>Classification: Softmax Output Layers<ul><li>Softmax output layers are most often used as the output of a classifier, to represent the probability distribution over K different classes</li><li>The Softmax output layer is comprised of:<ul><li>A linear transformation: $z=W^Th+b$</li></ul></li><li>Followed by the Softmax function: $$Softmax(z_i)= \frac{exp(z_i)}{\sum_j exp(z_j)}$$</li></ul></li><li>Classification: Cross-Entropy Loss Function<ul><li>By considering the output of the softmax output layer as aprobability distribution, the Cross Entropy Loss function is derived using maximum likelihood as: $$L(\theta) = -log(softmax(z_i)) = -z_i + log\sum_j exp(z_j) $$</li><li>The Cross-Entropy Loss has two terms to control how close the output of the network is to the true probability:<ul><li>$Z_i$ is the output of the hidden layer corresponding to the true class before being passed through the softmax function. This is usually called the class logit which comes from the field of logistic regression. The negative of the class logit $z_i$ encourages the network to output a large value for the probability of the correct class. </li><li>The second term on the other hand, encourages the output of the affine transformation to be small</li></ul></li></ul></li><li>Regression: Linear Output Layers<ul><li>Linear Output Units are based only on an affine transformation with no non-linearity: $z=W^Th+b$</li><li>Linear Output Units are usually used with the Mean Squared Error loss function to model the mean of a probability distribution: $$L(\theta) = \sum_i (z_i - f^*(x_i))^2$$</li></ul></li></ul><h3 id="Neural-Network-Training-with-Gradient-Descent"><a href="#Neural-Network-Training-with-Gradient-Descent" class="headerlink" title="Neural Network Training with Gradient Descent"></a>Neural Network Training with Gradient Descent</h3><p>Neural Network Loss Functions</p><ul><li>Thousands of training example pairs $[x,f^*(x)]$</li><li>The Loss function computed over all $N$ training examples is termed the Training Loss and can be written as: $J(\theta) = \frac 1N \sum^N_{i=1} L[f(x_i,\theta), f^*(x_i)]$</li><li>The gradient of the training loss with respect to the parameters $\theta$ can be written as: $$\nabla_\theta J(\theta) = \nabla_\theta [\frac 1N \sum^N_{i=1} L[f(x_i, \theta), f^*(x_i)]] = \frac 1N \sum^N_{i=1} \nabla_\theta L[f(x_i, \theta), f^\ast(x_i)] $$</li></ul><p>Batch Gradient Descent:</p><ul><li>Batch Gradient Descent is an iterative first order optimization procedure</li><li>Iterative means that it starts from an initial guess of parameters theta and improves on these parameters iteratively. </li><li>First order means that the algorithm only uses the first order derivative to improve the parameters theta. </li><li>Batch Gradient Descent Algorithm: <ul><li>Initialize parameters $\theta$</li><li>While Stopping Condition is Not Met:<ul><li>Compute gradient of loss function over all training examples using the above training loss</li><li>Update parameters according to: $\theta \leftarrow \theta - \epsilon \nabla_\theta J(\theta)$</li><li>$\epsilon$ is called the learning rate and controls how much we adjust the parameters in the direction of the negative gradient at every iteration.</li></ul></li></ul></li><li>Backpropagation used to compute $\nabla_{\theta}J(\theta)$ is very expensive to compute over the whole training dataset.<ul><li>Luckily, the lose function as well as its gradient are means over the training dataset</li><li>Standard error of the mean estimated from N samples is $\frac {\sigma}{\sqrt N}$, where $\sigma$ is the standard deviation of the value of the samples</li><li>Using all samples to estimate the gradient results in less than linear return in accuracy of this estimate</li><li>Use a small subsample (Minibatch) of the training data to estimate the gradient</li></ul></li><li>The Stochastic (minibatch) Gradient Descent just alterate at the sampling step.</li><li>Choose of Minibatch Size: <ul><li>GPUs work better with powers of 2 batch sizes</li><li>Large batch sizes &gt; 256: <ul><li>Hardware underutilized with very small batch sizes.</li><li>More accurate estimate of the gradient, but with less than linear returns</li></ul></li><li>Small batch size &lt; 64<ul><li>Small batches can offer a regularizing effect.The best generalization error is often achieved with batch size of 1.</li><li>Small batch sizes allow for faster convergence, as the algorithm can compute the parameter updates rapidly</li></ul></li><li>As a result of these trade-offs, typical power of two mini batch sizes range from 32 to 256, with smaller sizes sometimes being attempted for large models or to improve generalization.</li><li>Always make sure dataset is shuffled before sampling minibatch</li></ul></li></ul><p>Parameter Initialization and Stopping Conditions</p><ul><li>Parameter Initialization: <ul><li>Weights: initialized by randomly sampling from a standard normal distribution </li><li>Biases: initialized to 0</li><li>Other heuristics exist</li></ul></li><li>Stopping Conditions:<ul><li>Number of iterations: How many training iterations the neural network has performed</li><li>Change $ln \theta$ value: Stop if $\theta_{new} - \theta_{old}$ &lt; Threshold</li><li>Change $ln J(\theta)$ value: Stop if $J(\theta_{new})-J(\theta_{old})$ &lt; Threshold</li></ul></li></ul><p>SGD Variations</p><ul><li>Many variations of SGD exist<ul><li>Momentum SGD, Nestrove Momentum SGD </li><li>Ada-Grad, RMS-Prop </li><li>ADAM (Adaptive Moment Estimation)</li></ul></li><li>Which one to use?<ul><li>ADAM: Implemented in most deep neural network libraries, fairly robust to the choice of the learning rate and other hyperparameters</li></ul></li></ul><h3 id="Data-Splits-and-Neural-Network-Performance-Evaluation"><a href="#Data-Splits-and-Neural-Network-Performance-Evaluation" class="headerlink" title="Data Splits and Neural Network Performance Evaluation"></a>Data Splits and Neural Network Performance Evaluation</h3><ul><li>Data splits:<ul><li>training: used to minimize the Loss Function</li><li>validation: used to choose best hyperparameters, such as the learning rate, number of layers, etc.</li><li>testing: the neural network never observes this set. The developer never uses this set in the design process</li></ul></li><li>Percentage of split:<ul><li>total sample size is ~10000: training 60%, validation 20%, testing 20%</li><li>total sample size is ~1000000: training 98%, validation 1%, testing 1%</li></ul></li><li>Behavior of Split Specific Loss Functions:<ul><li>overfitting, underfitting</li><li>The gap between training and validation loss is called the generalization gap</li></ul></li><li>Reducing the Effect of Underfitting/Overfitting<ul><li>Underfitting: (Training loss is high)<ul><li>Train longer</li><li>More layers or more parameters per layer</li><li>Change architecture</li></ul></li><li>Overfitting: (Generalization gap is large)<ul><li>More training data</li><li>Regularization</li><li>Change architecture</li></ul></li></ul></li></ul><h3 id="Neural-Network-Regularization"><a href="#Neural-Network-Regularization" class="headerlink" title="Neural Network Regularization"></a>Neural Network Regularization</h3><p>Remedy overfitting through various regularization strategies:</p><ul><li>Parameter norm penalties<ul><li>$J(\theta)_{reg} = J(\theta) + \alpha \Omega(\theta)$ </li><li>limits the capacity of the model by adding the penalty $\omega$ of $\theta$ to the objective function. </li><li>$\alpha$ is a hyperparameter that weights the relative contribution of the norm penalty to the value of the loss function</li><li>$\Omega(\theta)$ is a measure of how large $\theta$’s value is, usually an $L_p$ Norm. </li><li>We usually only constrain the size of weights and not biases: $J(\theta)_{reg} = J(\theta) + \alpha \Omega(W)$ </li><li>The most common norm penalty used in neural networks is the L2-norm penalty: $\Omega(W) = \frac 12 W^TW = \frac 12 |W|^2_2$</li></ul></li><li>Dropout<ul><li>The first step of dropout is to choose a probability which we’ll call $P_{keep}$.</li><li>At every training iteration, this probability is used to choose a subset of the network nodes to keep in the network. These nodes can be either hidden units, output units, or input units.</li><li>We then proceed to evaluate the output y after cutting all the connections coming out of this unit. </li><li>Since we are removing units proportional to the keep probably, $P_{keep}$, we multiply the final weights by $P_{keep}$ at the ending of training. This is essential to avoid incorrectly scaling the outputs when we switch to inference for the full network.</li><li>Computationally inexpensive but powerful regularization method</li><li>Does not significantly limit the type of model or training procedure that can be used. Works well with nearly any model that uses a distributed over parameterized representation, and that can be trained with stochastic gradient descent</li><li>Dropout layers are practically implemented in all neural network libraries.</li></ul></li><li>Early Stopping<ul><li>Early stopping ends training when the validation loss keeps increasing for a preset number of iterations or epochs.</li><li>Early stopping should not be use as a first choice for regularization. As it also limits the training time, which may interfere with the overall network performance.</li></ul></li></ul><h3 id="Convolutional-Neural-Networks"><a href="#Convolutional-Neural-Networks" class="headerlink" title="Convolutional Neural Networks"></a>Convolutional Neural Networks</h3><p><strong>ConvNets</strong></p><ul><li>Used for processing data defined on grid</li><li>1Dtime series data,2D images,3D videos</li><li>Two major type of layers:<ul><li>Convolution Layers</li><li>Pooling Layers</li></ul></li><li>Cross-correlation:<ul><li>The vertical and horizontal shifts are usually the same value, referred as the stride of our convolutional layer. </li></ul></li><li>Output Volume Shape<ul><li>Filters are size mxm</li><li>Number of filters = K</li><li>Stride = S, Padding = P</li><li>the expression for width: $W_{out} = \frac{W_{in}-m+2*P}{S} +1$</li><li>the expression for height: $H_{out} = \frac{H_{in}-m+2*P}{S} +1$</li><li>the expression for depth: $D_{out} = K$</li></ul></li></ul><p><strong>Pooling</strong></p><ul><li>A pooling layer uses pooling functions to replace the output of the previous layer with a summary statistic of the nearby outputs. </li><li>Pooling helps make the representations become invariant to small translations of the input. </li><li>Max pooling:<ul><li>Max pooling summarizes output volume patches with the max function.</li><li>Output Volume Shape<ul><li>Pool size nxn</li><li>Stride = S</li><li>$W_{out} = \frac{W_{in}-n}{S} +1$</li><li>$H_{out} = \frac{H_{in}-n}{S} +1$</li><li>$D_{out} = D_{in}$</li></ul></li></ul></li><li>Advantages of ConvNets<ul><li>Convolutional neural networks are by design, a natural choice to process images</li><li>Convolutional layers have <em>less parameters</em> than fully connected layers, reducing the chances of overfitting</li><li>Convolutional layers use the same parameters to process every block of the image. Along with pooling layers, this leads to <em>translation invariance</em>, which is particularly important for image understanding</li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;From Coursera, State Estimation and Localization for Self-Driving Cars by University of Toronto&lt;br&gt;&lt;a href=&quot;https://www.coursera.org/lear
      
    
    </summary>
    
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
      <category term="Self-driving" scheme="http://tracyxinwang.site/blog/tags/Self-driving/"/>
    
  </entry>
  
  <entry>
    <title>Coursera Visual Perception for Self-Driving Cars 02</title>
    <link href="http://tracyxinwang.site/blog/2019/08/06/coursera_visual_percep02/"/>
    <id>http://tracyxinwang.site/blog/2019/08/06/coursera_visual_percep02/</id>
    <published>2019-08-06T13:30:23.000Z</published>
    <updated>2019-08-09T02:02:58.645Z</updated>
    
    <content type="html"><![CDATA[<p>From Coursera, State Estimation and Localization for Self-Driving Cars by University of Toronto<br><a href="https://www.coursera.org/learn/visual-perception-self-driving-cars" target="_blank" rel="noopener">https://www.coursera.org/learn/visual-perception-self-driving-cars</a></p><h2 id="Visual-Features-Detection-Description-and-Matching"><a href="#Visual-Features-Detection-Description-and-Matching" class="headerlink" title="Visual Features - Detection, Description and Matching"></a>Visual Features - Detection, Description and Matching</h2><h3 id="Introduction-to-Image-features-and-Feature-Detectors"><a href="#Introduction-to-Image-features-and-Feature-Detectors" class="headerlink" title="Introduction to Image features and Feature Detectors"></a>Introduction to Image features and Feature Detectors</h3><h3 id="Introduction-to-feature-detecors"><a href="#Introduction-to-feature-detecors" class="headerlink" title="Introduction to feature detecors"></a>Introduction to feature detecors</h3><p><strong>Feature extraction</strong></p><ul><li>Application: image stitching<ul><li>given two images from two different cameras, we would like to stitch them together to form a panorama. </li><li>First, we need to identify distinctive points in our images. We call this point image features. </li><li>Second, we associate a descriptor for each feature from its neighborhood. </li><li>Finally, we use these descriptors to match features across two or more images. </li></ul></li><li>Features are points of interest in an image</li><li>Points of interest should have the following characteristics: <ul><li>Saliency: distinctive, identifiable,and different from its immediate neighborhood </li><li>Repeatability: can be found in multiple images using same operations </li><li>Locality: occupies a relatively small subset of image space </li><li>Quantity: enough points represented In the image</li><li>Efficiency: reasonable computation time</li></ul></li><li>How to choose the points of interest:<ul><li>Repetitive texture less patches are challenging to detect consistently</li><li>Patches with large contrast changes (gradients) are easier to detect(edges)</li><li>Gradients in at least two(significantly) different orientations are the easiest to detect(corners)</li><li>The most famous corner detector is the Harris Corner Detector, which uses image gradient information to identify pixels that have a strong change in intensity in both x and y directions.</li></ul></li></ul><p><strong>Algorithms used</strong></p><ul><li>Harris[corners]: Easy to compute, but not scale invariant.<ul><li>meaning that the corners can look different depending on the distance the camera is away from the object generating the corner. </li></ul></li><li>Harris-Laplace[corners]: Same procedure as Harris detector, addition of scale selection based on Laplacian. Scale invariance.</li><li>Features from accelerated segment test(FAST) (corners): Machine learning approach for fast corner detection.<ul><li>high computational efficiency and solid detection performance</li></ul></li><li>Laplacian of Gaussian(LOG) detector[blobs]: Uses the concept of scale space in a large neighborhood(blob). Somewhat scale invariant.</li><li>Difference of Gaussian(DOG) detector[blobs]: Approximates LOG but is faster to compute</li></ul><h3 id="Feature-Descriptors"><a href="#Feature-Descriptors" class="headerlink" title="Feature Descriptors"></a>Feature Descriptors</h3><p><strong>Feature descriptor definition</strong></p><ul><li>Feature: Point of interest in an image defined by its image pixel coordinates [u,v]</li><li>Descriptor f: an n dimensional vector associated with each feature.<ul><li>The descriptor has the task of providing a summary of the image information in the vicinity of the feature itself, and can take on many forms. </li></ul></li><li>Feature descriptors should have the following characteristics:      <ul><li>Repeatability: manifested as robustness and invariance to translation, rotation,scale, and illumination changes</li><li>Distinctiveness: should allow us to distinguish between two close by features,very important for matching later on</li><li>Compactness &amp; Efficiency: reasonable computation time</li></ul></li><li>Designing Invariant Descriptors: SIFT<ul><li>Scale Invariant Feature Transform (SIFT)descriptors</li><li>Given a feature in the image, the shift descriptor takes a 16 by 16 window of pixels around it, we call this window the features local neighborhood.</li><li>then separate this window in to four 4 by 4 cells such that each cell contains 16 pixels.</li><li>Next we compute the edges and edge orientation of each pixel in each cell using the gradient filters.</li><li>For stability of the descriptor, we suppress weak edges using a predefined threshold as they are likely to vary significantly in orientation with small amounts of noise between images.</li><li>Finally, we compute a 32 dimensional histogram of orientations for each cell. And concatenate the histograms for all four cells to get a final 128 dimensional histogram for the feature at hand, we call this histogram or descriptor. </li></ul></li><li>Scale Invariant Feature Transform<ul><li>SIFT is an example of a very well human engineered feature descriptor, and is used in many state-of-the-art systems</li><li>The above process is usually compute on rotatedand scaled version of the 16x16 window, allowing for better scale robustness</li><li>Combined with the DOG feature detector, SIFT descriptors provide a scale,rotation, and illumination invariant detector/descriptor pair.</li></ul></li></ul><p><strong>Algorithms</strong><br>Other Descriptors:</p><ul><li>Speeded-Up Robust Features (SURF)</li><li>Gradient Location-Orientation Histogram (GLOH)</li><li>Binary Robust Independent Elementary Features (BRIEF)</li><li>Oriented Fast and Rotated Brief (ORB): free to use commertially</li><li>Many more!</li></ul><h3 id="Feature-Matching"><a href="#Feature-Matching" class="headerlink" title="Feature Matching"></a>Feature Matching</h3><p><strong>Match features based on a predefined distance function</strong></p><ul><li>Feature Matching: Given a feature and its descriptor in image 1, find the best match in image 2</li><li>Define a distance function $d(f_i,f_j)$ that compares the two descriptors</li><li>For every feature $f_i$ in Image 1: <ul><li>Compute $d(f_i,f_j)$ with all features $f_j$ in image 2</li><li>Find the closest match $f_c$, the match that has the minimum distance. This feature is known as the nearest neighbor.</li><li>Keep this match only if $d(f_i,f_j)$ is below threshold $\delta$</li></ul></li><li>Distance Function<ul><li>Sum of Squared Differences (SSD)： $d(f_i, f_j) =\sum^D_{k=1} (f_{i,k} - f_{j,k})^2$</li><li>Sum of absolute differences (SAD): $d(f_i, f_j) = \sum^D_{k=1} |f_{i,k} - f_{j,k}|$</li><li>Hamming Distance: $d(f_i, f_j) = \sum^D_{k=1} XOR(f_{i,k} - f_{j,k})$</li></ul></li><li>Brute force feature matching might not be fast enough for extremely large amounts of features<ul><li>Use a multidimensional search tree, usually a k-d tree to speed the search by constraining it spatially</li><li>Both of these matchers are implemented in OpenCV as: <code>cv2.BFMatcher()</code>: Brute force matcher; <code>cv2.FlannBasedMatcher()</code>: K-D tree based approximate nearest neighbor matcher</li></ul></li></ul><h3 id="Feature-Matching-Handling-Ambiguity-in-Matching"><a href="#Feature-Matching-Handling-Ambiguity-in-Matching" class="headerlink" title="Feature Matching: Handling Ambiguity in Matching"></a>Feature Matching: Handling Ambiguity in Matching</h3><ul><li>Ambiguous matches: more than one feature points can be found to have the minimum distance when do feature matching. </li><li>The solution is to use distance ratio:<ul><li>Compute $d(f_i,f_j)$ for each feature, $f_i$, in image 1, with all features, $f_j$, in image 2</li><li>Find the closest match $f_c$</li><li>Find the second closest match $f_s$</li><li>Find how better the closest match is than the second closest match. This can be done through distance ratio: $0 \leq \frac{d(f_i,f_c)}{d(f_i,f_s)} \leq 1$</li><li>If the distance ratio is close to one, it means that according to our descriptor and distance function, fi matches both fs and fc. In this case, we don’t want to use this match in our processing later on, as it clearly is not known to our matcher which location in image two corresponds to the feature in image one.</li></ul></li><li>So the Updated Brute Force Feature Matching: <ul><li>Define a distance function $d(f_i,f_j)$ that compares the two descriptors</li><li>Define distance ratio threshold $\rho$</li><li>For every feature $f_i$ in Image 1:<ul><li>Compute $d(f_i,f_j)$ with all features $f_j$ in image 22. </li><li>Find the closest match $f_c$ and the second closest match $f_s$ </li><li>Compute the distance ratio </li><li>Keep matches with distance ratio $&lt; \rho$</li></ul></li></ul></li></ul><h3 id="Outlier-Rejection"><a href="#Outlier-Rejection" class="headerlink" title="Outlier Rejection"></a>Outlier Rejection</h3><p><strong>Three-step feature extraction framework for the real-world problem of vehicle localization</strong></p><ul><li>Localization problem is defined as follows: <ul><li>given any two images of the same scene from different perspectives, find the translation $T=[t_u, t_v]$, between the coordinate system of the first image , and the coordinate system of the second image.</li><li>also need to solve for the scale and skew due to different viewpoints. </li></ul></li><li>Matched feature pairs in images 1 and 2: <ul><li>$f^{(1)}_i, f^{(2)}_i i \in [0…N]$</li><li>$f^{(1)}_i = (u^{(1)}_i, v^{(1)}_i)$</li><li>Model: $u^{(1)}_i + t_u = u^{(2)}_i$, $v^{(1)}_i + t_v = v^{(2)}_i$</li><li>solve using least squares: $t_u = \frac 1N \sqrt{\sum_i (u^{(1)}_i - u^{(2)}_i)^2}$  $t_v = \frac 1N \sqrt{\sum_i (v^{(1)}_i - v^{(2)}_i)^2}$</li></ul></li></ul><p><strong>Outliers and ANSAC algorithm</strong></p><ul><li>Outliers can be handled using a model-based outlier rejection method called Random Sample Consensus (RANSAC)<br>RANSAC algorithm: </li><li>Initialization:<ul><li>Given a model, find the smallest number M of data points or samples needed to compute the parameters of this model. In the above case is $t_u, t_v$</li></ul></li><li>Main loop:<ul><li>Randomly select M samples from the data.</li><li>Compute the model parameters using only the M samples selected from the data set. </li><li>Use the computed parameters and count how many of the remaining data points agree with this computed solution. The accepted points are retained and referred to as inliers.</li><li>if the number of inliers C is satisfactory, or if the algorithm has iterated a pre-set maximum number of iterations, terminate and return the computed solution and the inlier set. </li><li>Else, go back to step two and repeat.</li></ul></li><li>Finally, recompute and return the model parameters from the best inlier set: The one with the largest number of features. </li></ul><h3 id="Visual-Odometry"><a href="#Visual-Odometry" class="headerlink" title="Visual Odometry"></a>Visual Odometry</h3><p>Visual Odometry(VO): is the process of incrementally estimating the pose of the vehicle by examining the changes that motion induces on the images of its onboard cameras</p><ul><li>VO Pros:<ul><li>Not affected by wheel slip in uneven terrain, rainy/snowy weather, or other adverse conditions.</li><li>More accurate trajectory estimates compared to wheel odometry.</li></ul></li><li>VO Cons:<ul><li>Usually need an external sensor to estimate absolute scale</li><li>Camera is a passive sensor,might not be very robust against weather conditions and illumination changes</li><li>Any form of odometry (incremental state estimation) drifts over time</li></ul></li><li>Problem Formulation:<ul><li>Estimate the camera motion $T_k$ between consecutive images $l_{k-1}$ and $l_k$</li><li>Concatenating these single movements allows the recovery of the full trajectory of the camera, given frames $C_1, …, C_m$</li></ul></li><li>General process of visual odometry:<ul><li>Given: two consecutive image frames $I_{k-1}$ and $I_k$</li><li>First, perform feature detection and description. We end up with a set of features $f_{k-1}$ in image k-1 and $f_k$ in image of k. </li><li>We then proceed to match the features between the two frames to find the ones occurring in both of our target frames.</li><li>After that, we use the matched features to estimate the motion between the two camera frames represented by the transformation $T_k$.</li></ul></li><li>Motion estimation:<ul><li>depends on what type of feature representation we have:<ul><li>2D-2D: both $f_{k-1}$ and $f_k$ are defined in Image coordinates</li><li>3D-3D: both  $f_{k-1}$ and $f_k$ are specified in 3D</li><li>3D-2D: $f_{k-1}$ is specified in 3D and $f_k$ are their corresponding projection on 2D</li></ul></li></ul></li><li>Perspective N Point (PNP)<ul><li>Given feature locations in 3D, their corresponding projection in 2D, and the camera intrinsic calibration matrix k,</li><li>Solve for initial guess of [R|t] using Direct Linear Transform(DLT): Forms a linear model and solves for [R|t], with methods such as singular value decomposition(SVD)</li><li>Improve solution using Levenberg-Marquardt algorithm(LM)</li><li>Need at least 3 points to solve(P3P), 4 if we don’t wantambiguous solutions.</li><li>Finally, RANSAC can be incorporated into PnP by assuming that the transformation generated by PnP on four points is our model. </li><li>We then choose a subset of all feature matches to evaluate this model and check the percentage of inliers that result to confirm the validity of the point matches selected. </li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;From Coursera, State Estimation and Localization for Self-Driving Cars by University of Toronto&lt;br&gt;&lt;a href=&quot;https://www.coursera.org/lear
      
    
    </summary>
    
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
      <category term="Self-driving" scheme="http://tracyxinwang.site/blog/tags/Self-driving/"/>
    
  </entry>
  
  <entry>
    <title>Coursera Visual Perception for Self-Driving Cars 01</title>
    <link href="http://tracyxinwang.site/blog/2019/08/01/coursera_visual_percep01/"/>
    <id>http://tracyxinwang.site/blog/2019/08/01/coursera_visual_percep01/</id>
    <published>2019-08-01T13:30:23.000Z</published>
    <updated>2019-08-09T02:04:39.048Z</updated>
    
    <content type="html"><![CDATA[<p>From Coursera, State Estimation and Localization for Self-Driving Cars by University of Toronto<br><a href="https://www.coursera.org/learn/visual-perception-self-driving-cars" target="_blank" rel="noopener">https://www.coursera.org/learn/visual-perception-self-driving-cars</a></p><h2 id="Basics-of-3D-Computer-Vision"><a href="#Basics-of-3D-Computer-Vision" class="headerlink" title="Basics of 3D Computer Vision"></a>Basics of 3D Computer Vision</h2><h3 id="The-Camera-Sensor"><a href="#The-Camera-Sensor" class="headerlink" title="The Camera Sensor"></a>The Camera Sensor</h3><p>Pinhole Camera Model:</p><ul><li>focal length: the distance between the pinhole and the image plane. It defines the size of the object projected onto the image </li><li>camera center: The coordinates of the center of the pinhole. These coordinates defined the location on the imaging sensor that the object projection will inhabit. </li></ul><h3 id="Camera-Projective-Geometry"><a href="#Camera-Projective-Geometry" class="headerlink" title="Camera Projective Geometry"></a>Camera Projective Geometry</h3><p>Let’s define the problem we need to solve: a point $O_{world}$ defined at a particular location in the world coordinate frame. We want to project this point from the world frame to the camera image plane. </p><ul><li>Light travels from the $O_{world}$ on the object through the camera aperture to the sensor surface. </li><li>The projection onto the sensor surface through the aperture results in flipped images of the objects in the world.</li><li>need to develop a model for how to project a point from the world frame coordinates x, y and z to, image coordinates u and v:<ul><li>First, select a <em>world frame</em> in which to define the coordinates of all objects and the camera.</li><li>define the <em>camera coordinate frame</em> as the coordinate frame attached to the center of our lens aperture known as the optical sensor.</li><li>We refer to the parameters of the camera pose as the extrinsic parameters, as they are external to the camera and specific to the location of the camera in the world coordinate frame. </li><li>define <em>image coordinate frame</em> as the coordinate frame attached to our virtual image plane emanating from the optical center. The image pixel coordinate system is attached to the top <em>left corner</em> of the virtual image plane.</li><li>So we need to adjust the pixel locations to the image coordinate frame.</li><li>we define the focal length is the distance between the camera and the image coordinate frames along the z-axis of the camera coordinate frame.</li></ul></li><li>Finally, the projection problem reduces to two steps. <ul><li>We first need to project from the world to the camera coordinates, then we project from the camera coordinates to the image coordinates.</li><li>We can then transform image coordinates to pixel coordinates through scaling and offset.</li></ul></li><li>Computing the projection:<ul><li>World -&gt; Camera: $$o_{camera} = [R|t]O_{world}$$</li><li>Camera -&gt; Image: $$o_{image} = [f \; 0 \; u_0 ; 0 \; f \; v_0 ; 0 \; 0 \; 1]o_{camera} = Ko_{camera}$$<ul><li>K is a 3x3 matrix, which depends on camera intrinsic parameters: camera geometry and the camera lens characteristics</li></ul></li><li>World -&gt; Image: $$P = K[R|t]$$</li><li>therefore, $o_{image} = PO = K[R|t]O_{world}$</li></ul></li><li>Image coordinates to Pixel coordinates: $[x y z]^T -&gt; [u v 1]^T = \frac 1z[x y z]^T$</li></ul><p>The digital image:</p><ul><li>an image is represented digitally as an M by N by three array of pixels, with each pixel representing the projection of a 3D point onto the 2D image plane. </li></ul><h3 id="Camera-Calibration"><a href="#Camera-Calibration" class="headerlink" title="Camera Calibration"></a>Camera Calibration</h3><p>The camera calibration problem is defined as finding these unknown intrinsic and extrinsic camera parameters, given n known 3D point coordinates and their corresponding projection to the image plane.</p><ul><li>Our approach will comprise of getting the P matrix first and then decomposing it into the intrinsic parameters K and the extrinsic rotation parameters R and translation parameters t. </li><li>Use scenes with known geometry to:<ul><li>Correspond 2D image coordinates to 3D world coordinates</li><li>Find the Least Squares Solution (or non-linear solution)of the parameters of P</li></ul></li><li>The most commonly used example would be a 3D checkerboard, with squares of known size providing a map of fixed point locations to observe. </li><li>If we have N 3D points and their corresponding N 2D projections, set up homogeneous linear system<ul><li>Solved with Singular Value Decomposition(SVD)</li></ul></li></ul><h3 id="Visual-Depth-Perception-Stereopsis"><a href="#Visual-Depth-Perception-Stereopsis" class="headerlink" title="Visual Depth Perception - Stereopsis"></a>Visual Depth Perception - Stereopsis</h3><p><strong>Stereo Camera Model</strong></p><ul><li>A stereo sensor is usually created by two cameras with parallel optical axes.</li><li>Given a known rotation and translation between the two cameras and a known projection of a point $O$ in 3D to the two camera frames resulting in pixel locations $O_L$ and $O_R$ respectively, we can formulate the necessary equations to compute the 3D coordinates of the point $O$.</li><li>Assumptions:<ul><li>First, we assume that the two cameras used to construct the stereo sensors are identical. </li><li>Second, we will assume that while manufacturing the stereo sensor, we tried as hard as possible to keep the two cameras optical axes aligned.</li><li>project the previous figure to bird’s eye view for easier visualization. </li></ul></li><li>Some parameters:<ul><li>focal length: the distance between the camera center and the image plane.</li><li>the baseline is defined as the distance along the shared x-axis between the left and right camera centers. </li><li>By defining a baseline to represent the transformation between the two camera coordinate frames, we are assuming that the rotation matrix is identity and there is only a non-zero x component in the translation vector. The $[R|t]$ transformation therefore boils down to a single baseline parameter B.</li></ul></li><li>Define the quantities to compute:<ul><li>to compute the x and z coordinates of the point $O$ with respect to the left camera frame.</li><li>The y coordinate can be estimated easily after the x and z coordinates are computed. </li><li>by constructing the similarity, we get $\frac Zf = \frac X{x_L}$ and $\frac Zf = \frac {X-b}{x_R}$</li><li>finally we can get: $X=\frac{zx_L}{f}$, $Y=\frac{zy_L}{f}$</li></ul></li></ul><p><strong>Derive the location of a point in 3D</strong></p><ul><li>Two main problems: <ul><li>We need to know $f,b,u_o,v_o$: Use stereo camera calibration </li><li>We need to find corresponding $x_R$ for each $x_L$: Use disparity computation algorithms</li></ul></li></ul><h3 id="Visual-Depth-Perception-Computing-the-Disparity"><a href="#Visual-Depth-Perception-Computing-the-Disparity" class="headerlink" title="Visual Depth Perception - Computing the Disparity"></a>Visual Depth Perception - Computing the Disparity</h3><p>Disparity: The difference in image location of the same 3D point under perspective to two different cameras</p><ul><li>Correspond pixels in the left image to those in the right image to find matches</li></ul><p><strong>Estimate the disparity through stereo matching</strong></p><ul><li>if moving our 3D point along the line connecting it with the left cameras center. <ul><li>Its projection on the left camera image plane does not change. But for the projection on the right camera plane, the projection moves along the horizontal line. </li><li>This is called an epipolar line and follows directly from the fixed lateral offset and image plane alignment of the two cameras in a stereo pair. We can constrain our correspondence search to be along the epipolar line, reducing the search from 2D to 1D.</li><li>One thing to note is that horizontal epipolar lines only occur if the optical axes of the two cameras are parallel. </li><li>In the case of non parallel optical axis, the epipolar lines are skewed.</li><li>We can use <em>stereo rectification</em> to warpimages originating from two cameras with non-parallel optical axes to force epipolar lines to be horizontal.</li></ul></li><li>A Basic Stereo Algorithm <ul><li>Given: Rectified Images and Stereo Calibration.</li><li>For each epipolar line take a pixel on this line in the left image, compare these left image pixels to every pixel in the right image on the same epipolar line.</li><li>select the right image pixel that matches the left pixel the most closely which can be done by minimizing the cost. </li><li>a very simple cost can be the squared difference in pixel intensities.</li><li>Finally, we can compute the disparity by subtracting the right image location from the left one.</li></ul></li></ul><h3 id="Image-filtering"><a href="#Image-filtering" class="headerlink" title="Image filtering"></a>Image filtering</h3><p><strong>Cross correlation</strong></p><ul><li>The idea to reduce salt-pepper noise is to compute the mean of the whole neighborhood, and replace the outlier pixel with this mean value: $$G[u,v] = \frac 1{(2k+1)^2} \sum^k_{i=-k} \sum^k_{j=-k} I[u-i, v-j]$$ <ul><li>where (2k+1) is the filter size, (u,v) is the center pixel coordinates</li></ul></li><li>The mean equation can be generalized by adding a weight to every pixel in the neighborhood, resulting in cross-correlation. The weight matrix H is called a kernel. <ul><li>Kernal could be: mean filter, gaussian filter</li></ul></li><li>Application：<ul><li>Template matching: The pixel with the highest response from Cross-correlation is the location of the template in an image</li><li>Image gradient computation: Define a finite difference kernel,and apply it to the image to get the image gradient</li></ul></li></ul><p><strong>Convolution</strong></p><ul><li>A convolution is a cross-correlation where the filter is flipped both horizontally and vertically before being applied to the image</li><li>Unlike Cross-Correlation, Convolution is associative. If H and F are filter kernels then: $H<em>(F</em>I) = (H<em>F)</em>I$</li><li>Precompute filter convolutions(H*F)then apply it once to the image to reduce runtime.</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;From Coursera, State Estimation and Localization for Self-Driving Cars by University of Toronto&lt;br&gt;&lt;a href=&quot;https://www.coursera.org/lear
      
    
    </summary>
    
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
      <category term="Self-driving" scheme="http://tracyxinwang.site/blog/tags/Self-driving/"/>
    
  </entry>
  
  <entry>
    <title>Coursera State Estimation and Localization for Self-Driving Cars 05</title>
    <link href="http://tracyxinwang.site/blog/2019/08/01/coursera_state_est05/"/>
    <id>http://tracyxinwang.site/blog/2019/08/01/coursera_state_est05/</id>
    <published>2019-08-01T08:57:23.000Z</published>
    <updated>2019-08-09T02:20:44.787Z</updated>
    
    <content type="html"><![CDATA[<p>From Coursera, State Estimation and Localization for Self-Driving Cars by University of Toronto<br><a href="https://www.coursera.org/learn/state-estimation-localization-self-driving-cars" target="_blank" rel="noopener">https://www.coursera.org/learn/state-estimation-localization-self-driving-cars</a></p><h2 id="An-Autonomous-Vehicle-State-Estimator"><a href="#An-Autonomous-Vehicle-State-Estimator" class="headerlink" title="An Autonomous Vehicle State Estimator"></a>An Autonomous Vehicle State Estimator</h2><h3 id="State-Estimation-in-Practice"><a href="#State-Estimation-in-Practice" class="headerlink" title="State Estimation in Practice"></a>State Estimation in Practice</h3><p>Accuracy Requirements</p><ul><li>How accurate does the estimator need to be for safe self-driving?</li><li>Typically less than a meter for highway lane keeping</li><li>Less for driving in dense trafic</li><li>GPS accuracy is 1-5 meters in optimal conditions</li><li>Need additional sensors!</li></ul><p>Speed Requirements</p><ul><li>How fast do we need to update the vehicle state to ensure safe driving?</li><li>How much computation power does the vehicle have on-board?</li><li>How much power can our computing resources consume?</li></ul><p>Localization Failures</p><ul><li>How can localization fail?</li><li>Sensors fail or provide bad data (e.g., GPS in a tunnel)</li><li>Estimation error (e.g, linearization error in the EKF)</li><li>Large state uncertainty (e.g, relying on IMU for too long)</li></ul><h3 id="Multisensor-Fusion-for-State-Estimation"><a href="#Multisensor-Fusion-for-State-Estimation" class="headerlink" title="Multisensor Fusion for State Estimation"></a>Multisensor Fusion for State Estimation</h3><p>Develop an error state extended Kalman Filter for estimating position, velocity and orientation using an IMU, GNSS sensor, and LIDAR.</p><p><strong>Why use GNSS with IMU &amp; LIDAR?</strong></p><ul><li>Eror dynamics are completely different and uncorrelated</li><li>IMU provides ‘smoothing’ of GNSS, fill-in during outages due to jamming or maneuvering</li><li>Wheel odometry is also possible (if only 20 position orientation is desired)· </li><li>GNSS provides absolute positioning information to mitigate IMU drift</li><li>LIDAR provides accurate local positioning within known maps</li></ul><p><strong>Types of EKF coupling</strong></p><ul><li>Tightly coupling:<ul><li>use the raw pseudo range and point cloud measurements from our GNSS and LIDAR as observations</li><li>GNSS/LIDAR Measurement: Pseudo-ranges to satellites LIDAR point clouds</li><li>Accuracy: potentially Higher</li><li>Complexity: Higher</li></ul></li><li>Loosely<ul><li>assume data has already been preprocessed to produce a noisy position estimate</li><li>GNSS/LIDAR Measurement: Position</li><li>Accuracy: potentially lower</li><li>Complexity: Lower</li></ul></li></ul><p><strong>EKF - IMU+GNSS+LIDAR</strong></p><ul><li>use the IMU measurements as noisy inputs to the motion model. This will give us our predicted state, which will update every time we have an IMU measurement. This can happen hundreds of times a second.</li><li>Then we incorporate GNSS and LIDAR measurements whenever they become available(at a much slower rate,  say once a second or slower), and use them to correct our predicted state</li></ul><p><img src="/blog/images/state_est07.jpg" width="80%" height="80%"></p><ul><li>What is state?<ul><li>we’ll use a 10-dimensional state vector that includes a 3D position, a 3D velocity, and a 4D unit quaternion that will represent the orientation of our vehicle with respect to a navigation frame. $$x_k=[p_k \; v_k \; q_k]^T \in R^{10}$$</li><li>assume that IMU output specific forces and rotational rates in the sensor frame, and combine them into a single input vector u. - note that we’re not going to track accelerometer or gyroscope biases. These are often put into the state vector, estimated, and then subtracted off of the IMU measurements. For clarity, we’ll emit them here and assume our IMU measurements are unbiased.</li><li>therefore, the motion model input will consist of specific force and rotational rates from IMU: $$u_k = [f_k \; \omega_k]^T \in R^6$$</li></ul></li><li>Loop<ul><li>Update state with IMU inputs</li><li>Propagate uncertainty</li><li>If GNSS or LIDAR position available:<ul><li><ol><li>Compute Kalman gain</li></ol></li><li><ol start="2"><li>Compute error state</li></ol></li><li><ol start="3"><li>Correct predicted state</li></ol></li><li><ol start="4"><li>Computed orrected covariance</li></ol></li></ul></li></ul></li></ul><h3 id="Sensor-Calibration-A-Necessary-Evil"><a href="#Sensor-Calibration-A-Necessary-Evil" class="headerlink" title="Sensor Calibration - A Necessary Evil"></a>Sensor Calibration - A Necessary Evil</h3><p><strong>Intrinsic Calibration</strong></p><ul><li>deals with sensors specific parameters</li><li>ways to get the parameters:<ul><li>Manufacturer specifications</li><li>Measure by hand</li><li>Estimate as part of the state</li></ul></li></ul><p><strong>Extrinsic Calibration</strong> </p><ul><li>deals with how the sensors are positioned and oriented on the vehicle</li></ul><p><strong>Temporal Calibration</strong></p><ul><li>deals with the time offset between different sensor measurements</li><li>ways to deal with<ul><li>Assume zero</li><li>Hardware synchronization</li><li>Estimate as part of the state</li></ul></li></ul><h3 id="Loss-of-One-or-More-Sensors"><a href="#Loss-of-One-or-More-Sensors" class="headerlink" title="Loss of One or More Sensors"></a>Loss of One or More Sensors</h3>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;From Coursera, State Estimation and Localization for Self-Driving Cars by University of Toronto&lt;br&gt;&lt;a href=&quot;https://www.coursera.org/lear
      
    
    </summary>
    
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
      <category term="Self-driving" scheme="http://tracyxinwang.site/blog/tags/Self-driving/"/>
    
  </entry>
  
  <entry>
    <title>Coursera State Estimation and Localization for Self-Driving Cars 04</title>
    <link href="http://tracyxinwang.site/blog/2019/07/31/coursera_state_est04/"/>
    <id>http://tracyxinwang.site/blog/2019/07/31/coursera_state_est04/</id>
    <published>2019-07-31T08:57:23.000Z</published>
    <updated>2019-08-09T02:30:19.703Z</updated>
    
    <content type="html"><![CDATA[<p>From Coursera, State Estimation and Localization for Self-Driving Cars by University of Toronto<br><a href="https://www.coursera.org/learn/state-estimation-localization-self-driving-cars" target="_blank" rel="noopener">https://www.coursera.org/learn/state-estimation-localization-self-driving-cars</a></p><h2 id="LIDAR-Sensing"><a href="#LIDAR-Sensing" class="headerlink" title="LIDAR Sensing"></a>LIDAR Sensing</h2><h3 id="Light-Detection-and-Ranging-Sensors"><a href="#Light-Detection-and-Ranging-Sensors" class="headerlink" title="Light Detection and Ranging Sensors"></a>Light Detection and Ranging Sensors</h3><p><strong>The operating principles of LIDAR sensors</strong></p><ul><li>For a basic LIDAR in one dimension, it has three components: a laser, a photodetector, and a very precise stopwatch. </li><li>The laser first emits a short pulse of light usually in the near infrared frequency band along some known ray direction. At the same time, the stopwatch begins counting. The laser pulse travels outwards from the sensor at the speed of light and hits a distant target. </li><li>As long as the surface of the target isn’t too polished or shiny, the laser pulse will scatter off the surface in all directions, and some of that reflected light will travel back along the original ray direction. The photodetector catches that return pulse and the stopwatch tells you how much time has passed between when the pulse first went out and when it came back. That time is called the round-trip time. </li><li>then the distance from the LIDAR to the target is simply half of the round-trip distance calculated by the time and the speed of the light</li><li>This technique is called time-of-flight ranging</li><li>the photodetector also tells the intensity of the return pulse relative to the intensity of the pulse that was emitted. This intensity information is less commonly used for self-driving, but it provides some extra information about the geometry of the environment and the material the beam is reflecting off of.</li></ul><p><strong>The basic LIDAR sensor models in 2D and 3D</strong></p><ul><li>But how do to use the above knowledge to measure a whole bunch of distances in 2D or in 3D? <ul><li>The trick is to build a rotating mirror into the LIDAR that directs the emitted pulses along different directions. </li><li>As the mirror rotates, you can measure distances at points in a 2D slice around the sensor. </li><li>If you then add an up and down nodding motion to the mirror along with the rotation, you can use the same principle to create a scan in 3D. </li></ul></li><li>Measurement Models for 3D LIDAR Sensors<ul><li>LIDARs measure the position of points in 3D using spherical coordinates, range or radial distance from the center origin to the 3D point, elevation angle measured up from the sensors XY plane, and azimuth angle, measured counterclockwise from the sensors x-axis.</li><li>The azimuth and elevation angles are measured using encoders that tell you the orientation of the mirror, and the range is measured using the time of flight as we’ve seen before.</li><li>suppose we want to determine the cartesian XYZ coordinates of our scanned point in the sensor frame, which is something we often want to do when we’re combining multiple LIDAR scans into a map. To convert from spherical to Cartesian coordinates, we use the inverse sensor model: $$[x \; y \; z]^T = h^{-1}(r,\alpha, \varepsilon) = [r\cos\alpha \cos \varepsilon \quad r \sin \alpha \cos \varepsilon \quad r \sin \varepsilon]^T$$ where $\alpha$ is the azimuth angle, $\varepsilon$ is the elevation angle</li><li>Therefore, the forward sensor model is: (which from Cartesian coordinates to spherical coordinates) $$[r \alpha \varepsilon]^T = h(x,y,z) = [\sqrt{x^2+y^2+z^2} \tan^{-1}(\frac yx) \sin^{-1}(\frac{z}{\sqrt{x^2+y^2+z^2}})]^T$$</li></ul></li></ul><p><img src="/blog/images/state_est02.jpg" width="80%" height="80%"></p><p><strong>The major sources of measurement error for LIDAR sensors</strong></p><ul><li>Uncertainty in determining the exact time of arrival of the refected signal</li><li>Uncertainty in measuring the exact orientation of the mirror</li><li>Interaction with the target(surface absorption, specular reflection, etc.): e.g.: if the surface is completely black, it might absorb most of the laser pulse. Or if it’s very shiny like a mirror, the laser pulse might be scattered completely away from the original pulse direction.</li><li>Variation of propagation speed (e.g., through materials)</li><li>These factors are commonly accounted for by assuming additive zero-mean Gaussian noise on the spherical coordinates with an empirically determined or manually tuned covariance. </li><li>Motion Distortion<ul><li>Typical scan rate for a 3D LIDAR is 5-20 Hz</li><li>For a moving vehicle, each point in a scan is taken from a slightly different place</li><li>Need to account for this if the vehicle is moving quickly, otherwise motion distortion becomes a problem</li></ul></li></ul><h3 id="LIDAR-Sensor-Models-and-Point-Clouds"><a href="#LIDAR-Sensor-Models-and-Point-Clouds" class="headerlink" title="LIDAR Sensor Models and Point Clouds"></a>LIDAR Sensor Models and Point Clouds</h3><p><strong>The basic point cloud data structure</strong></p><ul><li>assign an index to each of the points, say point 1 through point n, and store the x, y, z coordinates of each point as a 3 by 1 column vector</li></ul><p><strong>Common spatial operations on point clouds</strong></p><ul><li>Translation<br><img src="/blog/images/state_est03.jpg" width="70%" height="70%"></li><li>Rotation<br><img src="/blog/images/state_est04.jpg" width="70%" height="70%"></li><li>Scaling<br><img src="/blog/images/state_est05.jpg" width="70%" height="70%"></li><li>Put them together<br><img src="/blog/images/state_est06.jpg" width="70%" height="70%"></li></ul><p><strong>Least squares to fit a plane to a point cloud</strong></p><ul><li>Plane fitting</li><li>One of the most common and important applications of plane-fitting for self-driving cars is figuring out where the road surface is and predicting where it’s going to be as the car continues driving.<ul><li>we have a bunch of measurements of x, y and z from our LIDAR point cloud, and we want to find values for the plane by the parameters a, b, and c defined: $z=a+bx+cy$</li><li>to find the best fit, we use least-squares estimation</li><li>define a measurement error $e$ for each point in the point cloud: $e_j = \hat z_j - z_j = (\hat a + \hat bx_j + \hat c y_j) - z_j \quad j=1,…n$ </li><li>We can stack all of the measurement errors into matrix form, ad minimize the squared-error criterion to get the least-squares solutions for the parameters</li></ul></li><li>Open-source Point Cloud Library(PCL) has many useful functions for doing basic and advanced operations on point clouds in C++</li></ul><h3 id="Pose-Estimation-from-LIDAR-Data"><a href="#Pose-Estimation-from-LIDAR-Data" class="headerlink" title="Pose Estimation from LIDAR Data"></a>Pose Estimation from LIDAR Data</h3><p><strong>Point set registration problem</strong></p><ul><li>one of the most important problems in computer vision and pattern recognition. used to estimate the motion of a self-driving car from point clouds </li><li>the point set registration problems says, given 2 point clouds in two different coordinate frames, and with the knowledge that they correspond to or contain the same object in the world, how shall we align them to determine how the sensor must have moved between the two scans? </li><li>More specifically, we want to figure out the optimal translation and the optimal rotation between the two sensor reference frames that minimizes the distance between the 2 point clouds.</li><li>ICP is the most popular algorithm to solve this problem.</li></ul><p><strong>Iterative Closest Point(ICP) algorithm</strong></p><ul><li>Intuition: When the optimal motion is found, corresponding points will be closer to each other than to other points</li><li>Heuristic:For each point,the best candidate for a corresponding point is the point that is closest to it right now</li><li>Steps of ICP:<ul><li>Get an initial guess for the transformation ${\check C_{S’S}, \check r^{S’S}_{S}}$: <ul><li>the initial guess can come from a number of sources. </li><li>One of the most common sources is a motion model, which could be supplied by an IMU or by wheel odometry or something really simple like a constant velocity or even a zero velocity model</li><li>How complex the motion model needs to be to give us a good initial guess really depends on how smoothly the car is driving.</li><li>If the car is moving slowly relative to the scanning rate of the LIDAR sensor, one may even use the last known pose as the initial guess.</li></ul></li><li>Associate each point in $P_{S’}$ with the nearest point in $P_S: transform the coordinates of the points in one cloud into the reference frame of the other</li><li>Solve for the optimal transformation ${\hat C_{S’S}, \hat r^{S’S}_S}$</li><li>Repeat until convergence</li></ul></li><li>Solving for the Optimal Transformation<ul><li>use least-squares:</li><li>Special attention need to be paid to the rotation matrix: as two rotation matrices addition will not necessarily results in a valid rotation matrix. 3D rotations belong to something called the special orthogonal group or SO3</li></ul></li><li>Steps:<ul><li>Compute the centroids of each point cloud: <ul><li>$\mu_S = \frac 1n \sum^n_{j=1}P^{j}_S$ </li><li>$\mu_{S’} = \frac 1n\sum^n_{j=1}P^{(j)}_{S’}$</li></ul></li><li>Compute a matrix capturing the spread of the two point clouds: $$W_{S’S} = \frac 1n \sum^n_{j=1}(P^{(j)}{s} - \mu_{S})(P^{(j)}{s’}-\mu_{S’})^T$$ this W matrix can be regarded as something like an inertia matrix you might encounter in mechanics. </li><li>finding the optimal rotation matrix using SVD of W matrix: $$USV^T = W_{S’S}$$ where U V are rotation and S is the scaling matrix. As we’re dealing with rigid body motion in this problem, we don’t want any scaling in a rotation estimate, so we’ll replace the S matrix with something like the identity matrix to remove the scaling.</li><li>Use the optimal rotation to get the optimal translation by aligning the centroids</li></ul></li><li>Estimate the uncertainty:<ul><li>We can obtain an estimate of the covariance matrix of the ICP solution using a formula</li><li>This expression tells us how the covariance of the estimated motion parameters is related to the covariance of the measurements in the two point clouds using certain second-order derivatives of the least squares cost function.</li></ul></li><li>Variants <ul><li>Point-to-point ICP minimizes the Euclidean distance between each point in $P_{S’}$, and the nearest point in $P_S$</li><li>Point-to-plane ICP minimizes the perpendicular distance between each point in $P_{S’}$, and the nearest plane in $P_S$·<ul><li>This tends to work well in structured environments like cities or indoors</li><li>first fit a number of planes to the first point cloud and then minimize the distance between each point in the second cloud and its closest plane in the first cloud.</li></ul></li></ul></li></ul><p><strong>Common pitfalls of the ICP algorithm</strong></p><ul><li>Outliers - Objects in Motion:<ul><li>be careful to exclude or mitigate the effects of outlying points that violate our assumptions of a stationary world</li><li>One way to do this is by fusing ICP motion estimates with GPS and INS estimates. </li><li>Another option is to identify and ignore moving objects, which we could do with some of the computer vision techniques.</li><li>But an even simpler approach for dealing with outliers like these is to choose a different loss function that is less sensitive to large errors induced by outliers than our standard squared error loss, Robust Loss Functions:</li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;From Coursera, State Estimation and Localization for Self-Driving Cars by University of Toronto&lt;br&gt;&lt;a href=&quot;https://www.coursera.org/lear
      
    
    </summary>
    
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
      <category term="Self-driving" scheme="http://tracyxinwang.site/blog/tags/Self-driving/"/>
    
  </entry>
  
  <entry>
    <title>Coursera State Estimation and Localization for Self-Driving Cars 03</title>
    <link href="http://tracyxinwang.site/blog/2019/07/29/coursera_state_est03/"/>
    <id>http://tracyxinwang.site/blog/2019/07/29/coursera_state_est03/</id>
    <published>2019-07-29T08:57:23.000Z</published>
    <updated>2019-08-09T02:33:26.430Z</updated>
    
    <content type="html"><![CDATA[<p>From Coursera, State Estimation and Localization for Self-Driving Cars by University of Toronto<br><a href="https://www.coursera.org/learn/state-estimation-localization-self-driving-cars" target="_blank" rel="noopener">https://www.coursera.org/learn/state-estimation-localization-self-driving-cars</a></p><h2 id="GNSS-INS-Sensing-for-Pose-Estimation"><a href="#GNSS-INS-Sensing-for-Pose-Estimation" class="headerlink" title="GNSS/INS Sensing for Pose Estimation"></a>GNSS/INS Sensing for Pose Estimation</h2><h3 id="3D-Geometry-and-Reference-Frames"><a href="#3D-Geometry-and-Reference-Frames" class="headerlink" title="3D Geometry and Reference Frames"></a>3D Geometry and Reference Frames</h3><p><strong>Reference frame and vector coordinates</strong></p><ul><li>Vectors can be expressed in different coordinate frames</li><li>The coordinates of the vector are related through a rotation matrix: $r_b = C_{ba}r_a$, $C_{ba}$ is the rotation matrix takes coordinates in frame a and rotates them into frame b </li></ul><p><strong>Rotation representations</strong></p><ul><li>rotation matrix (direction cosine matrix): <ul><li>$C_{ba}=[b_1 \;b_2\; b_3]^T[a_1 \; a_2\; a_3] \in R^{3\times 3}$</li><li>$r_b = C_{ba}r_a$</li><li>$C_{ba}C^T_{ba} = C_{ba}C_{ab} = 1$</li></ul></li><li>Unit quaternions<ul><li>$q=[q_w \; q_v]T = [\cos \frac \phi 2 \quad \hat u \sin \frac \phi 2]^T$</li><li>$| q| = 1$</li><li>$r_b = C(q_{ba}r_a)$</li><li>$C(q) = (q^2_w-q^T_vq_v)1+2q_vq^T_v + 2q_w[q_v]_x$ </li><li>Quaternion multiplication and rotations</li></ul></li><li>Euler angles<ul><li>$C(\theta_3,\theta_2,\theta_1) = C_3(\theta_3)C_2(\theta_2)C_1(\theta_1) $</li><li>suffer from singularity</li></ul></li></ul><p>The importance of the ECEF, ECIF and Navigation reference frames</p><p><strong>Reference Frames</strong></p><ul><li>ECIF: Earth-Centred Inertial Frame<ul><li>ECIF coordinate frame is fixed, Earth rotates about the z axis.</li></ul></li><li>ECEF: Earth-Centred Earth-Fixed Frame<ul><li>ECEF coordinate frame rotates with the Earth.</li><li>x axis aligns the prime meridian</li></ul></li><li>Navigation<ul><li>NED frame</li><li>ENU frame</li></ul></li><li>Sensor/Vehicle frame</li></ul><h3 id="The-Inertial-Measurement-Unit-IMU"><a href="#The-Inertial-Measurement-Unit-IMU" class="headerlink" title="The Inertial Measurement Unit (IMU)"></a>The Inertial Measurement Unit (IMU)</h3><p><strong>Components</strong></p><ul><li>gyroscopes<ul><li>measures a rotational rate in the sensor frame</li><li>Microelectromechanical systems(MEMS) are much smaller and cheaper</li><li>Measure rotational rates instead of orientation directly</li><li>Measurements are noisy and drift over time</li></ul></li><li>accelerometers <ul><li>measures a specific force (or acceleration relative to free-fall) in the sensor frame</li><li>Cheaper MEMS based accelerometers use a miniature cantilever beam with a proof mass attached to it. When the sensor is accelerated, the beam deflects.</li><li>More expensive sensors may also use Piezoelectric materials</li><li>Accelerometers measure acceleration relative to free-fall-this is also called the proper acceleration or specific force: $$a_{mean} = f = \frac{F_{non-gravity}}{m}$$</li><li>In localization, we typically require the acceleration relative to a fixed reference frame<ul><li>‘coordinate’acceleration</li><li>computed using fundamental equation for accelerometers in a gravity field: $f+g=\ddot r_i$</li></ul></li></ul></li></ul><h3 id="The-Global-Navigation-Satellite-Systems-GNSS"><a href="#The-Global-Navigation-Satellite-Systems-GNSS" class="headerlink" title="The Global Navigation Satellite Systems (GNSS)"></a>The Global Navigation Satellite Systems (GNSS)</h3><p>Global Navigation Satellite System (GNSS) is a catch-all term for a satellite system(s) that can be used to pinpoint a receiver’s position</p><p>GPS - Computing Position:</p><ul><li>Each GPS satellite transmits a signal that encodes<ul><li>its position (via accurate ephemeris information)</li><li>time of signal transmission (via onboard atomic clock)</li></ul></li><li>To compute a GPS position fix in the Earth-centred frame, the receiver uses the speed of light to compute distances to each satellite based on time of signal arrival</li><li>At least four satellites are required to solve for 3D position, three if only 2D is required</li></ul><p>GPS I Error Sources:</p><ul><li>Ephemeris &amp; clock errors<ul><li>A clock error of $lx10^{-6}$s gives a 300m position error!</li></ul></li><li>Geometric Dilution of Precision (GDOP)<ul><li>The configuration of the visible satellites affects position precision</li></ul></li></ul><p>Improvements of GPS:</p><ul><li>Basic GPS:<ul><li>mobile receiver</li><li>no error correction</li><li>~ 10m accuracy</li></ul></li><li>Differential GPS (DGPS):<ul><li>mobile receiver + fixed base station(s)</li><li>estimate eror caused by atmospheric effects</li><li>~10m accuracy</li></ul></li><li>Real-Time Kinematic (RTK) GPS<ul><li>mobile receiver + fixed base station(s)</li><li>estimate relative position using phase of carrier signal</li><li>~2cm accuracy</li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;From Coursera, State Estimation and Localization for Self-Driving Cars by University of Toronto&lt;br&gt;&lt;a href=&quot;https://www.coursera.org/lear
      
    
    </summary>
    
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
      <category term="Self-driving" scheme="http://tracyxinwang.site/blog/tags/Self-driving/"/>
    
  </entry>
  
  <entry>
    <title>Coursera State Estimation and Localization for Self-Driving Cars 02</title>
    <link href="http://tracyxinwang.site/blog/2019/07/25/coursera_state_est02/"/>
    <id>http://tracyxinwang.site/blog/2019/07/25/coursera_state_est02/</id>
    <published>2019-07-25T14:57:23.000Z</published>
    <updated>2019-08-09T02:35:15.060Z</updated>
    
    <content type="html"><![CDATA[<p>From Coursera, State Estimation and Localization for Self-Driving Cars by University of Toronto<br><a href="https://www.coursera.org/learn/state-estimation-localization-self-driving-cars" target="_blank" rel="noopener">https://www.coursera.org/learn/state-estimation-localization-self-driving-cars</a></p><h2 id="Linear-and-Nonlinear-Kalman-Filters"><a href="#Linear-and-Nonlinear-Kalman-Filters" class="headerlink" title="Linear and Nonlinear Kalman Filters"></a>Linear and Nonlinear Kalman Filters</h2><h3 id="The-Linear-Kalman-Filter"><a href="#The-Linear-Kalman-Filter" class="headerlink" title="The (Linear) Kalman Filter"></a>The (Linear) Kalman Filter</h3><ul><li>The Kalman Filter requires the following motion and measurement models: <ul><li>Motion madel: $x_k=F_{k-1}x_{k-1}+G_{k-1}u_{k-1} + w_{k-1}$</li><li>measurement model: $y_k = H_kx_k+v_k$</li></ul></li><li>with the following noise properties: $$v_k ~ N(0,R_k) \quad w_k ~ N(0,Q_k)$$ <ul><li>$v_k$ is the measurement noise, $w_k$ is the process/motion noise</li></ul></li></ul><p>The Kalman filter can be regarded as a recursive least squares estimator that also includes a motion model.<br>It has twp stages: the prediction and the </p><ul><li>Prediction: $$\check x_k = F_{k-1}x_{k-1}+G_{k-1}u_{k-1}$$ $$\check P_k = F_{k-1}\hat P_{k-1}\hat F^T_{k-1} + Q_{k-1}$$</li><li>Optimal gain: $$K_k = \check P_k H^T_k(H_k\check P_k H^T_k + R_k)^{-1}$$</li><li>Correction: $$\hat x_k = \check x_k + K_k(y_k-H_k\check x_k)$$ $$\hat P_k = (1-K_kH_k)\check P_k$$</li></ul><p>Summary:</p><ul><li>The Kalman Filter is very similar to RLS but includes a motion model that tells us how the state evolves over time</li><li>The Kalman Filter updates a state estimate through two stages:<ul><li>prediction using the motion model</li><li>correction using the measurement model</li></ul></li></ul><h3 id="Kalman-Filter-and-The-Bias-BLUEs"><a href="#Kalman-Filter-and-The-Bias-BLUEs" class="headerlink" title="Kalman Filter and The Bias BLUEs"></a>Kalman Filter and The Bias BLUEs</h3><p><strong>Bias</strong></p><ul><li>Bias = $E(\hat p_k) - p_k$ ,where pk is the true position</li><li>A filter is an unbiased if for all k : $E[\hat e_k] = E[\hat p_k -p_k] = E[\hat p_k] - p_k = 0$</li><li>How to compute bias analytically?<ul><li>consider the error dynamics: </li><li>predicted state error: $\check e_k = \check x_k - x_k$</li><li>corrected estimate error: $\hat e_k = \hat x_k - x_k$</li><li>using Kalman Filter equation we can derive: $$\check e_k = F_{k-1}\check e_{k-1} - w_k$$ $$\hat e_k = (1-K_kH_k)\check e_k + K_kv_k$$</li></ul></li><li>For Kalman filter, for all k: $$E[\check e_k] = E[F_{k-1}\check e_{k-1} - w_k] = F_{k-1} E[\check e_{k-1} - E[w_k] = 0$$ $$E[\hat e_k] = E[(1-K_kH_k)\check e_k +K_kv_k] = (1-K_kH_k)E[\check e_k]+K_kE[v_k]=0 $$<ul><li>unbiased prediction!</li><li>so long as $E[\hat e_0]=0, E[v]=0, E[w]=0 $, which is the white uncorrelated noise</li></ul></li></ul><p><strong>consistency</strong></p><ul><li>the filter is consistent if for all k: $E[\hat e^2_k]=E[(\hat p_k-p_k)^2]=\hat P_k $<ul><li>that is to say: for all time steps k, the filter co-variants $P_k$ matches the expected value of the square of our error.</li></ul></li><li>Practically, this means that our filter is neither overconfident, nor underconfident in the estimate it has produced: <ul><li>A filter that is overconfident, and hence inconsistent, will report a covariance that is optimistic: the filter will essentially place too much emphasis on its own estimate and will be less sensitive to future measurement updates.</li></ul></li><li>So long as the initial estimate is consisten and we have white zero noise, then all the estimates will be consistent</li></ul><p><strong>Kalman filter is the Best Linear Unbiased</strong></p><ul><li>given white uncorrelated zero mean noise, the Kalman Filter is unbiased and consistent.</li><li>We can also say that the filter is consistent</li><li>In general，if we have white，uncorrelated zero-mean noise，the Kalman filter is the best（i.e，lowest variance）unbiased estimator that uses only a linear combination of measurements</li></ul><h3 id="The-Extended-Kalman-Filter"><a href="#The-Extended-Kalman-Filter" class="headerlink" title="The Extended Kalman Filter"></a>The Extended Kalman Filter</h3><p>EKF: Uses first-order linearization to turn a nonlinear problem into a linear one</p><ul><li>As we introduced, the Kalman filter is actually the best of all possible estimators for linear systems</li><li>However, linear systems don’t exist in reality. </li><li>Therefore, we need to use a kind of Kalman filter that can apply to non-linear system. That is the extended kalman filter</li><li>The key concept in the Extended Kalman Filter is the idea of linearizing a nonlinear system</li></ul><p>Role of Jacobian matrices in the EKF and how to compute them</p><p><strong>Linearizing a nonlinear system</strong></p><ul><li>Linearization means to choose an operating point $a$ and finding a linear approximation to the nonlinear function in the neighborhood of $a$</li><li>in two dimensions, this means finding the tangent line to the function f of x when x equals a.</li><li>Mathematically, we do this by taking the Taylor series expansion of the function: $$f(x)\approx f(a) + \frac{\partial f(x)}{\partial x}|_{x=a}(x-a) + \frac{1}{2!}\frac{\partial^2f(x)}{\partial x^2}|{x=a}(x-a)^2 + … $$</li><li>For linearization, we’re only interested in the first order terms of the Taylor series expansion.</li></ul><p>Pick the most recent state estimate as the operating point:</p><ul><li>we can get the linearized motion and measurment model</li><li>the model involves Jacobian Matrices: <ul><li>In vector calculus，a Jacobian matrix is the matrix of all first-order partial derivatives of a vector-valued function</li><li>Intuitively，the Jacobian matrix tells you how fast each output of the function is changing along each input dimension</li></ul></li></ul><p>Apply the EKF to a simple nonlinear tracking problem</p><h3 id="The-Error-State-Extended-Kalman-Filter-ES-EKF"><a href="#The-Error-State-Extended-Kalman-Filter-ES-EKF" class="headerlink" title="The Error State Extended Kalman Filter (ES-EKF)"></a>The Error State Extended Kalman Filter (ES-EKF)</h3><p>Error-state formulation of the Extended Kalman Filter</p><ul><li>We can think of the vehicle state as composed of two parts: a large part called the nominal state, $\hat x$, and a small part called the error state, $\delta x$: $x=\hat x+\delta x$</li><li>We can think of the error state as the place where all of these modelling errors and process noise accumulate over time, so that the error state is just the difference between the nominal state and the true state at any given time.</li><li>If we can figure out what the error state is, we can actually use it as a correction to the nominal state to bring us closer to the true state. </li><li>So in the ES-EKF, instead of doing Kalman filtering on the full state which might have lots of complicated non-linear behaviors, we’re going to use the EKF to estimate the error state instead, and then use the estimate of the error state as a correction to the nominal state</li><li>Mathematically, we’re going to rearrange our linearized motion model so that we now have an equation that can tell us how the difference between the true state at time, k, and our predicted state at time, k, is related to the same difference at time, $k-1$. <ul><li>that means we can build the equations called the error state kinematics.</li></ul></li></ul><p>Loop:</p><ul><li>update the nominal state using the non-linear motion model and the current best estimate of the state. </li><li>keep track of the state covariance, which grows as we integrate more and more process noise from the motion model. </li><li>repeat the loop updating the nominal state and the error state covariance for as long as we like until we receive the measurement and want to do a correction. <ul><li>then compute the Kalman gain</li><li>compute the best estimate of the error state using the Kalman gain, the measurement, and our nonlinear measurement model</li><li>update the nomial state by just adding our estimate of the error state to the nominal state to get the correct state estimate for the full state</li><li>finally update the state covariance using the usual equations. </li></ul></li></ul><p>Advantages of the Error-state EKF over the vanilla EKF:</p><ul><li>Better performance compared to the vanilla EKF <ul><li>The”small”error state is more amenable to linear filtering than the “large” nominal state, which can be integrated nonlinearly</li></ul></li><li>Easy to work with constrained quantities(e.g., rotations in 3D)<ul><li>We can also break down the state using a generalized composition operator</li></ul></li></ul><h3 id="Limitations-of-the-EKF"><a href="#Limitations-of-the-EKF" class="headerlink" title="Limitations of the EKF"></a>Limitations of the EKF</h3><p><strong>Linearization error</strong></p><ul><li>The EKF works by linearizing the nonlinear motion and measurement models to update the mean and covariance of the state</li><li>The difference between the linear approximation and the nonlinear function is called linearization error</li><li>In general, the linearization error depends on two things:<ul><li>how non-linear the original function is to begin with. If our nonlinear function very slowly or is quite flat much of the time, linear approximation is going to be a pretty good fit. </li><li>how far away from the operating point the linear approximation is being used. The further away you move from the operating point, the more likely the linear approximation is to diverge from the true function. </li></ul></li></ul><p><strong>Computing Jacobians</strong></p><ul><li>Analytical differentiation is prone to human eror</li><li>Numerical differentiation can be slow and unstable</li><li>Automatic differentiation (e.g., at compile time) can also behave unpredictably</li></ul><h3 id="An-Alternative-to-the-EKF-The-Unscented-Kalman-Filter"><a href="#An-Alternative-to-the-EKF-The-Unscented-Kalman-Filter" class="headerlink" title="An Alternative to the EKF - The Unscented Kalman Filter"></a>An Alternative to the EKF - The Unscented Kalman Filter</h3><ul><li>an alternative approach to non-linear common filtering that relies on something called the unscented transform to pass probability distributions through nonlinear functions.</li></ul><p><strong>Use the Unscented transform to pass a probability distribution through a nonlinear function</strong></p><ul><li>The basic idea in the unscented transform has three steps. <ul><li>First, we choose a set of sample points from our input distribution. These aren’t random samples, but deterministic samples chosen to be a certain number of standard deviations away from the mean.</li><li>these samples are called sigma points, and the unscented transform is sometimes called the sigma point transform.</li><li>After getting the sigma points, pass each sigma point through the nonlinear function, producing a new set of sigma points belonging to the output distribution.</li><li>Finally, compute the sample mean and covariance of the output sigma points with some carefully chosen weights, and these will give us a good approximation of the mean and covariance of the true output distribution.</li></ul></li><li>The unscented transform - Choosing Sigma Points<ul><li>In general, for an $n$ dimensional probability distribution, we need $2n+1$ sigma points, one for the mean and the rest symmetrically distributed about the mean.</li><li>The first step in determining where the sigma point should be is taking something called the <em>Cholesky decomposition</em> of the <em>covariance matrix</em> associated with the input distribution: $LL^T=\Sigma_{xx}$ (L is the lower triangular)</li><li>In fact, if the input PDF is one dimensional the Cholesky decomposition is just the square root of the variants, which is  the standard deviation.</li></ul></li><li>The unscented transform - Transforming nad recombing<ul><li>pass each of the sigma points through nonlinear function to get a new set of transformed sigma points.</li><li>And finally compute the mean and covariance of the output PDF: each of the points gets a specific weight in the mean and covariance calculations, and that weight depends on the parameter kappa and the dimension of the input distribution N. </li></ul></li></ul><p><strong>How the unscented Kalman filter (UKF)uses the Unscented transform in the prediction and correction steps</strong></p><ul><li>We can easily use the Unscented Transform in our Kalman Filtering framework with nonlinear models;</li><li>Prediction step:<ul><li>To propagate the state from time (k-1) to time k, apply the Unscented Transform using the current best guess for the mean and covariance</li><li>decompose the estimated state covariance from time k- 1 and compute sigma point centered around the estimated means state from time k- 1</li><li>propagate our sigma points through our nonlinear motion model to get a new set of sigma points for the predicted state at time k.</li><li>finally, calculate the predicted mean and covariance for the state at time K. At this point it’s important to account for the process noise by adding its covariance to the covariance of the transformed sigma points to get the final predicted covariance.</li></ul></li><li>Correction step<ul><li>To correct the state estimate using measurements at time k,use the nonlinear measurement model and the sigma points from the prediction step to predict the measurements</li><li>First, redraw our sigma points using the predicted covariance matrix. We need to do this a second time because we added process noise at the end of the last step, and this will modify the positions of some of the sigma points. </li><li>plug these new sigma points one by one into our nonlinear measurement model to get another set of sigma points for the predicted measurements, then we can estimate the mean and covariance of the predicted measurements using the sample mean and covariance formulas.</li><li>To compute the common gain, we’re also going to need the cross covariance between the predicted state and the predicted measurements, which tells us how the measurements are correlated with the state.</li><li>Then use the Kalman gain to optimally correct the mean and covariance of the predicted state</li></ul></li></ul><p><strong>Advantages of the UKF over the EKF</strong></p><ul><li>recommand to use UKF</li><li>address the limitations of EKF</li></ul><p><strong>Apply the UKF to a simple nonlinear tracking problem</strong></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;From Coursera, State Estimation and Localization for Self-Driving Cars by University of Toronto&lt;br&gt;&lt;a href=&quot;https://www.coursera.org/lear
      
    
    </summary>
    
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
      <category term="Self-driving" scheme="http://tracyxinwang.site/blog/tags/Self-driving/"/>
    
  </entry>
  
  <entry>
    <title>Coursera State Estimation and Localization for Self-Driving Cars 01</title>
    <link href="http://tracyxinwang.site/blog/2019/07/23/coursera_state_est01/"/>
    <id>http://tracyxinwang.site/blog/2019/07/23/coursera_state_est01/</id>
    <published>2019-07-23T14:57:23.000Z</published>
    <updated>2019-08-09T02:36:52.719Z</updated>
    
    <content type="html"><![CDATA[<p>From Coursera, State Estimation and Localization for Self-Driving Cars by University of Toronto<br><a href="https://www.coursera.org/learn/state-estimation-localization-self-driving-cars" target="_blank" rel="noopener">https://www.coursera.org/learn/state-estimation-localization-self-driving-cars</a></p><h2 id="Least-Squares"><a href="#Least-Squares" class="headerlink" title="Least Squares"></a>Least Squares</h2><h3 id="Ordinary-and-weighted-least-squares"><a href="#Ordinary-and-weighted-least-squares" class="headerlink" title="Ordinary and weighted least squares"></a>Ordinary and weighted least squares</h3><p><strong>Ordinary least squares</strong></p><p>example from estimating resistance:</p><ul><li>let the measurement model be: $$y_i = x + v_i$$<ul><li>$x$ is the actual resistance</li><li>$v_i$ is the measurement noise</li><li>then the squared error is : $e^2_i = (y_i-x)^2$</li></ul></li><li>The squared error criterion: $$ \hat x_{LS}=argmin_x (e^2_1+e^2_2+e^2_3+e^2_4) = L_{LS}(x)$$<ul><li>the ‘best’ estimate of resistance is the one that minimizes the sum of squared errors.</li><li>rewrite into vector form: $$ e= y- H x$$</li><li>$H$ is called Jacobian:  $[1 1 1 1]^T$</li><li>therefore, $$L_{LS}(x) = (e^2_1+e^2_2+e^2_3+e^2_4) =  e^Te$$ $$=(y-Hx)^T(y-Hx)$$ $$=y^Ty - x^TH^Ty - y^THx + x^TH^THx$$</li><li>therefore, the rest thing is to minimize the above equation</li><li>get partial derivative with respect to the parameter, set to 0:<br>$$\frac{\partial L}{\partial x}|_{x=\hat x} = -y^TH-y^TH+2\hat x^T H^TH=0$$ $$-2y^TH+2\hat x^TH^TH=0$$</li><li>re-arrange, we get (when H is full-column rank) $$\hat x_{LS} = (H^TH)^{-1} H^Ty$$</li></ul></li><li>Assumptions:<ul><li>Our measurement model,$y=x+v$,is linear</li><li>Measurements are equally weighted (we do not suspect that some have more noise than others)</li></ul></li></ul><p><strong>weighted least squares</strong></p><p>The same example: Suppose we take measurements with multiple multimeters,some of which are better than others</p><ul><li>Consider the general linear measurement model for m measurements and n unknowns: $$y = Hx+v$$</li><li>In regular least squares, we implicitly assumed that each noise term was of equal variance: $$E(v^2_i) = \sigma^2 (i=1,…,m)$$ $$R=E(vv^T) = diag(\sigma^2,…,\sigma^2)$$</li><li>If we assume each noise term is independent, but of different variance<br>$E(v^2_i) = \sigma_i^2 (i=1,…,m)$, $R=E(vv^T) = diag(\sigma_1^2,…,\sigma_m^2)$</li><li>Then we can define a weighted least squares criterion as: $$L_{WLS}(x)=e^TR^{-1}e = \frac{e^2_1}{\sigma^2_1} + \frac{e^2_2}{\sigma^2_2} + … + \frac{e^2_m}{\sigma^2_m}$$, where $e = y-Hx$</li><li>expanding the new criterion: $$L_{WLS}(x) = e^TR^{-1}e = (y-Hx)^TR^{-1}(y-Hx)$$<ul><li>get the derivative: $$\frac{\partial L}{\partial x}|_{x=\hat x} = 0 = -y^TR^{-1}H + \hat x^T H^TR^{-1}H$$</li><li>get $$H^T R^{-1} H \hat x_{WLS} = H^TR^{-1}y$$</li><li>the weighted normal equation: $$\hat x = (H^TR^{-1}H)^{-1} H^T R^{-1}y$$</li></ul></li></ul><p>Comparison between ordinary and weighted least squares:<br><img src="/blog/images/state_est01.jpg" width="80%" height="80%"></p><p>Summary:</p><ul><li>Measurements can come from sensors that have different noisy characteristics</li><li>Weighted least squares lets us weight each measurement according to noise variance</li></ul><h3 id="Recursive-least-squares"><a href="#Recursive-least-squares" class="headerlink" title="Recursive least squares"></a>Recursive least squares</h3><p>In the above example, what if we have a stream of data?<br>We can use linear recursive estimator</p><ul><li>Suppose we have an optimal estimate, $\hat X_{k-1}$, of our unknown parameters at time k-1</li><li>Then we obtain a new measurement at time k: $y_k = H_kx+v_k$</li><li>We can use a linear recursive update: $\hat x_k = \hat x_{k-1} + K_k(y_k-H_k \hat x_{k-1})$<ul><li>We update our new state as a linear combination of the previous best guess and the current measurement residual (or error), weighted by a gain matrix $K_k$</li></ul></li><li>What is teh gain matrix?<ul><li>We can compute the gain matrix by minimizing a similar least squares criterion, but this time we’ll use a probabilistic formulation</li></ul></li><li>We wish to minimize the <em>expected value of the sum of squared errors</em> of our current estimate at time step k: $$L_{RLS} = E[(x_k-\hat x_k)^2]=\sigma_k^2$$</li><li>If we have n unknown parameters at time step k,we generalize this to $$L_{RLS} = E[(x_{1k}-\hat x_{1k})^2 + … +(x_{nk}-\hat x_{nk})^2] = Trace(P_k)$$<ul><li>$P_k$ is the estimator covariance</li></ul></li><li>Using linear recursive formulation, we can express covariance as a function of $K_k$: $$P_k = (1-K_kH_k)P_{k-1} (1-K_kH_k)^T + K_kR_kK^T_k$$</li><li>We can show(through matrix calculus) that this is minimized when $$K_k = P_{k-1}H^T_k(H_kP_{k-1}H^T_k + R_k)^{-1}$$</li><li>With this expression, we can also simplify our expression for $P_k$: $$P_k = P_{k-1} - K_kH_kP_{k-1} = (1-K_kH_k)P_{k-1}$$</li></ul><p><strong>Recursive Least Squares I Algorithm</strong></p><ul><li>Initialize the esimator: $$\hat x_0 = E[x]$$ $$P_0 = E[(x-\hat x_0)(x-\hat x_0)^T]$$</li><li>Set up the measurement model，defining the Jacobian and the measurement covariance matrix: $$y_k = H_kx+v_k$$</li><li>Update the estimate of $\hat x_k$ and the covariance $P_k$ using: $$K_k = P_{k-1}H^T_k(H_kP_{k-1}H^T_k +R_k)^{-1}$$ $$\hat x_k = \hat x_{k-1} + K_k(y_k-H_k\hat x_{k-1}) $$ $$P_k = (1-K_kH_k)P_{k-1}$$</li></ul><p><strong>Summary</strong></p><ul><li>RLS produces a ‘running estimate’ of parameter(s)for a stream of measurements</li><li>RLS is a linear recursive estimator that minimizes the (co)variance of the parameter(s) at the current time</li></ul><h3 id="Maximum-likelihood-and-the-method-of-least-squares"><a href="#Maximum-likelihood-and-the-method-of-least-squares" class="headerlink" title="Maximum likelihood and the method of least squares"></a>Maximum likelihood and the method of least squares</h3><p>The maximum likelihood estimate, given additive Gaussian noise, is equivalent to the least squares or weighted least squares solutions we derived earlier.</p><p>Summary:</p><ul><li>LS and WLS produce the same estimates as maximum likelihood assuming Gaussian noise</li><li>Central Limit Theorem states that complex errors will tend towards a Gaussian distribution</li><li>Least squares estimates are significantly affected by outliers</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;From Coursera, State Estimation and Localization for Self-Driving Cars by University of Toronto&lt;br&gt;&lt;a href=&quot;https://www.coursera.org/lear
      
    
    </summary>
    
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
      <category term="Self-driving" scheme="http://tracyxinwang.site/blog/tags/Self-driving/"/>
    
  </entry>
  
  <entry>
    <title>Coursera Self-Driving 04 Vehicle Dynamic Modeling</title>
    <link href="http://tracyxinwang.site/blog/2019/07/22/coursera_self_driving04/"/>
    <id>http://tracyxinwang.site/blog/2019/07/22/coursera_self_driving04/</id>
    <published>2019-07-22T01:57:23.000Z</published>
    <updated>2019-07-23T14:35:47.000Z</updated>
    
    <content type="html"><![CDATA[<p>From Coursera, Introduction to Self-Driving Cars by University of Toronto<br><a href="https://www.coursera.org/specializations/self-driving-cars?action=enroll" target="_blank" rel="noopener">https://www.coursera.org/specializations/self-driving-cars?action=enroll</a></p><p>Creating a good vehicle model is essential for model-based control development. </p><p>Kinematic Vs Dynamic Modeling:</p><ul><li>kinematics: positions and velocities</li><li>dynamics: forces and torques of a car and how they connect</li><li>Kinematic modeling: at low speeds,i t is often sufficient to look only at kinematic models of vehicles<ul><li>Examples: Two wheeled robot, Bicycle model</li></ul></li><li>Dynamic modeling is more involved, but captures vehicle behavior more precisely over a wide operating range <ul><li>Examples: Dynamic vehicle model</li></ul></li></ul><h2 id="Kinematic-Modeling-in-2D"><a href="#Kinematic-Modeling-in-2D" class="headerlink" title="Kinematic Modeling in 2D"></a>Kinematic Modeling in 2D</h2><p><strong>Coordinate Frames</strong></p><ul><li>Right handed by convention</li><li>Inertial frame (global world coordinate)<ul><li>Fixed reference frame, usually relative to earth</li><li>we often represent this coordinate frame as East North Up, ENU, relative to a reference point nearby. </li><li>Or Earth-Centered Earth Fixed, ECEF, as is used in GNSS systems.</li></ul></li><li>Body frame<ul><li>Attached to vehicle, origin at vehicle center of gravity, or center of rotation</li><li>is moving and rotating with respect to the fixed inertial frame as the vehicle moves about.</li></ul></li><li>Sensor frame <ul><li>Attached to sensor, convenient for expressing sensor measurements</li></ul></li><li>Coordinate transformation e.g.:<ul><li>Location of point (P) in Body Frame(B):<br>$$P_B = C_{EB}(\theta) P_E + O_{EB}$$</li><li>Location of point (P) in Inertial Frame(E):<br>$$P_E = C_{BE}(\theta) P_B + O_{BE}$$</li><li>$O_{BE}$ or $O_{EB}$ is the translation term, expressed in corresponding frame</li></ul></li></ul><p><strong>2D Kinematic Modeling</strong></p><ul><li>An example of a ball in the sky: The kinematic constraint is nonholonomic <ul><li>A constraint on rate of change of degrees of freedom </li><li>Vehicle velocity always tangent to current path<br>$$\frac{dy}{dx} = tan \theta = \frac{sin \theta}{cos \theta}$$</li><li>Nonholonomic constraint: $$ \dot y cos \theta - \dot x sin \theta = 0 $$</li><li>Velocity components: $$\dot x = v cos \theta, \quad \dot y = v sin \theta$$</li></ul></li></ul><p><img src="/blog/images/self_driving07.png" width="50%" height="50%"></p><p><strong>state-based models</strong></p><ul><li>A state is a set of variables often arranged in the form of a vector that fully describe the system at the current time. </li></ul><p><strong>Two-Wheeled Robot Kinematic Model</strong></p><ul><li>Assume control inputs are wheel speeds <ul><li>Center: p </li><li>Wheel to center: l</li><li>Wheel radius:r</li><li>Wheel rotation rates: w1, w2</li></ul></li><li>Kinematic constraint $$V_i = r w_i$$</li><li>Velocity is the average of the two wheel velocities $$v=\frac{v_1 + v_2}{2} = \frac {r w_1 + r w_2} {2}$$</li><li>Use the instantaneous center of rotation(ICR)</li><li>Equivalent triangles give the angular rate of rotation $$w = \frac{-v_2}{\rho} = \frac{-(v_2 - v_1)}{2l}$$ $$w = \frac{rw_1 - rw_2}{2l}$$</li><li>continuous time model: $$\dot x = [(\frac{rw_1+rw_2}{2})cos \theta]$$ $$\dot y = [(\frac{rw_1+rw_2}{2})sin \theta]$$ $$\dot \theta = (\frac{rw_1-rw_2}{2l})$$</li><li>discrete time model: $$ x_{k+1} = x_k + [(\frac{rw_{1,k}+rw_{2,k}}{2})cos \theta_k] \delta t$$ $$ y_{k+1} = y_k + [(\frac{rw_{1,k}+rw_{2,k}}{2})sin \theta_k] \delta t$$ $$ \theta_{k+1} = \theta_k + (\frac{rw_{1,k}-rw_{2,k}}{2l}) \delta t$$</li></ul><p>source: <a href="https://www.coursera.org/lecture/intro-self-driving-cars/lesson-1-kinematic-modeling-in-2d-pScZH" target="_blank" rel="noopener">https://www.coursera.org/lecture/intro-self-driving-cars/lesson-1-kinematic-modeling-in-2d-pScZH</a></p><h3 id="The-Kinematic-Bicycle-Model"><a href="#The-Kinematic-Bicycle-Model" class="headerlink" title="The Kinematic Bicycle Model"></a>The Kinematic Bicycle Model</h3><ul><li>2Dbicycle model(simplified car model)</li><li>Front wheel steering</li></ul><p>Rear Wheel Reference Point:</p><ul><li>Apply Instantaneous Center of Rotation（ICR）: $$\dot \theta = \omega = \frac VR$$</li><li>Similar triangles: $$tan \delta = \frac LR$$</li><li>Rotation rate equation: $$\dot \theta = \omega = \frac vR = \frac{v tan \delta}{L}$$</li></ul><p>Rear Axle Bicycle Model</p><ul><li>If the desired point is at the center of the rear axle: $$\dot x_r = v cos \theta$$ $$\dot y_r = v sin \theta$$ $$\dot \theta = \frac {v tan \delta}{L}$$</li><li>If the desired point is at the center of the front axle: $$\dot x_f = v cos (\theta + \delta)$$ $$\dot y_f = v sin (\theta+\delta)$$ $$\dot \theta = \frac {v sin \delta}{L}$$</li><li>If the desired point is at the center of the gravity(cg): $$\dot x_c = v cos (\theta + \beta)$$ $$\dot y_c = v sin (\theta+\beta)$$ $$\dot \theta = \frac {v cos \beta tan \delta}{L}$$ $$\beta = tan^{-1} (\frac {l_r tan \delta}{L})$$</li></ul><p><strong>State-space Representation</strong></p><ul><li>Modify CG kinematic bicycle model to use steering rate input <ul><li>state: $[x, y, \theta, \delta]^T$ </li><li>inputs: $[v,\phi]^T$ ($\phi$ is the modified input, the rate of the change of steering angle)<br>$$\dot x_c = v cos(\theta + \beta)$$<br>$$\dot y_c = v sin(\theta + \beta)$$<br>$$\dot \theta = \frac {v cos \beta tan \delta}{L}$$ $$\dot \delta = \phi$$</li></ul></li></ul><h2 id="Dynamic-Modeling-in-2D"><a href="#Dynamic-Modeling-in-2D" class="headerlink" title="Dynamic Modeling in 2D"></a>Dynamic Modeling in 2D</h2><p>mainly on Newton’s second law</p><h3 id="Longitudinal-Vehicle-Modeling"><a href="#Longitudinal-Vehicle-Modeling" class="headerlink" title="Longitudinal Vehicle Modeling"></a>Longitudinal Vehicle Modeling</h3><ul><li>Dynamic force balance on a vehicle</li><li>Powertrain component models</li><li><p>Connect models to create a full longitudinal motior model</p></li><li><p>Total resistance load: $$F_{load} = F_{aero} + R_x + mga$$</p></li><li>The aerodynamic force can depend on air density, frontal area,on the speed of the vehicle: $$F_{aero} = 1/2C_a \rho A\dot x^2 = c_a \dot x^2$$</li><li>The rolling resistance can depend on the tire normal force,tire pressures and vehicle speed: $$R_x = N(\hat c_{r,0}+\hat c_{r,1}|\dot x| + \hat c_{r,2}\dot x^2) \approx c_{r,1}|\dot x|$$</li></ul><h3 id="Lateral-Dynamics-of-Bicycle-Model"><a href="#Lateral-Dynamics-of-Bicycle-Model" class="headerlink" title="Lateral Dynamics of Bicycle Model"></a>Lateral Dynamics of Bicycle Model</h3><h3 id="Vehicle-Actuation"><a href="#Vehicle-Actuation" class="headerlink" title="Vehicle Actuation"></a>Vehicle Actuation</h3><h3 id="Tire-Slip-and-Modeling"><a href="#Tire-Slip-and-Modeling" class="headerlink" title="Tire Slip and Modeling"></a>Tire Slip and Modeling</h3><p>·Basics of kinematic and coordinates<br>·Kinematic model development of a bicycle<br>·Basics of dynamic modeling<br>·Vehicle longitudinal dynamics and modeling<br>·Vehicle lateral dynamics and modeling<br>·Vehicle actuation system<br>·Tire slips and modeling</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;From Coursera, Introduction to Self-Driving Cars by University of Toronto&lt;br&gt;&lt;a href=&quot;https://www.coursera.org/specializations/self-drivi
      
    
    </summary>
    
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
      <category term="Self-driving" scheme="http://tracyxinwang.site/blog/tags/Self-driving/"/>
    
  </entry>
  
  <entry>
    <title>MATLAB 自动驾驶相关</title>
    <link href="http://tracyxinwang.site/blog/2019/07/21/matlab_self_driving/"/>
    <id>http://tracyxinwang.site/blog/2019/07/21/matlab_self_driving/</id>
    <published>2019-07-21T09:07:23.000Z</published>
    <updated>2019-07-21T09:52:49.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="MATLAB-EXPO-2019-MATLAB和Simulink用于开发自动驾驶的新特性"><a href="#MATLAB-EXPO-2019-MATLAB和Simulink用于开发自动驾驶的新特性" class="headerlink" title="MATLAB EXPO 2019 MATLAB和Simulink用于开发自动驾驶的新特性"></a>MATLAB EXPO 2019 MATLAB和Simulink用于开发自动驾驶的新特性</h2><h3 id="创建虚拟驾驶场景"><a href="#创建虚拟驾驶场景" class="headerlink" title="创建虚拟驾驶场景"></a>创建虚拟驾驶场景</h3><ul><li>Sensor Fusion using synthetic radar and vision data:<ul><li><a href="https://www.mathworks.com/help/driving/examples/sensor-fusion-using-synthetic-radar-and-vision-data.html" target="_blank" rel="noopener">https://www.mathworks.com/help/driving/examples/sensor-fusion-using-synthetic-radar-and-vision-data.html</a></li></ul></li><li>模拟道路和车辆 </li><li>添加基于统计概率的视觉与雷达传感器</li><li>测试传感器融合与目标跟踪 </li><li>可视化传感器覆盖区域, 检测列表, 目标跟踪列表</li></ul><p>图形化的驾驶场景设计器:</p><ul><li>Driving Scenario Designer: <a href="https://www.mathworks.com/help/driving/ref/drivingscenariodesigner-app.html" target="_blank" rel="noopener">https://www.mathworks.com/help/driving/ref/drivingscenariodesigner-app.html</a></li><li>创建道路与车道线标记 </li><li>添加车辆与行驶轨迹 </li><li>设置车辆尺寸与雷达截面积(RCS)</li><li>提供预定义的ADAS场景 </li><li>支持导入OpenDRIVE格式路网文件</li></ul><p>Simulink仿真驾驶场景:</p><ul><li>Test Open-Loop ADAS Algorithm Using Driving Scenario: <a href="https://www.mathworks.com/help/driving/ug/test-open-loop-adas-algorithm-using-driving-scenario.html" target="_blank" rel="noopener">https://www.mathworks.com/help/driving/ug/test-open-loop-adas-algorithm-using-driving-scenario.html</a><ul><li>编辑驾驶场景</li><li>在Simulink中读取场景</li><li>添加传感器模型</li><li>可视化传感器输出</li><li>调节仿真速度</li></ul></li></ul><p>设计车辆的横向与纵向控制</p><ul><li>Lane following control with sensor fusion: <a href="https://www.mathworks.com/help/mpc/ug/lane-following-control-with-sensor-fusion-and-lane-detection.html" target="_blank" rel="noopener">https://www.mathworks.com/help/mpc/ug/lane-following-control-with-sensor-fusion-and-lane-detection.html</a><ul><li>将场景集成到Simulink </li><li>设计横向（车道保持）与纵向<br>（间距管理）模型预测控制器</li><li>设计传感器融合 </li><li>生成C/C++代码 </li><li>软件在环 (SIL) 测试</li></ul></li><li>可视化传感器检测列表与目标跟踪列表</li></ul><p>控制算法的自动化测试:</p><ul><li>Testing a Lane-Following Controller with Simulink Test: <a href="https://www.mathworks.com/help/sltest/examples/testing-a-lane-following-controller.html" target="_blank" rel="noopener">https://www.mathworks.com/help/sltest/examples/testing-a-lane-following-controller.html</a></li><li>指定测试需求与被测模型</li><li>指定测试通过判据</li><li>测试结果绘图与报告生成</li><li>自动化整个测试过程</li></ul><p>从录制的实车数据生成驾驶场景:</p><ul><li>Scenario Generation from Recorded Vehicle Data: <a href="https://www.mathworks.com/help/driving/examples/scenario-generation-from-recorded-vehicle-data.html" target="_blank" rel="noopener">https://www.mathworks.com/help/driving/examples/scenario-generation-from-recorded-vehicle-data.html</a></li><li>回放录制的视频</li><li>导入OpenDRIVE路网</li><li>导入GPS数据（本车位置）</li><li>导入传感器目标列表（其他车辆<br>位置）</li></ul><p>车道跟随控制器与视觉算法的集成仿真</p><ul><li>Lane-Following Control with Monocular Camera Perception: <a href="https://www.mathworks.com/help/mpc/ug/lane-following-control-with-monocular-camera-perception.html" target="_blank" rel="noopener">https://www.mathworks.com/help/mpc/ug/lane-following-control-with-monocular-camera-perception.html</a></li><li>集成Simulink控制器模块<ul><li>车道跟随</li><li>间距控制</li></ul></li><li>集成MATLAB图像算法<ul><li>车道边界检测</li><li>车辆检测</li></ul></li><li>通过“虚幻”引擎合成理想视觉传感器图像</li></ul><h3 id="传感器融合与目标跟踪"><a href="#传感器融合与目标跟踪" class="headerlink" title="传感器融合与目标跟踪"></a>传感器融合与目标跟踪</h3><p><strong>感知</strong></p><ul><li>多目标跟踪器（Multi-object tracker）<ul><li>GNN跟踪器（Global Nearest Neighbor tracker）</li><li>JPDA跟踪器（Joint Probabilistic Data Association tracker）</li><li>TOMHT跟踪器（Track-Oriented Multi-Hypothesis Tracker）</li><li>PHD跟踪器（Probability Hypothesis Density tracker）</li></ul></li><li>跟踪滤波器：<ul><li>线性, 扩展, 无迹卡尔曼滤波器</li><li>粒子滤波器</li><li>高斯和滤波器</li><li>交互式多模型（IMM）滤波器</li></ul></li></ul><p>点目标跟踪与扩展目标跟踪：</p><ul><li>Extended Object Tracking： <a href="https://www.mathworks.com/help/fusion/examples/extended-object-tracking.html" target="_blank" rel="noopener">https://www.mathworks.com/help/fusion/examples/extended-object-tracking.html</a><ul><li>自定义的扩展目标跟踪器</li><li>利用高精度传感器对单个目标生成的多个检测</li><li>可获取更多目标属性：大小、形状、方向等</li><li>评估跟踪性能和误差指标</li><li>评估算法在桌面的执行时间</li></ul></li><li>点目标跟踪<ul><li>点目标跟踪器 multiObjectTracker</li><li>传感器对单个目标生成单个检测或经过聚类后形成单个检测</li><li>将目标简化为一个点进行跟踪</li></ul></li></ul><p>将激光雷达点云转换为目标列表：</p><ul><li>Track Vehicles Using Lidar: <a href="https://www.mathworks.com/help/vision/ug/track-vehicles-using-lidar.html" target="_blank" rel="noopener">https://www.mathworks.com/help/vision/ug/track-vehicles-using-lidar.html</a><ul><li>设计3-D边框检测器</li><li>设计目标跟踪器</li><li>生成C/C++代码</li></ul></li></ul><p><strong>规划</strong></p><p>连接HERE高精度实时地图：读取道路和限速属性:</p><ul><li>Use HERE HD Live Map Data to Verify Lane Configurations: <a href="https://www.mathworks.com/help/driving/examples/use-here-hd-live-map-data-to-verify-lane-configurations.html" target="_blank" rel="noopener">https://www.mathworks.com/help/driving/examples/use-here-hd-live-map-data-to-verify-lane-configurations.html</a><ul><li>载入摄像机与GPS数据</li><li>读取道路限速</li><li>读取车道配置</li><li>可视化组合数据</li></ul></li></ul><p>设计路径规划器:</p><ul><li>Automated Parking Valet: <a href="https://www.mathworks.com/help/driving/examples/automated-parking-valet.html" target="_blank" rel="noopener">https://www.mathworks.com/help/driving/examples/automated-parking-valet.html</a><ul><li>创建环境的代价地图 </li><li>膨胀代价地图用于碰撞检测 </li><li>指定目标位置 </li><li>使用快速搜索随机树 (RRT*)算法规划路径</li></ul></li></ul><p>设计路径规划器与车辆控制器:</p><ul><li>Automated Parking Valet in Simulink: <a href="https://www.mathworks.com/help/driving/examples/automated-parking-valet-in-simulink.html" target="_blank" rel="noopener">https://www.mathworks.com/help/driving/examples/automated-parking-valet-in-simulink.html</a><ul><li>路径规划器（RRT*算法）</li><li>车辆横向与纵向控制器（基于运动学的Stanley算法）</li><li>与车辆动力学模型结合进行闭环仿真</li></ul></li></ul><p>规划与控制算法生成C/C++代码:</p><ul><li><a href="https://www.mathworks.com/help/driving/examples/code-generation-for-path-planning-and-vehicle-control.html" target="_blank" rel="noopener">https://www.mathworks.com/help/driving/examples/code-generation-for-path-planning-and-vehicle-control.html</a><ul><li>独立的模型文件</li><li>配置代码生成选项</li><li>生成C/C++代码</li><li>软件在环 (SIL) 测试</li><li>评估代码执行时间</li></ul></li></ul><p><strong>控制</strong></p><p>通过闭环仿真设计实际的ADAS功能</p><ul><li>Autonomous Emergency Braking with Sensor Fusion： <a href="https://www.mathworks.com/help/driving/examples/autonomous-emergency-braking-with-sensor-fusion.html" target="_blank" rel="noopener">https://www.mathworks.com/help/driving/examples/autonomous-emergency-braking-with-sensor-fusion.html</a><ul><li>指定驾驶场景</li><li>设计AEB逻辑</li><li>设计传感器融合算法</li><li>仿真完整系统</li><li>生成C/C++代码</li><li>软件在环 (SIL) 测试</li></ul></li></ul><p>训练用于ADAS控制的增强学习网络：</p><ul><li>Train DDPG Agent for Adaptive Cruise Control：<a href="https://www.mathworks.com/help/reinforcement-learning/ug/train-ddpg-agent-for-adaptive-cruise-control.html" target="_blank" rel="noopener">https://www.mathworks.com/help/reinforcement-learning/ug/train-ddpg-agent-for-adaptive-cruise-control.html</a><ul><li>创建环境接口</li><li>创建agent</li><li>训练agent</li><li>仿真训练的agent</li></ul></li></ul><h3 id="集成其他资源"><a href="#集成其他资源" class="headerlink" title="集成其他资源"></a>集成其他资源</h3><ul><li>与ROS集成的三种方式：<ul><li>回放通过ROS记录的数据：Work with rosbag Logfiles <a href="https://www.mathworks.com/help/robotics/examples/work-with-rosbag-logfiles.html" target="_blank" rel="noopener">https://www.mathworks.com/help/robotics/examples/work-with-rosbag-logfiles.html</a> </li><li>实时连接ROS系统：Exchange Data with ROS Publishers and Subscribers <a href="https://www.mathworks.com/help/robotics/examples/exchange-data-with-ros-publishers.html" target="_blank" rel="noopener">https://www.mathworks.com/help/robotics/examples/exchange-data-with-ros-publishers.html</a></li><li>生成独立的ROS节点：Generate a Standalone ROS Node from Simulink <a href="https://www.mathworks.com/help/robotics/examples/generate-a-standalone-ros-node-in-simulink.html" target="_blank" rel="noopener">https://www.mathworks.com/help/robotics/examples/generate-a-standalone-ros-node-in-simulink.html</a></li></ul></li><li>从MATLAB调用C++, Python, OpenCV:<ul><li>Import C++ Library Functionality into MATLAB: <a href="https://www.mathworks.com/help/matlab/matlab_external/what-you-need-to-import-cpp-library-functions-into-matlab.html" target="_blank" rel="noopener">https://www.mathworks.com/help/matlab/matlab_external/what-you-need-to-import-cpp-library-functions-into-matlab.html</a></li><li>Call Python from MATLAB: <a href="https://www.mathworks.com/help/matlab/matlab_external/call-python-from-matlab.html" target="_blank" rel="noopener">https://www.mathworks.com/help/matlab/matlab_external/call-python-from-matlab.html</a></li><li>Install and Use Computer Vision Toolbox OpenCV Interface: <a href="https://www.mathworks.com/help/vision/ug/opencv-interface.html" target="_blank" rel="noopener">https://www.mathworks.com/help/vision/ug/opencv-interface.html</a></li></ul></li></ul><p>用到的toolbox:<br>Model Predictive Control Toolbox<br>Automated Driving Toolbox<br>Embedded Coder<br>Sensor Fusion and Tracking Toolbox<br>Reinforcement Learning Toolbox</p><p>Reference:<br><a href="https://www.matlabexpo.com/content/dam/mathworks/mathworks-dot-com/images/events/matlabexpo/cn/2019/whats-new-in-matlab-and-simulink-for-adas.pdf" target="_blank" rel="noopener">https://www.matlabexpo.com/content/dam/mathworks/mathworks-dot-com/images/events/matlabexpo/cn/2019/whats-new-in-matlab-and-simulink-for-adas.pdf</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;MATLAB-EXPO-2019-MATLAB和Simulink用于开发自动驾驶的新特性&quot;&gt;&lt;a href=&quot;#MATLAB-EXPO-2019-MATLAB和Simulink用于开发自动驾驶的新特性&quot; class=&quot;headerlink&quot; title=&quot;MATL
      
    
    </summary>
    
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
      <category term="Self-driving" scheme="http://tracyxinwang.site/blog/tags/Self-driving/"/>
    
  </entry>
  
  <entry>
    <title>Coursera Self-Driving 03 Safety Assurance for Autonomous Vehicles</title>
    <link href="http://tracyxinwang.site/blog/2019/07/21/coursera_self_driving03/"/>
    <id>http://tracyxinwang.site/blog/2019/07/21/coursera_self_driving03/</id>
    <published>2019-07-21T06:07:23.000Z</published>
    <updated>2019-07-21T08:28:46.000Z</updated>
    
    <content type="html"><![CDATA[<p>From Coursera, Introduction to Self-Driving Cars by University of Toronto<br><a href="https://www.coursera.org/specializations/self-driving-cars?action=enroll" target="_blank" rel="noopener">https://www.coursera.org/specializations/self-driving-cars?action=enroll</a></p><h2 id="Safety-Assurance-for-Autonomous-Vehicles"><a href="#Safety-Assurance-for-Autonomous-Vehicles" class="headerlink" title="Safety Assurance for Autonomous Vehicles"></a>Safety Assurance for Autonomous Vehicles</h2><h3 id="Safety-Assurance-for-Self-Driving-Vehicles"><a href="#Safety-Assurance-for-Self-Driving-Vehicles" class="headerlink" title="Safety Assurance for Self-Driving Vehicles"></a>Safety Assurance for Self-Driving Vehicles</h3><ul><li>Autonomous driving crashes</li><li>Formal definitions<ul><li>Safety: absence of unreasonable risk of harm</li><li>Hazard: potential source of unreasonable risk of harm</li></ul></li><li>Major hazard sources<ul><li>Mechanical</li><li>Electrical</li><li>Hardware</li><li>Software</li><li>Sensors</li><li>Bahavior</li><li>Fallback</li><li>Cyber</li></ul></li><li>Safety requirements<ul><li>NHTSA: safety framework<ul><li>Systems engineering approach to safety</li><li>Autonomy design: ODD, OEDR, Fallback, Traffic laws, cybersecurity, HMI</li><li>Testing &amp; Crash mitigation: crashworthiness, post crash, data recording, consumer education</li></ul></li></ul></li></ul><h3 id="Industry-Methods-for-Safety-Assurance-and-Testing"><a href="#Industry-Methods-for-Safety-Assurance-and-Testing" class="headerlink" title="Industry Methods for Safety Assurance and Testing"></a>Industry Methods for Safety Assurance and Testing</h3><p><strong>Industry perspectives on self driving safety</strong></p><ul><li>Waymo:<ul><li>Behavior safety, Functional safety, Crash safety, Operational safety, Non collision safety, Approaches to demonstrating autonomy safety</li><li>Safety process:<ul><li>Identify hazard scenarios &amp; potential mitigations</li><li>Use hazard assessment methods to define safety requirements<ul><li>Preliminary analysis</li><li>Fault tree</li><li>Design Failure Modes &amp; Effects Analyses</li></ul></li></ul></li><li>Levels of testing to ensure safety<ul><li>Simulation testing: Test rigorously with simulation,thousands of variations,fuzzing of neighbouring vehicles</li><li>Closed-course testing:<ul><li>Follow 28 core + 19 additional scenario competencies on private test tracks </li><li>Focus on four most common crashes: Rear-end,intersection,road departure,lane change</li></ul></li><li>Real-world driving</li></ul></li></ul></li><li>GM:<ul><li>Address all 12 elements of NHTSA Safety Framework</li><li>Iterative Design: Analyze, build, simulate, drive</li><li>Safety through Comprehensive Risk Management and Deep Integration: <ul><li>identify and address risks,validate solutions </li><li>prioritize elimination of risks,not just mitigation</li></ul></li><li>All hardware,software systems meet self-set standards for performance,crash protection, reliability,serviceability,security,safety</li><li>Safety process:<ul><li>Deductive Analysis: fault tree analysis</li><li>Inductive Analysis: Design &amp;Process FMEA</li><li>Exploratory Analysis: HAZOP:Hazard &amp; Operability Study</li></ul></li><li>Safety Thresholds<ul><li>All GM vehicles are equipped with two key safety thresholds</li><li>Fail safes: There is redundant functionality(second controllers,backup systems etc)such that even if primary systems fail,the vehicle can stop normally</li><li>SOTIF: All critical functionalities are evaluated for unpredictable scenarios</li></ul></li><li>Testing:<ul><li>Performance testing at different levels</li><li>Requirements validation of components, levels</li><li>Fault injection testing of safety critical functionality</li><li>Intrusive testing such as electromagnetic interference, etc.</li><li>Durability testing and simulation based testing</li></ul></li></ul></li></ul><p><strong>Approaches to demonstrating autonomy safety</strong></p><ul><li>Analytical vs Data Driven: Definitions<ul><li>Analytical Safety: Ensuring the system works in theory and meets safety requirements found by hazard assessment</li></ul></li><li>Data driven safety<ul><li>Safety guarantee due to the fact that the system has performed autonomously without fail on the roads for a very large number of kms</li></ul></li></ul><h3 id="Safety-Frameworks-for-Self-Driving"><a href="#Safety-Frameworks-for-Self-Driving" class="headerlink" title="Safety Frameworks for Self-Driving"></a>Safety Frameworks for Self-Driving</h3><p><strong>Generic Safety Frameworks</strong></p><ul><li>Fault Tree Analysis<ul><li>Top down deductive failure analysis</li><li>Boolean logic</li></ul></li><li>Probabilistic Fault Tree Analysis<ul><li>Assign probabilities to fault “leaves”</li><li>Use logic gates to construct failure tree</li></ul></li><li>Failure Mode and Effects Analyses（FMEA）<ul><li>Bottom up process to identify all the effects of faults in a system</li><li>Failure Mode:<ul><li>Modes or ways in which a component of the system may fail</li></ul></li><li>Effects Analysis:<ul><li>Analyzing effects of the failure modes on the operation of the system</li></ul></li></ul></li><li>HAZOP - a variation on FMEA<ul><li>Hazard and operability study(HAZOP)</li><li>Qualitative brainstorming process, needs “imagination”</li><li>Uses guide words to trigger brainstorming(not, more, less etc.)</li><li>Applied to complex’ processes’<ul><li>Sufficient design information is available, and not likely to change significantly</li></ul></li></ul></li></ul><p><strong>Functional safety frameworks</strong></p><ul><li>FuSa HARA: safety requirements through risk analysis</li><li>SOTIF: behavior risk assessment</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;From Coursera, Introduction to Self-Driving Cars by University of Toronto&lt;br&gt;&lt;a href=&quot;https://www.coursera.org/specializations/self-drivi
      
    
    </summary>
    
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
      <category term="Self-driving" scheme="http://tracyxinwang.site/blog/tags/Self-driving/"/>
    
  </entry>
  
  <entry>
    <title>Coursera Self-Driving 05 Vehicle Longitudinal Control</title>
    <link href="http://tracyxinwang.site/blog/2019/07/21/coursera_self_driving05/"/>
    <id>http://tracyxinwang.site/blog/2019/07/21/coursera_self_driving05/</id>
    <published>2019-07-21T06:07:23.000Z</published>
    <updated>2019-07-22T08:46:45.092Z</updated>
    
    <content type="html"><![CDATA[<p>From Coursera, Introduction to Self-Driving Cars by University of Toronto<br><a href="https://www.coursera.org/specializations/self-driving-cars?action=enroll" target="_blank" rel="noopener">https://www.coursera.org/specializations/self-driving-cars?action=enroll</a></p><p>## </p><h3 id="S"><a href="#S" class="headerlink" title="S"></a>S</h3><p>- </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;From Coursera, Introduction to Self-Driving Cars by University of Toronto&lt;br&gt;&lt;a href=&quot;https://www.coursera.org/specializations/self-drivi
      
    
    </summary>
    
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
      <category term="Self-driving" scheme="http://tracyxinwang.site/blog/tags/Self-driving/"/>
    
  </entry>
  
  <entry>
    <title>Coursera Self-Driving 02 Hardware and Software Architectures</title>
    <link href="http://tracyxinwang.site/blog/2019/07/20/coursera_self_driving02/"/>
    <id>http://tracyxinwang.site/blog/2019/07/20/coursera_self_driving02/</id>
    <published>2019-07-20T09:07:23.000Z</published>
    <updated>2019-07-21T12:34:01.994Z</updated>
    
    <content type="html"><![CDATA[<p>From Coursera, Introduction to Self-Driving Cars by University of Toronto<br><a href="https://www.coursera.org/specializations/self-driving-cars?action=enroll" target="_blank" rel="noopener">https://www.coursera.org/specializations/self-driving-cars?action=enroll</a></p><h2 id="Self-Driving-Hardware-and-Software-Architectures"><a href="#Self-Driving-Hardware-and-Software-Architectures" class="headerlink" title="Self-Driving Hardware and Software Architectures"></a>Self-Driving Hardware and Software Architectures</h2><h3 id="Sensors-and-Computing-Hardware"><a href="#Sensors-and-Computing-Hardware" class="headerlink" title="Sensors and Computing Hardware"></a>Sensors and Computing Hardware</h3><p><strong>Sensors types and characteristics</strong></p><ul><li>Sensor Categorization:<ul><li>exteroceptive: extero=surroundings</li><li>proprioceptive: proprio=internal</li></ul></li><li>Camera:   <ul><li>Sensors for perception: Essential for correctly perceiving</li><li>Comparison metrics:<ul><li>Resolution</li><li>Field of view</li><li>Dynamic range: difference between the darkest and the lightest tones in an image</li><li>other properties: focal length, depth of field and frame rate </li></ul></li><li>Trade-off between resolution and FOV</li><li>stereo camera: <ul><li>The combination of two cameras with overlapping fields of view and aligned image planes</li><li>allow depth estimation from synchronized image pairs</li><li>Pixel values from image can be matched to the other image producing a disparity map of the scene. This disparity can then be used to estimate depth at each pixel.</li></ul></li></ul></li><li>Lidar:<ul><li>involves shooting light beams into the environment and measuring the reflected return.</li><li>include a spinning element with multiple stacked light sources</li><li>output detailed 3D scene geometry from LIDAR point cloud</li><li>not effected by the environments lighting. So do not face the same challenges as cameras when operating in poor or variable lighting conditions</li><li>Comparison metrics:<ul><li>Number of beams: 8, 16, 32, and 64</li><li>Points per second: The faster the point collection, the more detailed the 3D point cloud can be.</li><li>Rotation rate: The higher this rate, the faster the 3D point clouds are updated.</li><li>Field of view</li></ul></li><li>Upcoming: Solid state LIDAR<ul><li>without a rotational component of the typical LIDARs</li><li>to become extremely low-cost and reliable.</li></ul></li></ul></li><li>RADAR<ul><li>radio detection and ranging</li><li>robust object detection and relative speed estimation</li><li>particularly useful in adverse weather as they are mostly unaffected by precipitation.</li><li>Comparison metrics: <ul><li>range </li><li>field of view </li><li>position and speed accuracy</li></ul></li><li>Configurations: <ul><li>WFOV (Wide FOV), short range </li><li>NFOV (Narrow FOV), long range</li></ul></li></ul></li><li>Ultrasonic<ul><li>for sound navigation and ranging</li><li>Short-range all-weather distance measurement</li><li>Ideal for low-cost parking solutions</li><li>Unaffected by lighting, precipitation</li><li>Comparison metrics: <ul><li>Range</li><li>FOV</li><li>Cost</li></ul></li></ul></li><li>GNSS/IMU:<ul><li>Global Navigation Satellite Systems (e.g. GPS or Galileo) and Inertial measurement units</li><li>Direct measure of ego vehicle states <ul><li>position, velocity(GNSS): varying accuracies:RTK,PPP,DGPS </li><li>angular rotation rate(IMU)</li><li>acceleration(IMU)</li><li>heading (IMU, GPS)</li></ul></li></ul></li><li>Wheel odometry sensors<ul><li>Tracks wheel velocities and orientation</li><li>Uses these to calculate overall speed and orientation of car <ul><li>speed accuracy </li><li>position drift</li></ul></li></ul></li></ul><p><strong>Self-driving computing hardware</strong></p><ul><li>Need a”self-driving brain”: main decision makingunit of the car</li><li>Image processing, Object detection, Mapping <ul><li>GPUs - Graphic Processing Unit </li><li>FPGAs - Field Programmable Gate Array</li><li>ASICs - Application Specific Integrated Chip</li></ul></li><li>Synchronization hardware<ul><li>To synchronize different modules and provide a common clock</li><li>GPS relies on extremely accurate timing to function, and as such can act as an appropriate reference clock when available.</li><li>sensor measurements must be timestamped with consistent times for sensor fusion to function correctly.</li></ul></li><li>Sensor placement:<br><img src="/blog/images/self_driving01.jpg" width="50%" height="50%"></li></ul><h3 id="Hardware-Configuration-Design"><a href="#Hardware-Configuration-Design" class="headerlink" title="Hardware Configuration Design"></a>Hardware Configuration Design</h3><p><strong>Sensor coverage requirements for different scenarios</strong></p><ul><li>Assumptions:<ul><li>Aggressive deceleration: $5 m/s^2$</li><li>Comfortable deceleration: $2 m/s^2$<ul><li>This is the norm，unless otherwise stated</li></ul></li><li>Stopping distance: $d=\frac {v^2}{2a}$</li></ul></li></ul><p><em>Highway driving</em></p><ul><li>Broadly,3 kinds of maneuvers: Emergency Stop, Maintain Speed, Lane change</li><li>Emergency Stop:<ul><li>Longitudinal Coverage: Assume we are speeding at 120kmph</li><li>Stopping distance could be ~110 metres; aggressive deceleration</li><li>Lateral coverage: At least adjacent lanes, since we may change lanes to avoid a hard stop.</li></ul></li><li>Maintain Speed<ul><li>Relative speeds are typically less than 30 kmph.</li><li>Longitudinal coverage: At least~100 metres in front.</li><li>Both vehicles are moving, so don’t need to look as far as emergency-stop case.</li><li>Lateral Coverage: Usually current lane Adjacent lanes would be preferred for merging vehicle detection.</li></ul></li><li>Lane Change</li><li>summary:<br><img src="/blog/images/self_driving02.jpg" width="50%" height="50%"></li></ul><p><em>Urban driving</em></p><ul><li>Broadly,6 kinds of maneuvers: <ul><li>Emergency Stop, Maintain Speed, Lane Change</li><li>Overtaking, Turning,crossing at intersections, Passing roundabouts</li></ul></li><li>Overtaking:<ul><li>Longitudinal coverage: if overtaking a parked or moving vehicle, need to detect oncoming traffic beyond point of return to own lane.</li><li>Lateral coverage: always need to observe adjacent lanes. Need to observe additional lanes if other vehicles can move into adjacent lanes.</li></ul></li><li>Intersections:<ul><li>Observe beyond intersection for approaching vehicles, pedestrian crossings, clear exit lanes.</li><li>Requires near omni-directional sensing for arbitrary intersection angles.</li></ul></li><li>Roundabouts:<ul><li>Lateral coverage: Vehicles are slower than usual, limited range requirement.</li><li>Longitudinal coverage: Due to the shape of theroundabout, need a wider field of view.</li></ul></li><li>Summary:<br><img src="/blog/images/self_driving03.jpg" width="50%" height="50%"></li></ul><p><strong>Overall coverage,blind spots</strong><br><img src="/blog/images/self_driving04.jpg" width="50%" height="50%"></p><h3 id="Software-Architecture"><a href="#Software-Architecture" class="headerlink" title="Software Architecture"></a>Software Architecture</h3><p><strong>the basic architecture of a typical self-driving software</strong><br><img src="/blog/images/self_driving05.jpg" width="50%" height="50%"></p><p><strong>Identify the standard software decomposition</strong></p><ul><li>Environment Perception<ul><li>Localization: GPS/IMU/Wheel Odometry</li><li>Dynamic object detection -&gt; Dynamic object tracking -&gt; Object Motion Prediction: LIDAR, cameras, Radar</li><li>Static object detection: HD road Map</li></ul></li><li>Environment Mapping<ul><li>Occupancy Grid Map: Object tracks, LIDAR</li><li>Localization Map</li><li>Detailed Road Map</li></ul></li><li>Motion Planning<ul><li>Mission Planner</li><li>Behavior planner</li><li>Local planner</li></ul></li><li>Controller<ul><li>Velocity controller: throttle percentage, brake percentage</li><li>Steering controller: steering angle</li></ul></li><li>System Supervisor<ul><li>Hardware supervisor: sensor outputs</li><li>Software supervisor: Environment perception, environment mapping, motion planning, controller</li></ul></li></ul><h3 id="Environment-Representation"><a href="#Environment-Representation" class="headerlink" title="Environment Representation"></a>Environment Representation</h3><p><strong>Localization point cloud or feature map</strong></p><ul><li>localization of vehicle in the environment.</li><li>Collects continuous sets in LIDAR</li><li>The difference between LIDAR maps is used to calculate the movement of the autonomous vehicle</li></ul><p><strong>Occupancy grid map</strong></p><ul><li>collision avoidance with static objects.</li><li>Discretized fine grain grid map<ul><li>Can be 2Dor 3D</li></ul></li><li>Occupancy by a static object<ul><li>Trees and buildings</li></ul></li><li>Curbs and other non drivable surfaces<ul><li>Dynamic objects are removed</li></ul></li></ul><p><strong>Detailed road map</strong></p><ul><li>path planning</li><li>traffic regulation, lane boundaries</li><li>3 Methods of creation:<ul><li>Fully Online</li><li>Fully Offline</li><li>Created Offline and Updated Online</li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;From Coursera, Introduction to Self-Driving Cars by University of Toronto&lt;br&gt;&lt;a href=&quot;https://www.coursera.org/specializations/self-drivi
      
    
    </summary>
    
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
      <category term="Self-driving" scheme="http://tracyxinwang.site/blog/tags/Self-driving/"/>
    
  </entry>
  
  <entry>
    <title>Coursera Self-Driving 01 The Requirements for Autonomy</title>
    <link href="http://tracyxinwang.site/blog/2019/07/20/coursera_self_driving01/"/>
    <id>http://tracyxinwang.site/blog/2019/07/20/coursera_self_driving01/</id>
    <published>2019-07-20T06:07:23.000Z</published>
    <updated>2019-07-20T09:41:18.000Z</updated>
    
    <content type="html"><![CDATA[<p>From Coursera, Introduction to Self-Driving Cars by University of Toronto<br><a href="https://www.coursera.org/specializations/self-driving-cars?action=enroll" target="_blank" rel="noopener">https://www.coursera.org/specializations/self-driving-cars?action=enroll</a></p><h2 id="The-Requirements-for-Autonomy"><a href="#The-Requirements-for-Autonomy" class="headerlink" title="The Requirements for Autonomy"></a>The Requirements for Autonomy</h2><p>Some terms and definitions:<br><strong>Driving task</strong>:</p><ul><li>perceiving the environmrnt</li><li>Planning how to reach from point A to B</li><li>Controlling the vehicle</li></ul><p>Operational Design Domain (ODD)</p><h3 id="Taxonomy-of-Driving"><a href="#Taxonomy-of-Driving" class="headerlink" title="Taxonomy of Driving"></a>Taxonomy of Driving</h3><p>How to classify driving system automation?</p><ul><li>Driver attention requirements</li><li>Driver action requirements</li><li>What exactly makes up a driving task?<ul><li>Lateral control: steering</li><li>Longitudinal control: braking，accelerating</li><li>Object and Event Detection and Response(OEDR)：detection，reaction</li><li>Planning: long term, short term</li><li>Miscellaneous</li></ul></li></ul><p><strong>Taxonomy</strong>:</p><ul><li>Level 0: no automation<ul><li>regular vehicles, no automation</li><li>all be done by the driver</li></ul></li><li>Level 1: Driving Assistance<ul><li>either Longitudinal or Lateral control or both</li><li>e.g.:<ul><li>Adaptive Cruise Control: can control speed, driver has to steer</li><li>Lane Keeping Assistance: can help you stay in your lane,if you drift</li></ul></li></ul></li><li>Level 2: Partial Driving Automation<ul><li>need both Longitudinal <em>and</em> Lateral Control </li><li>e.g.:<ul><li>GM Super Cruise</li><li>Nissan ProPilot Assist</li></ul></li></ul></li><li>Level 3: Conditional Driving Automation<ul><li>Longitudinal + Lateral Control + OEOR</li><li>Includes automated object and event detection and response (Key differece between level 2)</li><li>e.g. Audi A8 Sedan</li></ul></li><li>Level 4: High Driving Automation <ul><li>Longitudinal + Lateral Control + OEOR + Fallback</li><li>can handle emergencies autonomously, driver can entirely focus on other tasks. But may need driver to handle specific emergencies.</li><li>e.g.: Waymo</li></ul></li><li>Level 5: High Driving Automation<ul><li>Longitudinal + Lateral Control + OEOR + Fallback + Unlirmited ODD</li></ul></li></ul><h3 id="Requirement-for-perception"><a href="#Requirement-for-perception" class="headerlink" title="Requirement for perception"></a>Requirement for perception</h3><p><strong>What is perception</strong></p><ul><li>identification:<ul><li>to know what is the object in front</li></ul></li><li>understanding motion:<ul><li>know what it will do</li></ul></li></ul><p><strong>Goals for perception</strong></p><ul><li>Static:<ul><li>Road and lane markings(on-road)</li><li>Curbs(off-road)</li><li>Traffic lights(off-road)</li><li>Road signs(off-road)</li><li>Construction signs, obstructions, and more(on-road)</li></ul></li><li>dynamic objects (on-road): we need to predoct their motion<ul><li>Vehicles<ul><li>4 wheelers(cars, truck…)</li><li>2 wheelers(motorbikes, bicycles…)</li></ul></li><li>Pedestrians</li></ul></li><li>Ego requirements<ul><li>Position</li><li>Velocity, acceleration</li><li>Orientation, angular motion</li></ul></li></ul><p><strong>Challenges to perception</strong></p><ul><li>Robust detection and segmentation<ul><li>use Machine Learning, deep learning</li><li>Snesor uncertainty: sensors may be suddenly broken</li><li>Occlusion, reflection</li><li>Illumination, lens flare</li><li>Weather, precipitation</li></ul></li></ul><h3 id="Driving-decision-and-actions"><a href="#Driving-decision-and-actions" class="headerlink" title="Driving decision and actions"></a>Driving decision and actions</h3><p><strong>Planning</strong><br>Making decisions:</p><ul><li>Long term:<ul><li>how to navigate from New York to Los Angeles</li></ul></li><li>Short term:<ul><li>Can I change my lane to the lane right of me?</li><li>Can I pass this intersection and join the left road?</li></ul></li><li>Immediate <ul><li>Can I stay on track on this curved road?</li><li>Accelerate or brake, by how much?</li></ul></li></ul><p><strong>Rule Based Planning</strong></p><ul><li>What we just did was rule based planning<ul><li>Involved decision trees!</li></ul></li><li>In reactive rule based planning, we have rules that take into account the current state of ego and other objects and give decisions.</li><li>Examples: <ul><li>If there is a pedestrian on the road, stop.</li><li>If speed limit changes, adjust speed to match it.</li></ul></li></ul><p><strong>Types of planning</strong></p><ul><li>Predictive Planning:<ul><li>Make predictions about other vehicles and how they are moving.Then use these predictions to inform our decisions.</li><li>Example: <ul><li>That car has been stopped for the last 10 seconds. It is going to be stopped for the next few seconds.</li><li></li></ul></li><li>relies on the accuracy of prediction</li></ul></li><li>Reactive planning</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;From Coursera, Introduction to Self-Driving Cars by University of Toronto&lt;br&gt;&lt;a href=&quot;https://www.coursera.org/specializations/self-drivi
      
    
    </summary>
    
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
      <category term="Self-driving" scheme="http://tracyxinwang.site/blog/tags/Self-driving/"/>
    
  </entry>
  
  <entry>
    <title>Python核心技术与实战13 Python 模块化</title>
    <link href="http://tracyxinwang.site/blog/2019/06/07/python13/"/>
    <id>http://tracyxinwang.site/blog/2019/06/07/python13/</id>
    <published>2019-06-07T06:07:23.000Z</published>
    <updated>2019-07-22T08:41:12.656Z</updated>
    
    <content type="html"><![CDATA[<p><strong>To be practice!</strong></p><h3 id="简单模块"><a href="#简单模块" class="headerlink" title="简单模块"></a>简单模块</h3><ul><li>最简单的模块化方式，就是把函数、类、常量拆分到不同的文件，把它们放在同一个文件夹，然后使用from your_file import function_name，class_name的方式调用。之后，这些函数和类就可以在文件内直接使用了。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># utils.py</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_sum</span><span class="params">(a, b)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> a + b</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># class_utils.py</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Encoder</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">encode</span><span class="params">(self, s)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> s[::<span class="number">-1</span>]</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Decoder</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">decode</span><span class="params">(self, s)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">''</span>.join(reversed(list(s)))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># main.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> get_sum</span><br><span class="line"><span class="keyword">from</span> class_utils <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">print(get_sum(<span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">encoder = Encoder()</span><br><span class="line">decoder = Decoder()</span><br><span class="line"></span><br><span class="line">print(encoder.encode(<span class="string">'abcde'</span>))</span><br><span class="line">print(decoder.decode(<span class="string">'edcba'</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">########## 输出 ##########</span></span><br><span class="line"></span><br><span class="line"><span class="number">3</span></span><br><span class="line">edcba</span><br><span class="line">abcde</span><br></pre></td></tr></table></figure><p>但是所有文件都堆在一个文件夹下也并不是办法，于是，我们试着建一些子文件夹：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># utils/utils.py</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_sum</span><span class="params">(a, b)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> a + b</span><br></pre></td></tr></table></figure></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># utils/class_utils.py</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Encoder</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">encode</span><span class="params">(self, s)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> s[::<span class="number">-1</span>]</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Decoder</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">decode</span><span class="params">(self, s)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">''</span>.join(reversed(list(s)))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># src/sub_main.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.path.append(<span class="string">".."</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> utils.class_utils <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">encoder = Encoder()</span><br><span class="line">decoder = Decoder()</span><br><span class="line"></span><br><span class="line">print(encoder.encode(<span class="string">'abcde'</span>))</span><br><span class="line">print(decoder.decode(<span class="string">'edcba'</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">########## 输出 ##########</span></span><br><span class="line"></span><br><span class="line">edcba</span><br><span class="line">abcde</span><br></pre></td></tr></table></figure><p> <br></p><ul><li><p>我们的文件结构是下面这样的：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── utils</span><br><span class="line">│   ├── utils.py</span><br><span class="line">│   └── class_utils.py</span><br><span class="line">├── src</span><br><span class="line">│   └── sub_main.py</span><br><span class="line">└── main.py</span><br></pre></td></tr></table></figure></li><li><p>main.py调用子目录的模块时，只需要使用.代替/来表示子目录，utils.utils表示utils 子文件夹下的utils.py模块就行。</p></li><li>如果我们想调用上层目录呢？注意，sys.path.append（”..”）表示将当前程序所在位置向上提了一级，之后就能调用utils的模块了。</li><li>同时要注意一点，import 同一个模块只会被执行一次，这样就可以防止重复导入模块出现问题。当然，良好的编程习惯应该杜绝代码多次导入的情况。</li><li>你可能在许多教程中看到过这样的要求：我们还需要在模块所在的文件夹新建一个_initpy，内容可以为空，也可以用来表述包对外暴露的模块接口。不过，事实上，这是Python2的规范。在Python3规范中，_init.py并不是必须的，很多教程里没提过这一点，或者没讲明白，我希望你还是能注意到这个地方。</li></ul><h3 id="项目模块化"><a href="#项目模块化" class="headerlink" title="项目模块化"></a>项目模块化</h3><p>使用绝对路径来导入文件<br>例子：使用Pycharm,项目结构如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── proto</span><br><span class="line">│   ├── mat.py</span><br><span class="line">├── utils</span><br><span class="line">│   └── mat_mul.py</span><br><span class="line">└── src</span><br><span class="line">    └── main.py</span><br></pre></td></tr></table></figure></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># proto/mat.py</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Matrix</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, data)</span>:</span></span><br><span class="line">        self.data = data</span><br><span class="line">        self.n = len(data)</span><br><span class="line">        self.m = len(data[<span class="number">0</span>])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># utils/mat_mul.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> proto.mat <span class="keyword">import</span> Matrix</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mat_mul</span><span class="params">(matrix_1: Matrix, matrix_2: Matrix)</span>:</span></span><br><span class="line">    <span class="keyword">assert</span> matrix_1.m == matrix_2.n</span><br><span class="line">    n, m, s = matrix_1.n, matrix_1.m, matrix_2.m</span><br><span class="line">    result = [[<span class="number">0</span> <span class="keyword">for</span> _ <span class="keyword">in</span> range(n)] <span class="keyword">for</span> _ <span class="keyword">in</span> range(s)]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(s):</span><br><span class="line">            <span class="keyword">for</span> k <span class="keyword">in</span> range(m):</span><br><span class="line">                result[i][k] += matrix_1.data[i][j] * matrix_2.data[j][k]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> Matrix(result)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># src/main.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> proto.mat <span class="keyword">import</span> Matrix</span><br><span class="line"><span class="keyword">from</span> utils.mat_mul <span class="keyword">import</span> mat_mul</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">a = Matrix([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]])</span><br><span class="line">b = Matrix([[<span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>]])</span><br><span class="line"></span><br><span class="line">print(mat_mul(a, b).data)</span><br><span class="line"></span><br><span class="line"><span class="comment">########## 输出 ##########</span></span><br><span class="line"></span><br><span class="line">[[<span class="number">19</span>, <span class="number">22</span>], [<span class="number">43</span>, <span class="number">50</span>]]</span><br></pre></td></tr></table></figure><p> <br></p><ul><li>这个例子和前面的例子长得很像，但请注意uti1s/mat_mul.py，你会发现，它import Matrix的方式是from proto.mat。这种做法，直接从项目根目录中导入，并依次向下导入模块mat.py中的Matrix，而不是使用..导入上一级文件夹。</li><li><p>Python解释器在遇到import的时候，它会在一个特定的列表中寻找模块。这个特定的列表，可以用下面的方式拿到：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys  </span><br><span class="line"></span><br><span class="line">print(sys.path)</span><br><span class="line"></span><br><span class="line"><span class="comment">########## 输出 ##########</span></span><br><span class="line"></span><br><span class="line">[<span class="string">''</span>, <span class="string">'/usr/lib/python36.zip'</span>, <span class="string">'/usr/lib/python3.6'</span>, <span class="string">'/usr/lib/python3.6/lib-dynload'</span>, <span class="string">'/usr/local/lib/python3.6/dist-packages'</span>, <span class="string">'/usr/lib/python3/dist-packages'</span>]</span><br></pre></td></tr></table></figure></li><li><p>可以看到第一项为空，而Pycharm会将这一项设置为项目根目录的绝对地址，这样在运行main.py时实际上是从根目录去找相应的包的。</p></li><li>在普通Python运行环境中，可以通过修改 PYTHONHOME 来实现绝对路径的添加。Python的Virtual Environment（虚拟运行环境），可以通过Virtualenv工具，非常方便地创建一个全新的Python运行环境。这样能够打造一个独立的运行环境来保持包和模块的纯净性。<ul><li>在一个Virtual Environment里，你能找到一个文件叫activate，在这个文件的末尾，填上下面的内容, 在每次通过activate激活这个运行时环境的时候，它就会自动将项目的根目录添加到搜索路径中去。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export PYTHONPATH=&quot;/home/ubuntu/workspace/your_projects&quot;</span><br></pre></td></tr></table></figure></li></ul></li></ul><h3 id="神奇的-if-name-‘main‘"><a href="#神奇的-if-name-‘main‘" class="headerlink" title="神奇的 if name == ‘main‘"></a>神奇的 if <strong>name</strong> == ‘<strong>main</strong>‘</h3><ul><li>Python是脚本语言，和C++、Java最大的不同在于，不需要显式提供main()函数入口<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── utils.py</span><br><span class="line">├── utils_with_main.py</span><br><span class="line">├── main.py</span><br><span class="line">└── main_2.py</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># utils.py</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_sum</span><span class="params">(a, b)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> a + b</span><br><span class="line"></span><br><span class="line">print(<span class="string">'testing'</span>)</span><br><span class="line">print(<span class="string">'&#123;&#125; + &#123;&#125; = &#123;&#125;'</span>.format(<span class="number">1</span>, <span class="number">2</span>, get_sum(<span class="number">1</span>, <span class="number">2</span>)))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># utils_with_main.py</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_sum</span><span class="params">(a, b)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> a + b</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    print(<span class="string">'testing'</span>)</span><br><span class="line">    print(<span class="string">'&#123;&#125; + &#123;&#125; = &#123;&#125;'</span>.format(<span class="number">1</span>, <span class="number">2</span>, get_sum(<span class="number">1</span>, <span class="number">2</span>)))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># main.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> get_sum</span><br><span class="line"></span><br><span class="line">print(<span class="string">'get_sum: '</span>, get_sum(<span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">########## 输出 ##########</span></span><br><span class="line"></span><br><span class="line">testing</span><br><span class="line"><span class="number">1</span> + <span class="number">2</span> = <span class="number">3</span></span><br><span class="line">get_sum: <span class="number">3</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># main_2.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> utils_with_main <span class="keyword">import</span> get_sum</span><br><span class="line"></span><br><span class="line">print(<span class="string">'get_sum_2: '</span>, get_sum(<span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">########## 输出 ##########</span></span><br><span class="line"></span><br><span class="line">get_sum_2: <span class="number">3</span></span><br></pre></td></tr></table></figure><p> <br></p><ul><li>import在导入文件的时候，会自动把所有暴露在外面的代码全都执行一遍。因此，如果你要把一个东西封装成模块，又想让它可以执行的话，你必须将要执行的代码放在’<code>if __name==__main__</code>下面。</li><li>其实，<code>__name__</code>作为Python的魔术内置参数，本质上是模块对象的一个属性。我们使用import 语句时，<code>__name__</code>就会被赋值为该模块的名字，自然就不等于<code>__main__</code>了。</li></ul><p>from module_name import *和import module_name 的区别：</p><ul><li>from module_name import * 会把 module 中所有的函数和类全拿过来，如果和其他函数名类名有冲突就会出问题；</li><li>import model_name 也会导入所有函数和类，但是调用的时候必须使用 model_name.func 的方法来调用，等于增加了一层 layer，有效避免冲突。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;To be practice!&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&quot;简单模块&quot;&gt;&lt;a href=&quot;#简单模块&quot; class=&quot;headerlink&quot; title=&quot;简单模块&quot;&gt;&lt;/a&gt;简单模块&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;最简单的模块化方式，就是把函数、
      
    
    </summary>
    
    
      <category term="Coding" scheme="http://tracyxinwang.site/blog/tags/Coding/"/>
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
      <category term="Python" scheme="http://tracyxinwang.site/blog/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Python核心技术与实战12 实现一个搜索引擎</title>
    <link href="http://tracyxinwang.site/blog/2019/06/05/python12/"/>
    <id>http://tracyxinwang.site/blog/2019/06/05/python12/</id>
    <published>2019-06-05T01:07:23.000Z</published>
    <updated>2019-07-22T03:35:40.017Z</updated>
    
    <content type="html"><![CDATA[<p><strong>To be practice!</strong></p><h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><ul><li>一个搜索引擎由搜索器、索引器、检索器和用户接口四个部分组成。</li><li>搜索器，就是我们常提到的爬虫（scrawler），它能在互联网上大量爬取各类网站的内容，送给索引器。索引器拿到网页和内容后，会对内容进行处理，形成索引（index），存储于内部的数据库等待检索。</li><li>用户接口是指网页和App前端界面，例如百度和谷歌的搜索页面。用户通过用户接口，向搜索引擎发出询问（query），询问解析后送达检索器；检索器高效检索后，再将结果返回给用户。</li></ul><p>先定义 SearchEngineBase 基类：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">class SearchEngineBase(object):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        pass</span><br><span class="line"></span><br><span class="line">    def add_corpus(self, file_path):</span><br><span class="line">        with open(file_path, &apos;r&apos;) as fin:</span><br><span class="line">            text = fin.read()</span><br><span class="line">        self.process_corpus(file_path, text)</span><br><span class="line"></span><br><span class="line">    def process_corpus(self, id, text):</span><br><span class="line">        raise Exception(&apos;process_corpus not implemented.&apos;)</span><br><span class="line"></span><br><span class="line">    def search(self, query):</span><br><span class="line">        raise Exception(&apos;search not implemented.&apos;)</span><br><span class="line"></span><br><span class="line">def main(search_engine):</span><br><span class="line">    for file_path in [&apos;1.txt&apos;, &apos;2.txt&apos;, &apos;3.txt&apos;, &apos;4.txt&apos;, &apos;5.txt&apos;]:</span><br><span class="line">        search_engine.add_corpus(file_path)</span><br><span class="line"></span><br><span class="line">    while True:</span><br><span class="line">        query = input()</span><br><span class="line">        results = search_engine.search(query)</span><br><span class="line">        print(&apos;found &#123;&#125; result(s):&apos;.format(len(results)))</span><br><span class="line">        for result in results:</span><br><span class="line">            print(result)</span><br></pre></td></tr></table></figure></p><ul><li>SearchEngineBase可以被继承，继承的类分别代表不同的算法引擎。每一个引擎都应该实现process_corpus()和search()两个函数，对应我们刚刚提到的索引器和检索器。main()函数提供搜索器和用户接口，于是一个简单的包装界面就有了。</li><li>具体看这段代码：<ul><li>add_corpus() 函数负责读取文件内容，将文件路径作为ID，连同内容一起送到process_corpus中。</li><li>process_corpus 需要对内容进行处理，然后文件路径为ID，将处理后的内容存下来。处理后的内容，就叫做索引（index）。</li><li>search 则给定一个询问，处理询问，再通过索引检索，然后返回。</li></ul></li></ul><p>然后定义一个基本可以工作的搜索引擎：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">class SimpleEngine(SearchEngineBase):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(SimpleEngine, self).__init__()</span><br><span class="line">        self.__id_to_texts = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    def process_corpus(self, id, text):</span><br><span class="line">        self.__id_to_texts[id] = text</span><br><span class="line"></span><br><span class="line">    def search(self, query):</span><br><span class="line">        results = []</span><br><span class="line">        for id, text in self.__id_to_texts.items():</span><br><span class="line">            if query in text:</span><br><span class="line">                results.append(id)</span><br><span class="line">        return results</span><br><span class="line"></span><br><span class="line">search_engine = SimpleEngine()</span><br><span class="line">main(search_engine)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">########## 输出 ##########</span><br><span class="line"></span><br><span class="line">simple</span><br><span class="line">found 0 result(s):</span><br><span class="line">little</span><br><span class="line">found 2 result(s):</span><br><span class="line">1.txt</span><br><span class="line">2.txt</span><br></pre></td></tr></table></figure></p><ul><li>SimpleEngine 实现了一个继承SearchEngineBase的子类，继承并实现了process_corpus和search 接口，同时，也顺手继承了add_corpus函数（当然你想重写也是可行的），因此我们可以在main()函数中直接调取。</li><li>在新的构造函数中，se1f.__id_to_texts={}初始化了自己的私有变量，也就是这个用来存储文件名到文件内容的字典。</li><li>process_corpus()函数则非常直白地将文件内容插入到字典中。这里注意，ID需要是唯一的，不然相同ID的新内容会覆盖掉旧的内容。</li><li>search 直接枚举字典，从中找到要搜索的字符串。如果能够找到，则将ID放到结果列表中，最后返回。</li></ul><h3 id="Bag-of-Words-and-Inverted-Index"><a href="#Bag-of-Words-and-Inverted-Index" class="headerlink" title="Bag of Words and Inverted Index"></a>Bag of Words and Inverted Index</h3><p>先实现一个名叫Bag of Words的搜索模型:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">import re</span><br><span class="line"></span><br><span class="line">class BOWEngine(SearchEngineBase):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(BOWEngine, self).__init__()</span><br><span class="line">        self.__id_to_words = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    def process_corpus(self, id, text):</span><br><span class="line">        self.__id_to_words[id] = self.parse_text_to_words(text)</span><br><span class="line"></span><br><span class="line">    def search(self, query):</span><br><span class="line">        query_words = self.parse_text_to_words(query)</span><br><span class="line">        results = []</span><br><span class="line">        for id, words in self.__id_to_words.items():</span><br><span class="line">            if self.query_match(query_words, words):</span><br><span class="line">                results.append(id)</span><br><span class="line">        return results</span><br><span class="line">    </span><br><span class="line">    @staticmethod</span><br><span class="line">    def query_match(query_words, words):</span><br><span class="line">        for query_word in query_words:</span><br><span class="line">            if query_word not in words:</span><br><span class="line">                return False</span><br><span class="line">        return True</span><br><span class="line"></span><br><span class="line">    @staticmethod</span><br><span class="line">    def parse_text_to_words(text):</span><br><span class="line">        # 使用正则表达式去除标点符号和换行符</span><br><span class="line">        text = re.sub(r&apos;[^\w ]&apos;, &apos; &apos;, text)</span><br><span class="line">        # 转为小写</span><br><span class="line">        text = text.lower()</span><br><span class="line">        # 生成所有单词的列表</span><br><span class="line">        word_list = text.split(&apos; &apos;)</span><br><span class="line">        # 去除空白单词</span><br><span class="line">        word_list = filter(None, word_list)</span><br><span class="line">        # 返回单词的 set</span><br><span class="line">        return set(word_list)</span><br><span class="line"></span><br><span class="line">search_engine = BOWEngine()</span><br><span class="line">main(search_engine)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">########## 输出 ##########</span><br><span class="line"></span><br><span class="line">i have a dream</span><br><span class="line">found 3 result(s):</span><br><span class="line">1.txt</span><br><span class="line">2.txt</span><br><span class="line">3.txt</span><br><span class="line">freedom children</span><br><span class="line">found 1 result(s):</span><br><span class="line">5.txt</span><br></pre></td></tr></table></figure></p><ul><li>先来理解一个概念，BOW Model，即Bag of Words Model，中文叫做词袋模型。这是NLP领域最常见最简单的模型之一。</li><li>假设一个文本，不考虑语法、句法、段落，也不考虑词汇出现的顺序，只将这个文本看成这些词汇的集合。于是相应的，我们把id to texts 替换成id_to_words，这样就只需要存这些单词，而不是全部文章，也不需要考虑顺序。</li><li>process_corpus()函数调用类静态函数 parse_text_to_words，将文章打碎形成词袋，放入set之后再放到字典中。</li><li>search()函数则稍微复杂一些。这里我们假设，想得到的结果，是所有的搜索关键词都要出现在同一篇文章中。那么，我们需要同样打碎query得到一个set，然后把set中的每一个词，和我们的索引中每一篇文章进行核对，看一下要找的词是否在其中。而这个过程由静态函数query_match负责。</li></ul><p><strong>优化</strong></p><ul><li><p>遍历代价太大，而其实每次查询的query单词量不会很多；其次，词袋模型并不考虑单词间的顺序，但有些人希望单词按顺序出现，或者希望搜索的单词在文中离得近一些，这种情况下词袋模型就无能为力了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line">import re</span><br><span class="line"></span><br><span class="line">class BOWInvertedIndexEngine(SearchEngineBase):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(BOWInvertedIndexEngine, self).__init__()</span><br><span class="line">        self.inverted_index = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    def process_corpus(self, id, text):</span><br><span class="line">        words = self.parse_text_to_words(text)</span><br><span class="line">        for word in words:</span><br><span class="line">            if word not in self.inverted_index:</span><br><span class="line">                self.inverted_index[word] = []</span><br><span class="line">            self.inverted_index[word].append(id)</span><br><span class="line"></span><br><span class="line">    def search(self, query):</span><br><span class="line">        query_words = list(self.parse_text_to_words(query))</span><br><span class="line">        query_words_index = list()</span><br><span class="line">        for query_word in query_words:</span><br><span class="line">            query_words_index.append(0)</span><br><span class="line">        </span><br><span class="line">        # 如果某一个查询单词的倒序索引为空，我们就立刻返回</span><br><span class="line">        for query_word in query_words:</span><br><span class="line">            if query_word not in self.inverted_index:</span><br><span class="line">                return []</span><br><span class="line">        </span><br><span class="line">        result = []</span><br><span class="line">        while True:</span><br><span class="line">            </span><br><span class="line">            # 首先，获得当前状态下所有倒序索引的 index</span><br><span class="line">            current_ids = []</span><br><span class="line">            </span><br><span class="line">            for idx, query_word in enumerate(query_words):</span><br><span class="line">                current_index = query_words_index[idx]</span><br><span class="line">                current_inverted_list = self.inverted_index[query_word]</span><br><span class="line">                </span><br><span class="line">                # 已经遍历到了某一个倒序索引的末尾，结束 search</span><br><span class="line">                if current_index &gt;= len(current_inverted_list):</span><br><span class="line">                    return result</span><br><span class="line"></span><br><span class="line">                current_ids.append(current_inverted_list[current_index])</span><br><span class="line"></span><br><span class="line">            # 然后，如果 current_ids 的所有元素都一样，那么表明这个单词在这个元素对应的文档中都出现了</span><br><span class="line">            if all(x == current_ids[0] for x in current_ids):</span><br><span class="line">                result.append(current_ids[0])</span><br><span class="line">                query_words_index = [x + 1 for x in query_words_index]</span><br><span class="line">                continue</span><br><span class="line">            </span><br><span class="line">            # 如果不是，我们就把最小的元素加一</span><br><span class="line">            min_val = min(current_ids)</span><br><span class="line">            min_val_pos = current_ids.index(min_val)</span><br><span class="line">            query_words_index[min_val_pos] += 1</span><br><span class="line"></span><br><span class="line">    @staticmethod</span><br><span class="line">    def parse_text_to_words(text):</span><br><span class="line">        # 使用正则表达式去除标点符号和换行符</span><br><span class="line">        text = re.sub(r&apos;[^\w ]&apos;, &apos; &apos;, text)</span><br><span class="line">        # 转为小写</span><br><span class="line">        text = text.lower()</span><br><span class="line">        # 生成所有单词的列表</span><br><span class="line">        word_list = text.split(&apos; &apos;)</span><br><span class="line">        # 去除空白单词</span><br><span class="line">        word_list = filter(None, word_list)</span><br><span class="line">        # 返回单词的 set</span><br><span class="line">        return set(word_list)</span><br><span class="line"></span><br><span class="line">search_engine = BOWInvertedIndexEngine()</span><br><span class="line">main(search_engine)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">########## 输出 ##########</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">little</span><br><span class="line">found 2 result(s):</span><br><span class="line">1.txt</span><br><span class="line">2.txt</span><br><span class="line">little vicious</span><br><span class="line">found 1 result(s):</span><br><span class="line">2.txt</span><br></pre></td></tr></table></figure></li><li><p>新模型继续使用之前的接口，仍然只在init()、pr ocess_corpus()和search()三个函数进行修改。</p></li><li>开头的Inverted Index，即倒序索引，是非常有名的搜索引擎方法: 也就是说这次反过来，我们保留的是word-&gt;id的字典。于是情况就豁然开朗了，在search时，我们只需要把想要的query_word的几个倒序索引单独拎出来，然后从这几个列表中找共有的元素，那些共有的元素，即ID，就是我们想要的查询结果。这样，我们就避免了将所有的index过一遍的尴尬,这解决了遍历的问题</li><li>process_corpus 建立倒序索引。注意，这里的代码都是非常精简的。在工业界领域，需要一个unique ID生成器，来对每一篇文章标记上不同的ID，倒序索引也应该按照这个uniqueid来进行排序。</li><li>search()函数，会根据 query_words 拿到所有的倒序索引，如果拿不到，就表示有的query word不存在于任何文章中，直接返回空；拿到之后，运行一个“合并K个有序数组”的算法，从中拿到我们想要的ID，并返回。注意，这里用到的算法并不是最优的，最优的写法需要用最小堆来存储index。这是一道有名的leetcode hard题，有兴趣请参考：</li><li>关于实现搜索单词按顺序出现，或者搜索的单词在文中离得近一些的情况，我们需要在Inverted Index上，对于每篇文章也保留单词的位置信息，这样一来，在合并操作的时候处理一下就可以了。</li></ul><h3 id="LRU和多重继承"><a href="#LRU和多重继承" class="headerlink" title="LRU和多重继承"></a>LRU和多重继承</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">import pylru</span><br><span class="line"></span><br><span class="line">class LRUCache(object):</span><br><span class="line">    def __init__(self, size=32):</span><br><span class="line">        self.cache = pylru.lrucache(size)</span><br><span class="line">    </span><br><span class="line">    def has(self, key):</span><br><span class="line">        return key in self.cache</span><br><span class="line">    </span><br><span class="line">    def get(self, key):</span><br><span class="line">        return self.cache[key]</span><br><span class="line">    </span><br><span class="line">    def set(self, key, value):</span><br><span class="line">        self.cache[key] = value</span><br><span class="line"></span><br><span class="line">class BOWInvertedIndexEngineWithCache(BOWInvertedIndexEngine, LRUCache):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(BOWInvertedIndexEngineWithCache, self).__init__()</span><br><span class="line">        LRUCache.__init__(self)</span><br><span class="line">    </span><br><span class="line">    def search(self, query):</span><br><span class="line">        if self.has(query):</span><br><span class="line">            print(&apos;cache hit!&apos;)</span><br><span class="line">            return self.get(query)</span><br><span class="line">        </span><br><span class="line">        result = super(BOWInvertedIndexEngineWithCache, self).search(query)</span><br><span class="line">        self.set(query, result)</span><br><span class="line">        </span><br><span class="line">        return result</span><br><span class="line"></span><br><span class="line">search_engine = BOWInvertedIndexEngineWithCache()</span><br><span class="line">main(search_engine)</span><br><span class="line"></span><br><span class="line">########## 输出 ##########</span><br><span class="line"></span><br><span class="line">little</span><br><span class="line">found 2 result(s):</span><br><span class="line">1.txt</span><br><span class="line">2.txt</span><br><span class="line">little</span><br><span class="line">cache hit!</span><br><span class="line">found 2 result(s):</span><br><span class="line">1.txt</span><br><span class="line">2.txt</span><br></pre></td></tr></table></figure><ul><li>LRUCache定义了一个缓存类，你可以通过继承这个类来调用其方法。LRU缓存是一种很经典的缓存（同时，LRU的实现也是硅谷大厂常考的算法面试题，这里为了简单，我直接使用pylru这个包），它符合自然界的局部性原理，可以保留最近使用过的对象，而逐渐淘汰掉很久没有被用过的对象。</li><li>这里的缓存使用起来也很简单，调用has()函数判断是否在缓存中，如果在，调用get函数直接返回结果；如果不在，送入后台计算结果，然后再塞入缓存。</li><li><p>我们可以看到，BOWInvertedlndexEngineWithCache类，多重继承了两个类。首先，你需要注意的是构造函数。多重继承有两种初始化方法:</p><ul><li><p>第一种方法，用下面这行代码，直接初始化该类的第一个父类：不过使用这种方法时，要求继承链的最顶层父类必须要继承 object。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">super(BOWInvertedIndexEngineWithCache, self).__init__()</span><br></pre></td></tr></table></figure></li><li><p>第二种方法，对于多重继承，如果有多个构造函数需要调用，我们必须用传统的方法LRUCach e._init（self）。</p></li></ul></li><li>注意，search()函数被子类BOWInvertedlndexEngineWithCache 再次重载，但是我还需要调用BOWInvertedlndexEngine的search()函数，这时该怎么办呢？请看下面这行代码：这样我们可以强行调用被覆益的父类的函数<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">super(BOWInvertedIndexEngineWithCache, self).search(query)</span><br></pre></td></tr></table></figure></li></ul><p>关于私有化：<br>Python并没有真正的私有化支持，但可用下划线得到伪私有：</p><ul><li><code>_xxx</code> “单下划线 “ 开始的成员变量叫做保护变量，意思是只有类对象和子类对象自己能访问到这些变量，需通过类提供的接口进行访问；</li><li><code>__xxx</code> 类中的私有变量/方法名，只有类对象自己能访问，连子类对象也不能访问到这个数据。</li><li><code>__xxx__</code> 魔法函数，前后均有一个“双下划线” 代表python里特殊方法专用的标识，如 <strong>init</strong>() 代表类的构造函数。</li><li>如果想要强行访问父类的私有类型，做法是 self._ParentClass__var，这是非常不推荐的 hacky method。以下是示范代码：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">class A:</span><br><span class="line">    __a = 1</span><br><span class="line"></span><br><span class="line">class B(A):</span><br><span class="line">    pass</span><br><span class="line"></span><br><span class="line">b = B()</span><br><span class="line">print(b._A__a)</span><br></pre></td></tr></table></figure></li></ul><p>Reference:<br><a href="https://time.geekbang.org/column/article/98998" target="_blank" rel="noopener">https://time.geekbang.org/column/article/98998</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;To be practice!&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&quot;基本概念&quot;&gt;&lt;a href=&quot;#基本概念&quot; class=&quot;headerlink&quot; title=&quot;基本概念&quot;&gt;&lt;/a&gt;基本概念&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;一个搜索引擎由搜索器、索引器、检
      
    
    </summary>
    
    
      <category term="Coding" scheme="http://tracyxinwang.site/blog/tags/Coding/"/>
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
      <category term="Python" scheme="http://tracyxinwang.site/blog/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Python核心技术与实战11 面向对象</title>
    <link href="http://tracyxinwang.site/blog/2019/06/03/python11/"/>
    <id>http://tracyxinwang.site/blog/2019/06/03/python11/</id>
    <published>2019-06-03T13:07:23.000Z</published>
    <updated>2019-07-22T08:32:45.034Z</updated>
    
    <content type="html"><![CDATA[<h3 id="对象基础"><a href="#对象基础" class="headerlink" title="对象基础"></a>对象基础</h3><p>示例代码：<br>    <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">class Document():</span><br><span class="line">    def __init__(self, title, author, context):</span><br><span class="line">        print(&apos;init function called&apos;)</span><br><span class="line">        self.title = title</span><br><span class="line">        self.author = author</span><br><span class="line">        self.__context = context # __ 开头的属性是私有属性</span><br><span class="line"></span><br><span class="line">    def get_context_length(self):</span><br><span class="line">        return len(self.__context)</span><br><span class="line"></span><br><span class="line">    def intercept_context(self, length):</span><br><span class="line">        self.__context = self.__context[:length]</span><br><span class="line"></span><br><span class="line">harry_potter_book = Document(&apos;Harry Potter&apos;, &apos;J. K. Rowling&apos;, &apos;... Forever Do not believe any thing is capable of thinking independently ...&apos;)</span><br><span class="line"></span><br><span class="line">print(harry_potter_book.title)</span><br><span class="line">print(harry_potter_book.author)</span><br><span class="line">print(harry_potter_book.get_context_length())</span><br><span class="line"></span><br><span class="line">harry_potter_book.intercept_context(10)</span><br><span class="line"></span><br><span class="line">print(harry_potter_book.get_context_length())</span><br><span class="line"></span><br><span class="line">print(harry_potter_book.__context)</span><br><span class="line"></span><br><span class="line">########## 输出 ##########</span><br><span class="line"></span><br><span class="line">init function called</span><br><span class="line">Harry Potter</span><br><span class="line">J. K. Rowling</span><br><span class="line">77</span><br><span class="line">10</span><br><span class="line"></span><br><span class="line">---------------------------------------------------------------------------</span><br><span class="line">AttributeError                            Traceback (most recent call last)</span><br><span class="line">&lt;ipython-input-5-b4d048d75003&gt; in &lt;module&gt;()</span><br><span class="line">    22 print(harry_potter_book.get_context_length())</span><br><span class="line">    23 </span><br><span class="line">---&gt; 24 print(harry_potter_book.__context)</span><br><span class="line"></span><br><span class="line">AttributeError: &apos;Document&apos; object has no attribute &apos;__context&apos;</span><br></pre></td></tr></table></figure></p><ul><li>类：一群有着相似性的事物的集合，这里对应Python的class。</li><li>对象：集合中的一个事物，这里对应由class生成的某一个object，比如代码中的harry potter_book。</li><li>属性：对象的某个静态特征，比如上述代码中的title、author和_context。</li><li>函数：对象的某个动态能力，比如上述代码中的intercept_context()函数。</li><li><strong>init</strong> 表示构造函数，即在一个对象生成时会被自动调用的函数。我们能看到，<code>harry_po tter_book=Document(...)</code>这一行代码被执行的时候，<code>init function called</code>字符串会被打印出来。</li><li>而 get_context length()和intercept_context()则为类的普通函数，我们调用它们来对对象的属性做一些事情。</li><li>class Document 还有三个属性，title、author和_context分别表示标题、作者和内容，通过构造函数传入。这里代码很直观，我们可以看到，intercept_context 能修改对象harry_potter_book的_context 属性。</li><li>另外注意的一点是，如果一个属性以<code>__</code>（注意，此处有两个_）开头，我们就默认这个属性是私有属性。私有属性，是指不希望在类的函数之外的地方被访问和修改的属性。所以，你可以看到，title和author 能够很自由地被打印出来，但是print（harry potter_book.__context）就会报错。</li></ul><h3 id="进阶"><a href="#进阶" class="headerlink" title="进阶"></a>进阶</h3><pre><code><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">class Document():</span><br><span class="line">    </span><br><span class="line">    WELCOME_STR = &apos;Welcome! The context for this book is &#123;&#125;.&apos;</span><br><span class="line">    </span><br><span class="line">    def __init__(self, title, author, context):</span><br><span class="line">        print(&apos;init function called&apos;)</span><br><span class="line">        self.title = title</span><br><span class="line">        self.author = author</span><br><span class="line">        self.__context = context</span><br><span class="line">    </span><br><span class="line">    # 类函数</span><br><span class="line">    @classmethod</span><br><span class="line">    def create_empty_book(cls, title, author):</span><br><span class="line">        return cls(title=title, author=author, context=&apos;nothing&apos;)</span><br><span class="line">    </span><br><span class="line">    # 成员函数</span><br><span class="line">    def get_context_length(self):</span><br><span class="line">        return len(self.__context)</span><br><span class="line">    </span><br><span class="line">    # 静态函数</span><br><span class="line">    @staticmethod</span><br><span class="line">    def get_welcome(context):</span><br><span class="line">        return Document.WELCOME_STR.format(context)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">empty_book = Document.create_empty_book(&apos;What Every Man Thinks About Apart from Sex&apos;, &apos;Professor Sheridan Simove&apos;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(empty_book.get_context_length())</span><br><span class="line">print(empty_book.get_welcome(&apos;indeed nothing&apos;))</span><br><span class="line"></span><br><span class="line">########## 输出 ##########</span><br><span class="line"></span><br><span class="line">init function called</span><br><span class="line">7</span><br><span class="line">Welcome! The context for this book is indeed nothing.</span><br></pre></td></tr></table></figure></code></pre><ul><li>如何在一个类中定义一些常量，每个对象都可以方便访问这些常量而不用重新构造？:<ul><li>在Python的类里，只需要和函数并列地声明并赋值，就可以实现这一点，例如这段代码中的WELCOME_STR。</li><li>一种很常规的做法，是用全大写来表示常量，因此我们可以在类中使用self.WELCOME_STR，或者在类外使用Entity.WELCOME_STR，来表达这个字符</li></ul></li><li>如果一个函数不涉及到访问修改这个类的属性，而放到类外面有点不恰当，怎么做才能更优雅呢？<ul><li>针对这个问题，我们提出了<strong>类函数、成员函数和静态函数</strong>三个概念。</li><li>前两者产生的影响是动态的，能够访问或者修改对象的属性；</li><li>而静态函数则与类没有什么关联，最明显的特征便是，静态函数的第一个参数没有任何特殊性。</li><li>一般而言，<strong>静态函数</strong>可以用来做一些简单独立的任务，既方便测试，也能优化代码结构。静态函数还可以通过在函数前一行加上@staticmethod来表示，代码中也有相应的示例。这其实使用了装饰器的概念，我们会在后面的章节中详细讲解。</li><li>而<strong>类函数</strong>的第一个参数一般为cls，表示必须传一个类进来。类函数最常用的功能是实现不同的init 构造函数，比如上文代码中，我们使用create_empty_book类函数，来创造新的书籍对象，其context一定为’nothing’。这样的代码，就比你直接构造要清晰一些。类似的，类函数需要装饰器@classmethod 来声明。</li><li><strong>成员函数</strong>则是我们最正常的类的函数，它不需要任何装饰器声明，第一个参数self代表当前对象的引用，可以通过此函数，来实现想要的查询/修改类的属性等功能。</li></ul></li></ul><h3 id="继承"><a href="#继承" class="headerlink" title="继承"></a>继承</h3><p>既然类是一群相似的对象的集合，那么可不可以是一群相似的类的集合呢？这就涉及到类的继承</p><ul><li><p>类的继承，指的是一个类既拥有另一个类的特征，也拥有不同于另一个类的独特特征。在这里的第一个类叫做子类，另一个叫做父类，特征其实就是类的属性和函数。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">class Entity():</span><br><span class="line">    def __init__(self, object_type):</span><br><span class="line">        print(&apos;parent class init called&apos;)</span><br><span class="line">        self.object_type = object_type</span><br><span class="line">    </span><br><span class="line">    def get_context_length(self):</span><br><span class="line">        raise Exception(&apos;get_context_length not implemented&apos;)</span><br><span class="line">    </span><br><span class="line">    def print_title(self):</span><br><span class="line">        print(self.title)</span><br><span class="line"></span><br><span class="line">class Document(Entity):</span><br><span class="line">    def __init__(self, title, author, context):</span><br><span class="line">        print(&apos;Document class init called&apos;)</span><br><span class="line">        Entity.__init__(self, &apos;document&apos;)</span><br><span class="line">        self.title = title</span><br><span class="line">        self.author = author</span><br><span class="line">        self.__context = context</span><br><span class="line">    </span><br><span class="line">    def get_context_length(self):</span><br><span class="line">        return len(self.__context)</span><br><span class="line">    </span><br><span class="line">class Video(Entity):</span><br><span class="line">    def __init__(self, title, author, video_length):</span><br><span class="line">        print(&apos;Video class init called&apos;)</span><br><span class="line">        Entity.__init__(self, &apos;video&apos;)</span><br><span class="line">        self.title = title</span><br><span class="line">        self.author = author</span><br><span class="line">        self.__video_length = video_length</span><br><span class="line">    </span><br><span class="line">    def get_context_length(self):</span><br><span class="line">        return self.__video_length</span><br><span class="line"></span><br><span class="line">harry_potter_book = Document(&apos;Harry Potter(Book)&apos;, &apos;J. K. Rowling&apos;, &apos;... Forever Do not believe any thing is capable of thinking independently ...&apos;)</span><br><span class="line">harry_potter_movie = Video(&apos;Harry Potter(Movie)&apos;, &apos;J. K. Rowling&apos;, 120)</span><br><span class="line"></span><br><span class="line">print(harry_potter_book.object_type)</span><br><span class="line">print(harry_potter_movie.object_type)</span><br><span class="line"></span><br><span class="line">harry_potter_book.print_title()</span><br><span class="line">harry_potter_movie.print_title()</span><br><span class="line"></span><br><span class="line">print(harry_potter_book.get_context_length())</span><br><span class="line">print(harry_potter_movie.get_context_length())</span><br><span class="line"></span><br><span class="line">########## 输出 ##########</span><br><span class="line"></span><br><span class="line">Document class init called</span><br><span class="line">parent class init called</span><br><span class="line">Video class init called</span><br><span class="line">parent class init called</span><br><span class="line">document</span><br><span class="line">video</span><br><span class="line">Harry Potter(Book)</span><br><span class="line">Harry Potter(Movie)</span><br><span class="line">77</span><br><span class="line">120</span><br></pre></td></tr></table></figure></li><li><p>在上面的代码中，Document和Video它们有相似的地方，都有相应的标题、作者和内容等属性。我们可以从中抽象出一个叫做Entity的类，来作为它俩的父类。</p></li><li>首先需要注意的是构造函数。每个类都有构造函数，继承类在生成对象的时候，是不会自动调用父类的构造函数的，因此你必须在init()函数中显式调用父类的构造函数。它们的执行顺序是子类的构造函数-&gt;父类的构造函数。</li><li>其次需要注意父类get_context_length()函数。如果使用Entity 直接生成对象，调用get_context_length()函数，就会raise error中断程序的执行。这其实是一种很好的写法，叫做函数重写，可以使子类必须重新写一遍 get_context_length()函数，来覆盖掉原有函数。</li><li>最后需要注意到print title()函数，这个函数定义在父类中，但是子类的对象可以毫无阻力地使用它来打印title，这也就体现了继承的优势：减少重复的代码，降低系统的嫡值（即复杂度）。</li></ul><p><strong>抽象函数和抽象类</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">from abc import ABCMeta, abstractmethod</span><br><span class="line"></span><br><span class="line">class Entity(metaclass=ABCMeta):</span><br><span class="line">    @abstractmethod</span><br><span class="line">    def get_title(self):</span><br><span class="line">        pass</span><br><span class="line"></span><br><span class="line">    @abstractmethod</span><br><span class="line">    def set_title(self, title):</span><br><span class="line">        pass</span><br><span class="line"></span><br><span class="line">class Document(Entity):</span><br><span class="line">    def get_title(self):</span><br><span class="line">        return self.title</span><br><span class="line">    </span><br><span class="line">    def set_title(self, title):</span><br><span class="line">        self.title = title</span><br><span class="line"></span><br><span class="line">document = Document()</span><br><span class="line">document.set_title(&apos;Harry Potter&apos;)</span><br><span class="line">print(document.get_title())</span><br><span class="line"></span><br><span class="line">entity = Entity()</span><br><span class="line"></span><br><span class="line">########## 输出 ##########</span><br><span class="line"></span><br><span class="line">Harry Potter</span><br><span class="line"></span><br><span class="line">---------------------------------------------------------------------------</span><br><span class="line">TypeError                                 Traceback (most recent call last)</span><br><span class="line">&lt;ipython-input-7-266b2aa47bad&gt; in &lt;module&gt;()</span><br><span class="line">     21 print(document.get_title())</span><br><span class="line">     22 </span><br><span class="line">---&gt; 23 entity = Entity()</span><br><span class="line">     24 entity.set_title(&apos;Test&apos;)</span><br><span class="line"></span><br><span class="line">TypeError: Can&apos;t instantiate abstract class Entity with abstract methods get_title, set_title</span><br></pre></td></tr></table></figure></p><ul><li>Entity本身是没有什么用的，只需拿来定义Document和Video的一些基本元素就够了。不过，万一你不小心生成Entity的对象该怎么办呢？为了防止这样的手误，就引入了抽象类的概念。</li><li>抽象类是一种特殊的类，它生下来就是作为父类存在的，一旦对象化就会报错。同样，抽象函数定义在抽象类之中，子类必须重写该函数才能使用。相应的抽象函数，则是使用装饰器@abstractmethod来表示。</li><li>在上述代码中，entity=Entity()直接报错，只有通过Document 继承Entity才能正常使用。</li><li>这其实正是软件工程中一个很重要的概念，定义接口。大型工程往往需要很多人合作开发，比如在Facebook中，在idea提出之后，开发组和产品组首先会召开产品设计会，PM（Product Manager，产品经理）写出产品需求文档，然后迭代；TL（Team Leader，项目经理）编写开发文档，开发文档中会定义不同模块的大致功能和接口、每个模块之间如何协作、单元测试和集成测试、线上灰度测试、监测和日志等等一系列开发流程。</li></ul><p>Reference:<br>极客时间</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;对象基础&quot;&gt;&lt;a href=&quot;#对象基础&quot; class=&quot;headerlink&quot; title=&quot;对象基础&quot;&gt;&lt;/a&gt;对象基础&lt;/h3&gt;&lt;p&gt;示例代码：&lt;br&gt;    &lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td cl
      
    
    </summary>
    
    
      <category term="Coding" scheme="http://tracyxinwang.site/blog/tags/Coding/"/>
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
      <category term="Python" scheme="http://tracyxinwang.site/blog/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Python核心技术与实战10 匿名函数</title>
    <link href="http://tracyxinwang.site/blog/2019/05/31/python10/"/>
    <id>http://tracyxinwang.site/blog/2019/05/31/python10/</id>
    <published>2019-05-31T13:07:23.000Z</published>
    <updated>2019-07-22T03:35:05.071Z</updated>
    
    <content type="html"><![CDATA[<h3 id="函数基础"><a href="#函数基础" class="headerlink" title="函数基础"></a>函数基础</h3><ul><li><p>格式如下：</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lambda argument1, argument2,... argumentN : expression</span><br></pre></td></tr></table></figure></li><li><p>用法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">square = lambda x: x**2</span><br><span class="line">square(3)</span><br><span class="line"></span><br><span class="line">9</span><br></pre></td></tr></table></figure></li><li><p>lambda是一个表达式（expression），并不是一个语句（statement）。</p></li><li>lambda的主体是只有一行的简单表达式，并不能扩展成一个多行的代码块。</li></ul><h3 id="函数式编程"><a href="#函数式编程" class="headerlink" title="函数式编程"></a>函数式编程</h3><ul><li>函数式编程，是指代码中每一块都是不可变的（immutable），都由纯函数（pure function）的形式组成。这里的纯函数，是指函数本身相互独立、互不影响，对于相同的输入，总会有相同的输出，没有任何副作用。</li><li>Python 主要提供了这么几个函数：map()、filter())和reduce()，通常结合匿名函数lambda一起使用。</li><li><p>map(function，iterable)函数，前面的例子提到过，它表示，对iterable中的每个元素，都运用function这个函数，最后返回一个新的可遍历的集合。比如刚才列表的例子，要对列表中的每个元素乘以2，那么用map就可以表示为下面这样：</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">l = [1, 2, 3, 4, 5]</span><br><span class="line">new_list = map(lambda x: x * 2, l) # [2， 4， 6， 8， 10]</span><br></pre></td></tr></table></figure></li><li><p>filter(function，iterable)函数，和map函数类似，function同样表示一个函数对象。filter()函数表示对iterable中的每个元素，都使用function判断，并返回True或者False，最后将返回True的元素组成一个新的可遍历的集合。e.g.，比如我要返回一个列表中的所有偶数，可以写成下面这样：</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">l = [1, 2, 3, 4, 5]</span><br><span class="line">new_list = filter(lambda x: x % 2 == 0, l) # [2,4]</span><br></pre></td></tr></table></figure></li><li><p>reduce(function，iterable)函数，通常用来对一个集合做一些累积操作。function 同样是一个函数对象，规定它有两个参数，表示对iterable中的每个元素以及上一次调用后的结果，运用function 进行计算，所以最后返回的是一个单独的数值。e.g.，我想要计算某个列表元素的乘积，就可以用reduce()函数来表示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">l = [1, 2, 3, 4, 5]</span><br><span class="line">new_list = reduce(lambda x, y: x * y, l)    # 1*2*3*4*5=120</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;函数基础&quot;&gt;&lt;a href=&quot;#函数基础&quot; class=&quot;headerlink&quot; title=&quot;函数基础&quot;&gt;&lt;/a&gt;函数基础&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;格式如下：&lt;/p&gt;
  &lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;t
      
    
    </summary>
    
    
      <category term="Coding" scheme="http://tracyxinwang.site/blog/tags/Coding/"/>
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
      <category term="Python" scheme="http://tracyxinwang.site/blog/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Python核心技术与实战09 自定义函数</title>
    <link href="http://tracyxinwang.site/blog/2019/05/29/python09/"/>
    <id>http://tracyxinwang.site/blog/2019/05/29/python09/</id>
    <published>2019-05-29T13:07:23.000Z</published>
    <updated>2019-07-22T03:34:51.040Z</updated>
    
    <content type="html"><![CDATA[<h3 id="函数基础"><a href="#函数基础" class="headerlink" title="函数基础"></a>函数基础</h3><ul><li><p>定义：</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">def name(param1, param2, ..., paramN):</span><br><span class="line">    statements</span><br><span class="line">    return/yield value # optional</span><br></pre></td></tr></table></figure></li><li><p>和其他需要编译的语言（比如C语言）不一样的是，def是可执行语句，这意味着函数直到被调用前，都是不存在的。当程序调用函数时，def语句才会创建一个新的函数对象，并赋予其名字。</p></li><li>调用函数时，必须保证这个函数此前已经定义过.</li><li><p>但如果在某函数内部调用其他函数，函数间哪个声明在前、哪个在后就无所谓，因为def是可执行语句，函数在调用之前都不存在，我们只需保证调用时，所需的函数都已经声明定义。</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">def my_func(message):</span><br><span class="line">    my_sub_func(message) # 调用 my_sub_func() 在其声明之前不影响程序执行</span><br><span class="line">    </span><br><span class="line">def my_sub_func(message):</span><br><span class="line">    print(&apos;Got a message: &#123;&#125;&apos;.format(message))</span><br><span class="line"></span><br><span class="line">my_func(&apos;hello world&apos;)</span><br><span class="line"></span><br><span class="line"># 输出</span><br><span class="line">Got a message: hello world</span><br></pre></td></tr></table></figure></li><li><p>另外，Python函数的参数可以设定默认值, 如下。这样在调用函数func()时，如果参数param没有传入，则参数默认为0；而如果传入了参数param，其就会覆盖默认值。</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">def func(param = 0):</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure></li><li><p>Python不用考虑输入的数据类型，而是将其交给具体的代码去判断执行，同样的一个函数（如一个相加函数），可以同时应用在整型、列表、字符串等等的操作中。编程语言中，我们把这种行为称为多态。这也是Python 和其他语言，比如Java、C等很大的一个不同点。</p></li><li>因此，在函数开头进行数据类型检查很重要</li><li><p>函数嵌套：</p><ul><li><p>函数的嵌套能够保证内部函数的隐私。内部函数只能被外部函数所调用和访问，不会暴露在全局作用域，因此，如果你的函数内部有一些隐私数据（比如数据库的用户、密码等），不想暴露在外，那你就可以使用函数的的嵌套，将其封装在内部函数中，只通过外部函数来访问：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">def connect_DB():</span><br><span class="line">    def get_DB_configuration():</span><br><span class="line">        ...</span><br><span class="line">        return host, username, password</span><br><span class="line">    conn = connector.connect(get_DB_configuration())</span><br><span class="line">    return conn</span><br></pre></td></tr></table></figure></li><li><p>合理的使用函数嵌套，能够提高程序的运行效率:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">def factorial(input):</span><br><span class="line">    # validation check</span><br><span class="line">    if not isinstance(input, int):</span><br><span class="line">        raise Exception(&apos;input must be an integer.&apos;)</span><br><span class="line">    if input &lt; 0:</span><br><span class="line">        raise Exception(&apos;input must be greater or equal to 0&apos; )</span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    def inner_factorial(input):</span><br><span class="line">        if input &lt;= 1:</span><br><span class="line">            return 1</span><br><span class="line">        return input * inner_factorial(input-1)</span><br><span class="line">    return inner_factorial(input)</span><br><span class="line"></span><br><span class="line">print(factorial(5))</span><br></pre></td></tr></table></figure></li></ul></li></ul><h3 id="函数变量作用域"><a href="#函数变量作用域" class="headerlink" title="函数变量作用域"></a>函数变量作用域</h3><ul><li>如果变量是在函数内部定义的，就称为局部变量，只在函数内部有效。一旦函数执行完毕，局部变量就会被回收，无法访问.</li><li>想要在函数内部修改全局变量的值，需要在函数内部 用关键字 global 申明。</li><li>如果遇到函数内部局部变量和全局变是同名的情况，那么在函数内部，局部变量会覆盖全局变量</li><li>对于嵌套函数来说，内部函数可以访问外部函数定义的变量，但是无法修改，若要修改，必须加上nonlocal这个关键字</li></ul><h3 id="闭包-closure"><a href="#闭包-closure" class="headerlink" title="闭包 closure"></a>闭包 closure</h3><ul><li><p>闭包其实和刚刚讲的嵌套函数类似，不同的是，这里外部函数返回的是一个函数，而不是一个具体的值。返回的函数通常赋于一个变量，这个变量可以在后面被继续执行调用。</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">def nth_power(exponent):</span><br><span class="line">    def exponent_of(base):</span><br><span class="line">        return base ** exponent</span><br><span class="line">    return exponent_of # 返回值是 exponent_of 函数</span><br><span class="line"></span><br><span class="line">square = nth_power(2) # 计算一个数的平方</span><br><span class="line">cube = nth_power(3) # 计算一个数的立方 </span><br><span class="line">square</span><br><span class="line"># 输出</span><br><span class="line">&lt;function __main__.nth_power.&lt;locals&gt;.exponent(base)&gt;</span><br><span class="line"></span><br><span class="line">cube</span><br><span class="line"># 输出</span><br><span class="line">&lt;function __main__.nth_power.&lt;locals&gt;.exponent(base)&gt;</span><br><span class="line"></span><br><span class="line">print(square(2))  # 计算 2 的平方</span><br><span class="line">print(cube(2)) # 计算 2 的立方</span><br><span class="line"># 输出</span><br><span class="line">4 # 2^2</span><br><span class="line">8 # 2^3</span><br></pre></td></tr></table></figure></li><li><p>这里外部函数nth_power()返回值，是函数exponent_of()，而不是一个具体的数值。需要注意的是，在执行完square=nth_power(2)和cube=nth_power(3)后，外部函数nth power()的参数exponent，仍然会被内部函数exponent of()记住。这样，之后我们调用square(2)或者cube(2)时，程序就能顺利地输出结果，而不会报错说参数exponent没有定义了。</p></li><li>闭包常常和装饰器（decorator）一起使用。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;函数基础&quot;&gt;&lt;a href=&quot;#函数基础&quot; class=&quot;headerlink&quot; title=&quot;函数基础&quot;&gt;&lt;/a&gt;函数基础&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;定义：&lt;/p&gt;
  &lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;
      
    
    </summary>
    
    
      <category term="Coding" scheme="http://tracyxinwang.site/blog/tags/Coding/"/>
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
      <category term="Python" scheme="http://tracyxinwang.site/blog/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Python核心技术与实战08 异常处理</title>
    <link href="http://tracyxinwang.site/blog/2019/05/27/python08/"/>
    <id>http://tracyxinwang.site/blog/2019/05/27/python08/</id>
    <published>2019-05-27T13:07:23.000Z</published>
    <updated>2019-07-22T03:34:37.520Z</updated>
    
    <content type="html"><![CDATA[<h3 id="错误与异常"><a href="#错误与异常" class="headerlink" title="错误与异常"></a>错误与异常</h3><ul><li>在程序中，如果我们不确定某段代码能否成功执行，往往这个地方就需要使用异常处理。</li><li>程序中的错误至少包括两种，一种是语法错误，另一种则是异常。</li><li>Python 中常见的异常类型：<ul><li>NameError, TypeError, FileNotFoundError</li><li>KeyError是指字典中的键找不到</li></ul></li></ul><h3 id="如何处理异常"><a href="#如何处理异常" class="headerlink" title="如何处理异常"></a>如何处理异常</h3><ul><li><p>用 try 和 except 来处理异常问题</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">try:</span><br><span class="line">    s = input(&apos;please enter two numbers separated by comma: &apos;)</span><br><span class="line">    num1 = int(s.split(&apos;,&apos;)[0].strip())</span><br><span class="line">    num2 = int(s.split(&apos;,&apos;)[1].strip())</span><br><span class="line">except ValueError as err:</span><br><span class="line">    print(&apos;Value Error: &#123;&#125;&apos;.format(err))</span><br><span class="line"></span><br><span class="line">print(&apos;continue&apos;)</span><br></pre></td></tr></table></figure></li><li><p>except block只接受与它相匹配的异常类型并执行，如果程序抛出的异常并不匹配，那么程序也会终止并退出。</p></li><li><p>想解决这种情况，第一种方法就是在except block中加入多种异常的类型，比如：</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">try:</span><br><span class="line">    s = input(&apos;please enter two numbers separated by comma: &apos;)</span><br><span class="line">    num1 = int(s.split(&apos;,&apos;)[0].strip())</span><br><span class="line">    num2 = int(s.split(&apos;,&apos;)[1].strip())</span><br><span class="line">except (ValueError, IndexError) as err:</span><br><span class="line">    print(&apos;Error: &#123;&#125;&apos;.format(err))</span><br><span class="line">    </span><br><span class="line">print(&apos;continue&apos;)</span><br></pre></td></tr></table></figure></li><li><p>或者这样写: except block 中只要有一个exception 类型与实际匹配即可。并在最后一个except block，声明其处理的异常类型是Exception。Exception是其他所有非系统异常的基类，能够匹配任意非系统异常，所以基本能够涵盖所有错误类型。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">try:</span><br><span class="line">    s = input(&apos;please enter two numbers separated by comma: &apos;)</span><br><span class="line">    num1 = int(s.split(&apos;,&apos;)[0].strip())</span><br><span class="line">    num2 = int(s.split(&apos;,&apos;)[1].strip())</span><br><span class="line">except ValueError as err:</span><br><span class="line">    print(&apos;Value Error: &#123;&#125;&apos;.format(err))</span><br><span class="line">except IndexError as err:</span><br><span class="line">    print(&apos;Index Error: &#123;&#125;&apos;.format(err))</span><br><span class="line">except Exception as err:</span><br><span class="line">    print(&apos;Other error: &#123;&#125;&apos;.format(err))</span><br><span class="line"></span><br><span class="line">print(&apos;continue&apos;)</span><br></pre></td></tr></table></figure></li><li><p>也可以在except后面省略异常类型，表示与任意异常相匹配（包括系统异常等）：</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">try:</span><br><span class="line">    s = input(&apos;please enter two numbers separated by comma: &apos;)</span><br><span class="line">    num1 = int(s.split(&apos;,&apos;)[0].strip())</span><br><span class="line">    num2 = int(s.split(&apos;,&apos;)[1].strip())</span><br><span class="line">except ValueError as err:</span><br><span class="line">    print(&apos;Value Error: &#123;&#125;&apos;.format(err))</span><br><span class="line">except IndexError as err:</span><br><span class="line">    print(&apos;Index Error: &#123;&#125;&apos;.format(err))</span><br><span class="line">except:</span><br><span class="line">    print(&apos;Other error&apos;)</span><br><span class="line"></span><br><span class="line">print(&apos;continue&apos;)</span><br></pre></td></tr></table></figure></li><li><p>此外，当程序中存在多个except block时，最多只有一个except block会被执行。所以如果多个except声明的异常类型都与实际相匹配，那么只有最前面的except block会被执行，其他则被忽略。</p></li><li>异常处理中，还有一个很常见的用法是finally，经常和try、except放在一起来用。无论发生什么情况，finally block中的语句都会被执行，哪怕前面的try 和excep block中使用了return语句。  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import sys</span><br><span class="line">try:</span><br><span class="line">    f = open(&apos;file.txt&apos;, &apos;r&apos;)</span><br><span class="line">    .... # some data processing</span><br><span class="line">except OSError as err:</span><br><span class="line">    print(&apos;OS error: &#123;&#125;&apos;.format(err))</span><br><span class="line">except:</span><br><span class="line">    print(&apos;Unexpected error:&apos;, sys.exc_info()[0])</span><br><span class="line">finally:</span><br><span class="line">    f.close()</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;错误与异常&quot;&gt;&lt;a href=&quot;#错误与异常&quot; class=&quot;headerlink&quot; title=&quot;错误与异常&quot;&gt;&lt;/a&gt;错误与异常&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;在程序中，如果我们不确定某段代码能否成功执行，往往这个地方就需要使用异常处理。&lt;/li&gt;
&lt;li&gt;程序中
      
    
    </summary>
    
    
      <category term="Coding" scheme="http://tracyxinwang.site/blog/tags/Coding/"/>
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
      <category term="Python" scheme="http://tracyxinwang.site/blog/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Python核心技术与实战07 条件与循环</title>
    <link href="http://tracyxinwang.site/blog/2019/05/24/python07/"/>
    <id>http://tracyxinwang.site/blog/2019/05/24/python07/</id>
    <published>2019-05-24T08:07:23.000Z</published>
    <updated>2019-07-22T03:33:27.163Z</updated>
    
    <content type="html"><![CDATA[<h3 id="条件语句"><a href="#条件语句" class="headerlink" title="条件语句"></a>条件语句</h3><ul><li>条件语句的末尾必须加上冒号（:）</li><li><p>Python 不支持 switch 语句，因此，当存在多个条件判断时，我们需要用else if来实现，这在Python中的表达是elif：</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">if x:</span><br><span class="line">    statement_1</span><br><span class="line">elif y:</span><br><span class="line">    statement_2</span><br><span class="line">...</span><br><span class="line">elif z:</span><br><span class="line">    statement_i</span><br><span class="line">else:</span><br><span class="line">    statement_n</span><br></pre></td></tr></table></figure></li><li><p>整个条件语句是顺序执行的，如果遇到一个条件满足，在执行完statement后，便会退出整个if、elif、else条件语句，而不会继续向下执行。</p></li></ul><h3 id="循环语句"><a href="#循环语句" class="headerlink" title="循环语句"></a>循环语句</h3><ul><li>一般通过 for 循环和 while 循环实现<br><strong>for 循环</strong></li><li><p>Python中的数据结构只要是可迭代的（iterable），比如列表、集合等等，都可以通过下面这种方式遍历</p><ul><li>遍历列表：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">l = [1, 2, 3, 4]</span><br><span class="line">for item in l:</span><br><span class="line">    print(item)</span><br><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td></tr></table></figure></li></ul></li><li><p>字典本身只有键是可迭代的，如果我们要遍历它的值或者是键值对，就需要通过其内置的函数 values() 或者items() 实现。</p><ul><li>其中，values() 返回字典的值的集合，items()返回键值对的集合<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">d = &#123;&apos;name&apos;: &apos;jason&apos;, &apos;dob&apos;: &apos;2000-01-01&apos;, &apos;gender&apos;: &apos;male&apos;&#125;</span><br><span class="line">for k in d: # 遍历字典的键</span><br><span class="line">    print(k)</span><br><span class="line">name</span><br><span class="line">dob</span><br><span class="line">gender</span><br><span class="line"></span><br><span class="line">for v in d.values(): # 遍历字典的值</span><br><span class="line">    print(v)</span><br><span class="line">jason</span><br><span class="line">2000-01-01</span><br><span class="line">male    </span><br><span class="line"></span><br><span class="line">for k, v in d.items(): # 遍历字典的键值对</span><br><span class="line">    print(&apos;key: &#123;&#125;, value: &#123;&#125;&apos;.format(k, v))</span><br><span class="line">key: name, value: jason</span><br><span class="line">key: dob, value: 2000-01-01</span><br><span class="line">key: gender, value: male</span><br></pre></td></tr></table></figure></li></ul></li><li><p>通过集合中的索引来遍历元素: range() 函数</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">l = [1, 2, 3, 4, 5, 6, 7]</span><br><span class="line">for index in range(0, len(l)):</span><br><span class="line">    if index &lt; 5:</span><br><span class="line">        print(l[index])</span><br></pre></td></tr></table></figure></li><li><p>同时需要索引和元素时，用Python内置的函数enumerate 实现：</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">l = [1, 2, 3, 4, 5, 6, 7]</span><br><span class="line">for index, item in enumerate(l):</span><br><span class="line">    if index &lt; 5:</span><br><span class="line">        print(item)</span><br></pre></td></tr></table></figure></li><li><p>在循环语句中，常常搭配 continue和break一起使用。continue，就是让程序跳过当前这层循环，继续执行下面的循环；而break则是指完全跳出所在的整个循环体。在循环中适当加入continue和break，往往能使程序更加简洁、易读。</p><ul><li>e.g. 过多嵌套会使代码冗余<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"># name_price: 产品名称 (str) 到价格 (int) 的映射字典</span><br><span class="line"># name_color: 产品名字 (str) 到颜色 (list of str) 的映射字典</span><br><span class="line">for name, price in name_price.items():</span><br><span class="line">    if price &lt; 1000:</span><br><span class="line">        if name in name_color:</span><br><span class="line">            for color in name_color[name]:</span><br><span class="line">                if color != &apos;red&apos;:</span><br><span class="line">                    print(&apos;name: &#123;&#125;, color: &#123;&#125;&apos;.format(name, color))</span><br><span class="line">        else:</span><br><span class="line">            print(&apos;name: &#123;&#125;, color: &#123;&#125;&apos;.format(name, &apos;None&apos;))</span><br><span class="line"></span><br><span class="line"># 加入 continue</span><br><span class="line"># name_price: 产品名称 (str) 到价格 (int) 的映射字典</span><br><span class="line"># name_color: 产品名字 (str) 到颜色 (list of str) 的映射字典</span><br><span class="line">for name, price in name_price.items():</span><br><span class="line">    if price &gt;= 1000:</span><br><span class="line">        continue</span><br><span class="line">    if name not in name_color:</span><br><span class="line">        print(&apos;name: &#123;&#125;, color: &#123;&#125;&apos;.format(name, &apos;None&apos;))</span><br><span class="line">        continue</span><br><span class="line">    for color in name_color[name]:</span><br><span class="line">        if color == &apos;red&apos;:</span><br><span class="line">            continue</span><br><span class="line">        print(&apos;name: &#123;&#125;, color: &#123;&#125;&apos;.format(name, color))</span><br></pre></td></tr></table></figure></li></ul></li></ul><p><strong>while 循环</strong></p><ul><li><p>基本同 for 一样</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">while condition:</span><br><span class="line">    ....</span><br></pre></td></tr></table></figure></li><li><p>哪个效率高？ range() 函数是直接由 C 语言写的，调用它速度非常快</p></li></ul><h3 id="条件与循环的复用"><a href="#条件与循环的复用" class="headerlink" title="条件与循环的复用"></a>条件与循环的复用</h3><ul><li><p>将条件与循环并做一行:</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">expression1 if condition else expression2 for item in iterable</span><br></pre></td></tr></table></figure></li><li><p>复用用于多个循环。e.g. 给定两个列表x、y，要求返回x、y中所有元素对组成的元祖，相等情况除外</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[(xx, yy) for xx in x for yy in y if xx != yy]</span><br></pre></td></tr></table></figure></li></ul><h3 id="思考题"><a href="#思考题" class="headerlink" title="思考题"></a>思考题</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">attributes = [&apos;name&apos;, &apos;dob&apos;, &apos;gender&apos;]</span><br><span class="line">values = [[&apos;jason&apos;, &apos;2000-01-01&apos;, &apos;male&apos;], </span><br><span class="line">[&apos;mike&apos;, &apos;1999-01-01&apos;, &apos;male&apos;],</span><br><span class="line">[&apos;nancy&apos;, &apos;2001-02-01&apos;, &apos;female&apos;]</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"># expected outout:</span><br><span class="line">[&#123;&apos;name&apos;: &apos;jason&apos;, &apos;dob&apos;: &apos;2000-01-01&apos;, &apos;gender&apos;: &apos;male&apos;&#125;, </span><br><span class="line">&#123;&apos;name&apos;: &apos;mike&apos;, &apos;dob&apos;: &apos;1999-01-01&apos;, &apos;gender&apos;: &apos;male&apos;&#125;, </span><br><span class="line">&#123;&apos;name&apos;: &apos;nancy&apos;, &apos;dob&apos;: &apos;2001-02-01&apos;, &apos;gender&apos;: &apos;female&apos;&#125;]</span><br></pre></td></tr></table></figure><p>answer:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># 一行</span><br><span class="line">[dict(zip(attributes,v)) for v in values]</span><br><span class="line"></span><br><span class="line"># 多行</span><br><span class="line">l = []</span><br><span class="line">for value in values:</span><br><span class="line">    d = &#123;&#125;</span><br><span class="line">    for i in range(3):</span><br><span class="line">        d[attributes[i]] = value[i]</span><br><span class="line">    l.append(d)</span><br></pre></td></tr></table></figure></p><p>极客时间版权所有: <a href="https://time.geekbang.org/column/article/96597" target="_blank" rel="noopener">https://time.geekbang.org/column/article/96597</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;条件语句&quot;&gt;&lt;a href=&quot;#条件语句&quot; class=&quot;headerlink&quot; title=&quot;条件语句&quot;&gt;&lt;/a&gt;条件语句&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;条件语句的末尾必须加上冒号（:）&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Python 不支持 switch 语句，因此，当存在
      
    
    </summary>
    
    
      <category term="Coding" scheme="http://tracyxinwang.site/blog/tags/Coding/"/>
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
      <category term="Python" scheme="http://tracyxinwang.site/blog/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Python核心技术与实战05 深入浅出字符串</title>
    <link href="http://tracyxinwang.site/blog/2019/05/22/python05/"/>
    <id>http://tracyxinwang.site/blog/2019/05/22/python05/</id>
    <published>2019-05-22T10:44:23.000Z</published>
    <updated>2019-07-22T03:31:29.567Z</updated>
    
    <content type="html"><![CDATA[<h3 id="基础"><a href="#基础" class="headerlink" title="基础"></a>基础</h3><ul><li><p>可用单引号，双引号，或者三引号：</p>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">name = <span class="string">'jason'</span></span><br><span class="line">city = <span class="string">'beijing'</span></span><br><span class="line">text = <span class="string">"welcome to jike shijian"</span></span><br></pre></td></tr></table></figure></li><li><p>Python 的三引号字符串，则主要应用于多行字符串的情境. e.g. 函数的注释</p></li><li>转义字符(反斜杠开头)：<ul><li>\newline: 接下一行</li><li>\: \</li></ul></li></ul><h3 id="常用操作"><a href="#常用操作" class="headerlink" title="常用操作"></a>常用操作</h3><ul><li><p>支持索引，切片和遍历等等操作</p>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">name = <span class="string">'Jason'</span></span><br><span class="line">name[<span class="number">0</span>]</span><br><span class="line">    <span class="string">'J'</span></span><br><span class="line">name[<span class="number">1</span>:<span class="number">3</span>]</span><br><span class="line">    <span class="string">'as'</span></span><br></pre></td></tr></table></figure></li><li><p>遍历字符串相当于遍历字符串中的每个字符</p><ul><li><code>for char in name</code></li></ul></li><li><p>Python 的字符串是不可变的: 改变一个字符串内部的字符是不允许的。</p>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">s = <span class="string">'hello'</span></span><br><span class="line">s[<span class="number">0</span>] = <span class="string">'H'</span></span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">File <span class="string">"&lt;stdin&gt;"</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">TypeError: <span class="string">'str'</span> object does <span class="keyword">not</span> support item assignment</span><br></pre></td></tr></table></figure></li><li><p>Python 中字符串的改变，通常只能通过创建新的字符串来完成</p>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">s = <span class="string">'H'</span> + s[<span class="number">1</span>:]</span><br><span class="line">s = s.replace(<span class="string">'h'</span>, <span class="string">'H'</span>)</span><br></pre></td></tr></table></figure></li><li><p>字符串拼接方法：</p><ul><li><p>使用 ‘+=’ ：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">s = <span class="string">''</span></span><br><span class="line"><span class="keyword">for</span> n <span class="keyword">in</span> range(<span class="number">0</span>, <span class="number">100000</span>):</span><br><span class="line">    s += str(n)</span><br></pre></td></tr></table></figure></li><li><p>使用内置函数 join :</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">l = []</span><br><span class="line"><span class="keyword">for</span> n <span class="keyword">in</span> range(<span class="number">0</span>, <span class="number">100000</span>):</span><br><span class="line">    l.append(str(n))</span><br><span class="line">l = <span class="string">' '</span>.join(l)</span><br></pre></td></tr></table></figure></li></ul></li><li><p>字符串分割：</p><ul><li>split(): string.split(separator)，表示把字符串按照 separator 分割成子字符串并返回一个分割后子字符串组合的<em>列表</em><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">query_data</span><span class="params">(namespace, table)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    given namespace and table, query database to get corresponding</span></span><br><span class="line"><span class="string">    data         </span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">path = <span class="string">'hive://ads/training_table'</span></span><br><span class="line">namespace = path.split(<span class="string">'//'</span>)[<span class="number">1</span>].split(<span class="string">'/'</span>)[<span class="number">0</span>] <span class="comment"># 返回'ads'</span></span><br><span class="line">table = path.split(<span class="string">'//'</span>)[<span class="number">1</span>].split(<span class="string">'/'</span>)[<span class="number">1</span>] <span class="comment"># 返回 'training_table'</span></span><br><span class="line">data = query_data(namespace, table)</span><br></pre></td></tr></table></figure></li></ul></li><li><p>其他函数：</p><ul><li>string.strip(str)，表示去掉首尾的 str 字符串</li><li>string.lstrip(str)，表示去掉开头的 str 字符串</li><li>string.rstrip(str)，表示去掉结尾的 str 字符串</li><li>string.find(sub, start, end)，表示从 start 到 end 查找字符串中子字符串 sub 的位置</li></ul></li></ul><h3 id="字符串的格式化"><a href="#字符串的格式化" class="headerlink" title="字符串的格式化"></a>字符串的格式化</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'no data available for person with id: &#123;&#125;, name: &#123;&#125;'</span>.format(id, name))</span><br><span class="line"><span class="comment"># 类似于 matlab 里面的 %d, %s</span></span><br></pre></td></tr></table></figure><p>\newline</p><p>极客时间版权所有: <a href="https://time.geekbang.org/column/article/95897" target="_blank" rel="noopener">https://time.geekbang.org/column/article/95897</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;基础&quot;&gt;&lt;a href=&quot;#基础&quot; class=&quot;headerlink&quot; title=&quot;基础&quot;&gt;&lt;/a&gt;基础&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;可用单引号，双引号，或者三引号：&lt;/p&gt;
  &lt;figure class=&quot;highlight python&quot;&gt;&lt;tabl
      
    
    </summary>
    
    
      <category term="Coding" scheme="http://tracyxinwang.site/blog/tags/Coding/"/>
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
      <category term="Python" scheme="http://tracyxinwang.site/blog/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Python 核心技术与实战 03</title>
    <link href="http://tracyxinwang.site/blog/2019/05/22/python03/"/>
    <id>http://tracyxinwang.site/blog/2019/05/22/python03/</id>
    <published>2019-05-22T10:44:23.000Z</published>
    <updated>2019-07-22T03:22:32.521Z</updated>
    
    <content type="html"><![CDATA[<h2 id="列表-list-和元组-tuple-的使用"><a href="#列表-list-和元组-tuple-的使用" class="headerlink" title="列表(list)和元组(tuple)的使用"></a>列表(list)和元组(tuple)的使用</h2><h3 id="基础"><a href="#基础" class="headerlink" title="基础"></a>基础</h3><ul><li><p>列表和元组，都是可以放置任意数据类型的有序集合，且不要求元素类型一致</p><ul><li><p>e.g. </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">list = [1,2,&apos;hello&apos;,&apos;world&apos;]</span><br><span class="line">tup = (&apos;jason&apos;,22)</span><br></pre></td></tr></table></figure></li><li><p>list有点像是matlab中的array, 只不过是一般化了的array</p></li><li>注意一个是[], 一个是() 来表示数据</li></ul></li><li><p>区别在于：</p><ul><li>列表是动态的，长度大小不固定，可以随意地增加、删减或者改变元素</li><li>元组是静态的，长度大小固定，无法增加删减或者改变</li><li>e.g. 试着改变最后一个元素：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">l = [1, 2, 3, 4]</span><br><span class="line">l[3] = 40 # 更改最后一个元素</span><br><span class="line">l</span><br><span class="line">    [1, 2, 3, 40]</span><br><span class="line"></span><br><span class="line">tup = (1, 2, 3, 4)</span><br><span class="line">tup[3] = 40</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">    File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;</span><br><span class="line">TypeError: &apos;tuple&apos; object does not support item assignment</span><br></pre></td></tr></table></figure></li></ul></li><li><p>如果想增加一个元素，元组只能另创建一个元组，但列表可以直接加在末尾：</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">tup = (1, 2, 3, 4)</span><br><span class="line">new_tup = tup + (5, ) # 创建新的元组 new_tup，并依次填充原元组的值</span><br><span class="line">new _tup</span><br><span class="line">    (1, 2, 3, 4, 5)</span><br><span class="line"></span><br><span class="line">l = [1, 2, 3, 4]</span><br><span class="line">l.append(5) # 添加元素 5 到原列表的末尾</span><br><span class="line">l</span><br><span class="line">    [1, 2, 3, 4, 5]</span><br></pre></td></tr></table></figure></li><li><p>列表和元组都支持负数索引(索引都是用[])：</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">l = [1, 2, 3, 4]</span><br><span class="line">l[-1]</span><br><span class="line">    4</span><br><span class="line"></span><br><span class="line">tup = (1, 2, 3, 4)</span><br><span class="line">tup[-1]</span><br><span class="line">    4</span><br></pre></td></tr></table></figure></li><li><p>都支持切片操作(注意切片操作不包括最后一个索引)：</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">l = [1, 2, 3, 4]</span><br><span class="line">l[1:3] # 返回列表中索引从 1 到 2 的子列表</span><br><span class="line">    [2, 3]</span><br><span class="line"></span><br><span class="line">tup = (1, 2, 3, 4)</span><br><span class="line">tup[1:3] # 返回元组中索引从 1 到 2 的子元组</span><br><span class="line">    (2, 3)</span><br></pre></td></tr></table></figure></li><li><p>可以随意嵌套：</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">l = [[1, 2, 3], [4, 5]] # 列表的每一个元素也是一个列表</span><br><span class="line"></span><br><span class="line">tup = ((1, 2, 3), (4, 5, 6)) # 元组的每一个元素也是一元组</span><br></pre></td></tr></table></figure></li><li><p>可以通过 list() 和 tuple() 函数相互转换</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">list((1, 2, 3))</span><br><span class="line">    [1, 2, 3]</span><br><span class="line"></span><br><span class="line">tuple([1, 2, 3])</span><br><span class="line">    (1, 2, 3)</span><br></pre></td></tr></table></figure></li><li><p>列表和元组常用的内置函数：</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">l = [3, 2, 3, 7, 8, 1]</span><br><span class="line">l.count(3) </span><br><span class="line">    2</span><br><span class="line">l.index(7)</span><br><span class="line">    3</span><br><span class="line">l.reverse()</span><br><span class="line">l</span><br><span class="line">    [1, 8, 7, 3, 2, 3]</span><br><span class="line">l.sort()</span><br><span class="line">l</span><br><span class="line">    [1, 2, 3, 3, 7, 8]</span><br><span class="line"></span><br><span class="line">tup = (3, 2, 3, 7, 8, 1)</span><br><span class="line">tup.count(3)</span><br><span class="line">    2</span><br><span class="line">tup.index(7)</span><br><span class="line">    3</span><br><span class="line">list(reversed(tup))</span><br><span class="line">    [1, 8, 7, 3, 2, 3]</span><br><span class="line">sorted(tup)</span><br><span class="line">    [1, 2, 3, 3, 7, 8]</span><br></pre></td></tr></table></figure></li></ul><h3 id="储存方式"><a href="#储存方式" class="headerlink" title="储存方式"></a>储存方式</h3><ul><li><p>先看一个例子：</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">l = [1, 2, 3]</span><br><span class="line">l.__sizeof__()</span><br><span class="line">    64</span><br><span class="line">tup = (1, 2, 3)</span><br><span class="line">tup.__sizeof__()</span><br><span class="line">    48</span><br></pre></td></tr></table></figure></li><li><p>可见同样的元素，元组的存储空间比列表少16字节</p><ul><li>这是因为列表是动态的，它需要存储指针，来指向对应的元素（上述例子中，对于int型是8字节）</li><li>此外，由于列表可变，所以需要额外存储已经分配的长度大小（8 字节），这样才可以实时追踪列表空间的使用情况，当空间不足时，及时分配额外空间</li><li><p>例子如下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">l = []</span><br><span class="line">l.__sizeof__() // 空列表的存储空间为 40 字节</span><br><span class="line">    40</span><br><span class="line">l.append(1)</span><br><span class="line">l.__sizeof__() </span><br><span class="line">    72 // 加入了元素 1 之后，列表为其分配了可以存储 4 个元素的空间 (72 - 40)/8 = 4</span><br><span class="line">l.append(2) </span><br><span class="line">l.__sizeof__()</span><br><span class="line">    72 // 由于之前分配了空间，所以加入元素 2，列表空间不变</span><br><span class="line">l.append(3)</span><br><span class="line">l.__sizeof__() </span><br><span class="line">    72 // 同上</span><br><span class="line">l.append(4)</span><br><span class="line">l.__sizeof__() </span><br><span class="line">    72 // 同上</span><br><span class="line">l.append(5)</span><br><span class="line">l.__sizeof__() </span><br><span class="line">    104 // 加入元素 5 之后，列表的空间不足，所以又额外分配了可以存储 4 个元素的空间</span><br></pre></td></tr></table></figure></li><li><p>所以列表空间分配的时，为了减小每次增加 / 操作空间分配的开销，每次分配空间时都会额外分配一些，这样Over-allocating保证了其操作的高效性：即增加、删除 的时间复杂度为O(1).</p></li></ul></li><li>list和tuple的内部实现都是array的形式，list因为可变，所以是一个over-allocate的array，tuple因为不可变，所以长度大小固定。</li></ul><h3 id="列表和元组的性能"><a href="#列表和元组的性能" class="headerlink" title="列表和元组的性能"></a>列表和元组的性能</h3><ul><li>元组要比列表更加轻量级一些，所以总体上来说，元组的性能速度要略优于列表</li><li>此外，Python会在后台，对静态数据做一些资源缓存(resource caching). 通常来讲，因为垃圾回收机制的存在，如果一些变量不被使用了，Python就会回收他们所占用的内存，返还给操作系统</li><li>但是对一些静态变量，比如元组，如果它不被使用并且占用空间不大时，Python 会暂时缓存这部分内存，这样下次创建同样大小的元组时，Python 就可以不用再向操作系统发出请求，去寻找内存，而是可以直接分配之前缓存的内存空间，这样就能大大加快程序的运行速度</li><li><p>以下例子是计算初始化一个相同元素的列表和元组分别所需的时间。我们可以看到，元组的初始化速度，要比列表快 5 倍。</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">python3 -m timeit &apos;x=(1,2,3,4,5,6)&apos;</span><br><span class="line">    20000000 loops, best of 5: 9.97 nsec per loop</span><br><span class="line">python3 -m timeit &apos;x=[1,2,3,4,5,6]&apos;</span><br><span class="line">    5000000 loops, best of 5: 50.1 nsec per loop</span><br></pre></td></tr></table></figure></li><li><p>但如果是索引操作的话，两者速度差别非常小：</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">python3 -m timeit -s &apos;x=[1,2,3,4,5,6]&apos; &apos;y=x[3]&apos;</span><br><span class="line">    10000000 loops, best of 5: 22.2 nsec per loop</span><br><span class="line">python3 -m timeit -s &apos;x=(1,2,3,4,5,6)&apos; &apos;y=x[3]&apos;</span><br><span class="line">    10000000 loops, best of 5: 21.9 nsec per loop</span><br></pre></td></tr></table></figure></li></ul><h3 id="列表和元组的使用场景"><a href="#列表和元组的使用场景" class="headerlink" title="列表和元组的使用场景"></a>列表和元组的使用场景</h3><ul><li>如果存储的数据和数量不变，比如你有一个函数，需要返回的是一个地点的经纬度，然后直接传给前端渲染，那么肯定选用元组更合适</li><li>如果存储的数据或数量是可变的，比如社交平台上的一个日志功能,是统计一个用户在一周之内看了哪些用户的帖子，那么则用列表更合适</li></ul><h3 id="思考题"><a href="#思考题" class="headerlink" title="思考题"></a>思考题</h3><p>想创建一个空的列表，我们可以用下面的 A、B 两种方式，请问它们在效率上有什么区别吗？应该优先考虑使用哪种？<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 创建空列表</span><br><span class="line"># option A</span><br><span class="line">empty_list = list()</span><br><span class="line"></span><br><span class="line"># option B</span><br><span class="line">empty_list = []</span><br></pre></td></tr></table></figure></p><ul><li>answer: 区别主要在于list()是一个function call，Python的function call会创建stack，并且进行一系列参数检查的操作，比较expensive，反观[]是一个内置的C函数，可以直接被调用，因此效率高。</li></ul><p>极客时间版权所有: <a href="https://time.geekbang.org/column/article/94972" target="_blank" rel="noopener">https://time.geekbang.org/column/article/94972</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;列表-list-和元组-tuple-的使用&quot;&gt;&lt;a href=&quot;#列表-list-和元组-tuple-的使用&quot; class=&quot;headerlink&quot; title=&quot;列表(list)和元组(tuple)的使用&quot;&gt;&lt;/a&gt;列表(list)和元组(tuple)的使用&lt;/
      
    
    </summary>
    
    
      <category term="Coding" scheme="http://tracyxinwang.site/blog/tags/Coding/"/>
    
      <category term="learning" scheme="http://tracyxinwang.site/blog/tags/learning/"/>
    
  </entry>
  
  <entry>
    <title>Python核心技术与实战04 字典与集合</title>
    <link href="http://tracyxinwang.site/blog/2019/05/22/python04/"/>
    <id>http://tracyxinwang.site/blog/2019/05/22/python04/</id>
    <published>2019-05-22T10:44:23.000Z</published>
    <updated>2019-07-22T03:21:39.313Z</updated>
    
    <content type="html"><![CDATA[<h3 id="基础"><a href="#基础" class="headerlink" title="基础"></a>基础</h3><ul><li>字典(dict)：由键（key）和值（value）配对组成的元素的集合<ul><li>在 Python3.7+，字典被确定为有序</li><li>相比于列表和元组，字典的性能更优，特别是对于查找、添加和删除操作，字典都能在常数时间复杂度内完成</li></ul></li><li>集合(set): 和字典基本相同，唯一的区别，就是集合没有键和值的配对，是一系列无序的、唯一的元素组合</li><li><p>创建：</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">d1 = &#123;&apos;name&apos;: &apos;jason&apos;, &apos;age&apos;: 20, &apos;gender&apos;: &apos;male&apos;&#125;</span><br><span class="line">d2 = dict(&#123;&apos;name&apos;: &apos;jason&apos;, &apos;age&apos;: 20, &apos;gender&apos;: &apos;male&apos;&#125;)</span><br><span class="line">d3 = dict([(&apos;name&apos;, &apos;jason&apos;), (&apos;age&apos;, 20), (&apos;gender&apos;, &apos;male&apos;)])</span><br><span class="line">d4 = dict(name=&apos;jason&apos;, age=20, gender=&apos;male&apos;) </span><br><span class="line">d1 == d2 == d3 ==d4</span><br><span class="line">True</span><br><span class="line"></span><br><span class="line">s1 = &#123;1, 2, 3&#125;</span><br><span class="line">s2 = set([1, 2, 3])</span><br><span class="line">s1 == s2</span><br><span class="line">True</span><br></pre></td></tr></table></figure></li><li><p>元素访问：</p><ul><li><p>字典访问：可直接索引, 也可使用get(key,default)函数来索引</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">d = &#123;&apos;name&apos;: &apos;jason&apos;, &apos;age&apos;: 20&#125;</span><br><span class="line">d[&apos;name&apos;]</span><br><span class="line">    &apos;jason&apos;</span><br><span class="line">d[&apos;location&apos;]</span><br><span class="line">    Traceback (most recent call last):</span><br><span class="line">    File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;</span><br><span class="line">    KeyError: &apos;location&apos;</span><br><span class="line"></span><br><span class="line">d.get(&apos;name&apos;)</span><br><span class="line">    &apos;jason&apos;</span><br><span class="line">d.get(&apos;location&apos;, &apos;null&apos;)</span><br><span class="line">    &apos;null&apos;</span><br></pre></td></tr></table></figure></li><li><p><strong>集合：并不支持索引操作</strong>，因为集合本质上是一个哈希表，和列表不一样</p></li><li>可用 value in dict/set 来判断一个元素是否在字典/集合内<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">s = &#123;1, 2, 3&#125;</span><br><span class="line">1 in s</span><br><span class="line">    True</span><br><span class="line">10 in s</span><br><span class="line">    False</span><br><span class="line"></span><br><span class="line">d = &#123;&apos;name&apos;: &apos;jason&apos;, &apos;age&apos;: 20&#125;</span><br><span class="line">&apos;name&apos; in d</span><br><span class="line">    True</span><br><span class="line">&apos;location&apos; in d</span><br><span class="line">    False</span><br></pre></td></tr></table></figure></li></ul></li><li><p>增加、删除、更新等操作</p>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">d = &#123;<span class="string">'name'</span>: <span class="string">'jason'</span>, <span class="string">'age'</span>: <span class="number">20</span>&#125;</span><br><span class="line">d[<span class="string">'gender'</span>] = <span class="string">'male'</span> <span class="comment"># 增加元素对'gender': 'male'</span></span><br><span class="line">d[<span class="string">'dob'</span>] = <span class="string">'1999-02-01'</span> <span class="comment"># 增加元素对'dob': '1999-02-01'</span></span><br><span class="line">d</span><br><span class="line">    &#123;<span class="string">'name'</span>: <span class="string">'jason'</span>, <span class="string">'age'</span>: <span class="number">20</span>, <span class="string">'gender'</span>: <span class="string">'male'</span>, <span class="string">'dob'</span>: <span class="string">'1999-02-01'</span>&#125;</span><br><span class="line">d[<span class="string">'dob'</span>] = <span class="string">'1998-01-01'</span> <span class="comment"># 更新键'dob'对应的值 </span></span><br><span class="line">d.pop(<span class="string">'dob'</span>) <span class="comment"># 删除键为'dob'的元素对</span></span><br><span class="line">    <span class="string">'1998-01-01'</span></span><br><span class="line"></span><br><span class="line">d</span><br><span class="line">    &#123;<span class="string">'name'</span>: <span class="string">'jason'</span>, <span class="string">'age'</span>: <span class="number">20</span>, <span class="string">'gender'</span>: <span class="string">'male'</span>&#125;</span><br><span class="line">s = &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>&#125;</span><br><span class="line">s.add(<span class="number">4</span>) <span class="comment"># 增加元素 4 到集合</span></span><br><span class="line">s</span><br><span class="line">    &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>&#125;</span><br><span class="line">s.remove(<span class="number">4</span>) <span class="comment"># 从集合中删除元素 4</span></span><br><span class="line">s</span><br><span class="line">    &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>&#125;</span><br></pre></td></tr></table></figure><ul><li>集合的 pop() 操作是删除集合中最后一个元素，可是集合本身是无序的，你无法知道会删除哪个元素，因此这个操作谨慎使用</li></ul></li><li><p>对字典或集合进行排序：</p><ul><li><p>对于字典，通常根据键或者值进行升序或降序排序</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">d = &#123;<span class="string">'b'</span>: <span class="number">1</span>, <span class="string">'a'</span>: <span class="number">2</span>, <span class="string">'c'</span>: <span class="number">10</span>&#125;</span><br><span class="line">d_sorted_by_key = sorted(d.items(), key=<span class="keyword">lambda</span> x: x[<span class="number">0</span>]) <span class="comment"># 根据字典键的升序排序</span></span><br><span class="line">d_sorted_by_value = sorted(d.items(), key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>]) <span class="comment"># 根据字典值的升序排序</span></span><br><span class="line">d_sorted_by_key</span><br><span class="line">    [(<span class="string">'a'</span>, <span class="number">2</span>), (<span class="string">'b'</span>, <span class="number">1</span>), (<span class="string">'c'</span>, <span class="number">10</span>)]</span><br><span class="line">d_sorted_by_value</span><br><span class="line">    [(<span class="string">'b'</span>, <span class="number">1</span>), (<span class="string">'a'</span>, <span class="number">2</span>), (<span class="string">'c'</span>, <span class="number">10</span>)]</span><br><span class="line"><span class="comment"># 这里返回了一个列表。列表中的每个元素，是由原字典的键和值组成的元组</span></span><br></pre></td></tr></table></figure></li><li><p>对集合进行排序：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">s = &#123;<span class="number">3</span>,<span class="number">4</span>,<span class="number">2</span>,<span class="number">1</span>&#125;</span><br><span class="line">sorted(s)</span><br><span class="line">    [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]</span><br><span class="line"><span class="comment"># 返回排好序的列表</span></span><br></pre></td></tr></table></figure></li></ul></li></ul><h3 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h3><ul><li>字典和集合是进行过性能高度优化的数据结构，特别是对于查找、添加和删除操作</li><li>例子一：<ul><li>电商企业的后台，存储了每件产品的 ID、名称和价格。现在的需求是，给定某件商品的 ID，我们要找出其价格。</li><li>若用列表来存储这些数据结构，并进行查找，时间复杂度就为O(n), 即使我们先对列表进行排序，然后使用二分查找，也会需要 O(logn), 且列表的排序还需要 O(nlogn) 的时间</li><li>若使用字典，只需 O(1) 的时间复杂度就可以完成，因为字典内部组成是一张哈希表</li></ul></li><li>例子二：<ul><li>现在需求变成，要找出这些商品有多少种不同的价格</li><li>若使用列表，则有两层循环（循环原始数据表和新建的unique列表），最差情况需要O(n^2)</li><li>若选择使用集合，则只有一层循环(只循环原始数据表，新建的unique为集合，添加/查找只需O(1)), 总时间复杂度就是O(n)</li></ul></li></ul><h3 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h3><ul><li>字典和集合的内部结构都是一张哈希表</li><li>字典的表，储存了哈希值，键和值3个元素</li><li>集合的表，只有单一的元素</li><li>插入操作：<ul><li>每次向字典或集合插入一个元素时，Python 会首先计算键的哈希值（hash(key)），再和 mask = PyDicMinSize - 1 做与操作，计算这个元素应该插入哈希表的位置 index = hash(key) &amp; mask。如果哈希表中此位置是空的，那么这个元素就会被插入其中。</li><li>若此位置已被占用，Python 便会比较两个元素的哈希值和键是否相等：若两者都相等，则表明这个元素已经存在，如果值不同，则更新值；若两者中有一个不相等，这种情况我们通常称为哈希冲突（hash collision), 思是两个元素的键不相等，但是哈希值相等。种情况下，Python 便会继续寻找表中空余的位置，直到找到空位为止</li></ul></li><li>查找操作<ul><li>Python 会根据哈希值，找到其应该处于的位置；</li><li>然后，比较哈希表这个位置中元素的哈希值和键，与需要查找的元素是否相等</li><li>如果相等，则直接返回；如果不等，则继续查找，直到找到空位或者抛出异常为止</li></ul></li><li>删除操作<ul><li>Python 会暂时对这个位置的元素，赋于一个特殊的值，等到重新调整哈希表的大小时，再将其删除</li></ul></li><li>哈希冲突的发生，往往会降低字典和集合操作的速度；为了保证其高效性，字典和集合内的哈希表，通常会保证其至少留有1/3 的剩余空间。随着元素的不停插入，当剩余空间小于 1/3 时，Python 会重新获取更大的内存空间，扩充哈希表。在这种情况下，表内所有的元素位置都会被重新排放。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;基础&quot;&gt;&lt;a href=&quot;#基础&quot; class=&quot;headerlink&quot; title=&quot;基础&quot;&gt;&lt;/a&gt;基础&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;字典(dict)：由键（key）和值（value）配对组成的元素的集合&lt;ul&gt;
&lt;li&gt;在 Python3.7+，字典被确定为有
      
    
    </summary>
    
    
      <category term="Coding" scheme="http://tracyxinwang.site/blog/tags/Coding/"/>
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
      <category term="Python" scheme="http://tracyxinwang.site/blog/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Python核心技术与实战06 输入输出</title>
    <link href="http://tracyxinwang.site/blog/2019/05/22/python06/"/>
    <id>http://tracyxinwang.site/blog/2019/05/22/python06/</id>
    <published>2019-05-22T07:44:23.000Z</published>
    <updated>2019-07-22T03:31:15.219Z</updated>
    
    <content type="html"><![CDATA[<h3 id="基础"><a href="#基础" class="headerlink" title="基础"></a>基础</h3><ul><li>input() 函数暂停程序运行，同时等待键盘输入；直到回车被按下，函数的参数即为提示语，输入的类型永远是<strong>字符串型（str）</strong>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">name = input(&apos;your name:&apos;)</span><br></pre></td></tr></table></figure></li></ul><h3 id="文件输入输出"><a href="#文件输入输出" class="headerlink" title="文件输入输出"></a>文件输入输出</h3><ul><li>用 open() 函数拿到文件的指针<ul><li>第一个参数指定文件位置</li><li>第二个参数，’r’表示读取，’w’ 则表示写，’a’ 表示 append</li></ul></li><li><p>拿到指针后，通过 read() 函数来读取全部内容</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">with open(&apos;in.txt&apos;, &apos;r&apos;) as fin:</span><br><span class="line">    text = fin.read()</span><br></pre></td></tr></table></figure><ul><li>此方法优点是方便，缺点是如果文件过大，一次性读取可能造成内存崩溃</li><li>此时可给read指定参数size, 用来读取最大长度</li><li>也可通过 readline() 函数每次读取一行</li><li>open() 函数对应于 close() 函数，正常情况下，调用了read() 读取完毕之后就应该立刻关掉该打开的文件，但使用 with 语句，就不需要显式调用close(). 在 with 的语境下任务执行完毕后，close() 函数会被自动调用</li></ul></li><li>write() 函数将字符串输出到文件中</li></ul><p>\newline</p><p>极客时间版权所有: <a href="https://time.geekbang.org/column/article/96570" target="_blank" rel="noopener">https://time.geekbang.org/column/article/96570</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;基础&quot;&gt;&lt;a href=&quot;#基础&quot; class=&quot;headerlink&quot; title=&quot;基础&quot;&gt;&lt;/a&gt;基础&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;input() 函数暂停程序运行，同时等待键盘输入；直到回车被按下，函数的参数即为提示语，输入的类型永远是&lt;strong&gt;字符串
      
    
    </summary>
    
    
      <category term="Coding" scheme="http://tracyxinwang.site/blog/tags/Coding/"/>
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
      <category term="Python" scheme="http://tracyxinwang.site/blog/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>编程规范</title>
    <link href="http://tracyxinwang.site/blog/2019/05/14/Huawei_note/"/>
    <id>http://tracyxinwang.site/blog/2019/05/14/Huawei_note/</id>
    <published>2019-05-14T10:44:23.000Z</published>
    <updated>2019-05-16T11:55:25.424Z</updated>
    
    <content type="html"><![CDATA[<h3 id="头文件"><a href="#头文件" class="headerlink" title="头文件"></a>头文件</h3><ul><li>在一个设计良好的系统中， 修改一个文件，只需要重新编译数个，甚至是一个文件：<ul><li>e.g. 若文件A包含B， B包含C， C包含D，最终几乎每一个源文件都包含了项目组所有的头文件，从而导致<br>绝大部分编译时间都花在解析头文件<h4 id="原则"><a href="#原则" class="headerlink" title="原则"></a>原则</h4></li></ul></li><li>头文件中适合放置接口的声明，不适合放置实现<ul><li>头文件是模块（ Module）或单元（ Unit）的对外接口。头文件中应放置对外部的声明，如对外提供的函数声明、宏定义、类型定义等。</li><li>内部使用的函数（相当于类的私有方法）声明不应放在头文件中。</li><li>内部使用的宏、枚举、结构定义不应放入头文件中。</li><li>变量定义不应放在头文件中，应放在.c文件中。</li><li>变量的声明尽量不要放在头文件中，亦即尽量不要使用全局变量作为接口。变量是模块或单元的内部实现细节，不应通过在头文件中声明的方式直接暴露给外部，应通过函数接口的方式进行对外暴露。 即使必须使用全局变量，也只应当在.c中定义全局变量，在.h中仅声明变量为全局的。</li></ul></li><li>头文件应当职责单一<ul><li>不常用的头文件不应该被包含</li></ul></li><li>头文件应向稳定的方向包含<ul><li>头文件的包含关系是一种依赖，一般来说，应当让不稳定的模块依赖稳定的模块，从而当不稳定的模块发生变化时，不会影响（编译）稳定的模块。</li><li>如：产品依赖于平台，平台依赖于标准库。<h4 id="规则"><a href="#规则" class="headerlink" title="规则"></a>规则</h4></li></ul></li><li>每一个.c文件应有一个同名.h文件，用于声明需要对外公开的接口</li><li>禁止头文件循环依赖</li><li>c/.h文件禁止包含用不到的头文件</li><li>头文件应当自包含：<ul><li>自包含就是任意一个头文件均可独立编译</li></ul></li><li>总是编写内部#include保护符（ #define 保护）<ul><li>以阻止头文件内容被包含多于一次：通常的手段是为每个文件配置一个宏，当头文件第一次被包含时就定义这个宏，并在头文件被再次包含时使用它以排除文件内容</li><li>所有头文件都应当使用#define 防止头文件被多重包含，命名格式为<code>FILENAME_H</code>，为了保证唯一性，更好的命名是<code>PROJECTNAME_PATH_FILENAME_H</code></li><li>没有在宏最前面加上<code>_</code>，即使用<code>FILENAME_H</code>代替<code>_FILENAME_H_</code>，是因为一般以”_”和”__”开头的标识符为系统保留或者标准库使用</li></ul></li><li>禁止在头文件中定义变量</li><li>只能通过包含头文件的方式使用其他.c提供的接口，禁止在.c中通过extern的方式使用外部函数接口、变量<ul><li>若a.c使用了b.c定义的foo()函数，则应当在b.h中声明extern int foo(int input)；并在a.c中通过#include &lt;b.h&gt;来使用foo。禁止通过在a.c中直接写extern int foo(int input);来使用foo，后面这种写法容易在foo改变时可能导致声明和定义不一致。</li></ul></li><li>禁止在extern “C”中包含头文件<ul><li>在extern “C”中包含头文件， 会导致extern “C”嵌套， Visual Studio对extern “C”嵌套层次有限制，嵌套层次太多会编译错误</li><li>P9-10 ？？？<h4 id="建议"><a href="#建议" class="headerlink" title="建议"></a>建议</h4></li></ul></li><li>一个模块通常包含多个.c文件，建议放在同一个目录下，目录名即为模块名。为方便外部使用者，建议每一个模块提供一个.h，文件名为目录名</li><li>如果一个模块包含多个子模块，则建议每一个子模块提供一个对外的.h，文件名为子模块名。说明：降低接口使用者的编写难度。</li><li>头文件不要使用非习惯用法的扩展名，如.inc</li><li>同一产品统一包含头文件排列方式：<ul><li>常见的包含头文件排列方式： 功能块排序、文件名升序、稳定度排序</li><li>以升序方式排列头文件可以避免头文件被重复包含</li><li>以稳定度排序， 建议将不稳定的头文件放在前面，这样不必编译稳定文件就可知不稳定文件有没有问题，减少编译时间</li></ul></li></ul><h3 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h3><ul><li>代码的有效组织包括：逻辑层组织和物理层组织两个方面。</li><li>逻辑层，主要是把不同功能的函数通过某种联系组织起来，主要关注模块间的接口，也就是模块的架构。</li><li>物理层，无论使用什么样的目录或者名字空间等，需要把函数用一种标准的方法组织起来。例如：设计良好的目录结构、函数名字、文件组织等，这样可以方便查找<h4 id="原则-1"><a href="#原则-1" class="headerlink" title="原则"></a>原则</h4></li><li>一个函数仅完成一件功能</li><li>重复代码应该尽可能提炼成函数<h4 id="规则-1"><a href="#规则-1" class="headerlink" title="规则"></a>规则</h4></li><li>避免函数过长，新增函数不超过50行（非空非注释行）</li><li>避免函数的代码块嵌套过深，新增函数的代码块嵌套不超过4层</li><li>可重入函数应避免使用共享变量；若需要使用，则应通过互斥手段（关中断、信号量）对其加以保护<ul><li>可重入函数是指可能被多个任务并发调用的函数。在多任务操作系统中，函数具有可重入性是多个任务可以共用此函数的必要条件。共享变量指的全局变量和static变量</li><li>编写C语言的可重入函数时，不应使用static局部变量，否则必须经过特殊处理，才能使函数具有可重入性</li><li>P16 例子</li></ul></li><li>对参数的合法性检查，由调用者负责还是由接口函数负责，应在项目组/模块内应统一规定。缺省由调用者负责<ul><li>对于模块间接口函数的参数的合法性检查这一问题，往往有两个极端现象，即：要么是调用者和被调用者对参数均不作合法性检查，结果就遗漏了合法性检查这一必要的处理过程，造成问题隐患；要么就是调用者和被调用者均对参数进行合法性检查，这种情况虽不会造成问题，但产生了冗余代码，降低了效率</li></ul></li><li>对函数的错误返回码要全面处理<ul><li>一个函数（标准库中的函数/第三方库函数/用户定义的函数）能够提供一些指示错误发生的方法。这可以通过使用错误标记、特殊的返回数据或者其他手段，不管什么时候函数提供了这样的机制，调用程序应该在函数返回时立刻检查错误指示</li></ul></li><li>设计高扇入，合理扇出（小于7）的函数<ul><li>扇出是指一个函数直接调用（控制）其它函数的数目，而扇入是指有多少上级函数调用它<h4 id="建议-1"><a href="#建议-1" class="headerlink" title="建议"></a>建议</h4></li></ul></li><li>函数不变参数使用const</li><li>函数应避免使用全局变量、静态局部变量和I/O操作，不可避免的地方应集中使用<ul><li>带有内部“存储器”的函数的功能可能是不可预测的，因为它的输出可能取决于内部存储器（如某标记）的状态。这样的函数既不易于理解又不利于测试和维护。</li><li>在C语言中，函数的static局部变量是函数的内部存储器，有可能使函数的功能不可预测，然而，当某函数的返回值为指针类型时，则必须是static的局部变量的地址作为返回值，若为auto类，则返回为错针。</li></ul></li><li>检查函数所有非参数输入的有效性，如数据文件、公共变量等<ul><li>函数的输入主要有两种：一种是参数输入；另一种是全局变量、数据文件的输入，即非参数输入。函数在使用输入参数之前，应进行有效性检查。</li></ul></li><li>函数的参数个数不超过5个</li><li>除打印类函数外，不要使用可变长参函数</li><li>在源文件范围内声明和定义的所有函数，除非外部可见，否则应该增加static关键字<ul><li>如果一个函数只是在同一文件中的其他地方调用，那么就用static声明。</li><li>使用static确保只是在声明它的文件中是可见的，并且避免了和其他文件或库中的相同标识符发生混淆的可能性。</li><li>建议定义一个STATIC宏，在调试阶段，将STATIC定义为static，版本发布时，改为空，以便于后续的打热补丁等操作</li></ul></li></ul><h3 id="标识符命名与定义"><a href="#标识符命名与定义" class="headerlink" title="标识符命名与定义"></a>标识符命名与定义</h3><ul><li>文件命名统一采用小写字符</li><li>全局变量应增加“g_”前缀</li><li>静态变量应增加“s_”前缀</li><li>函数命名应以函数要执行的动作命名，一般采用动词或者动词＋名词的结构</li><li>对于数值或者字符串等等常量的定义，建议采用全大写字母，单词之间加下划线“_”的方式命名（枚举同样建议使用此方式定义）</li></ul><h3 id="变量"><a href="#变量" class="headerlink" title="变量"></a>变量</h3><h4 id="原则-2"><a href="#原则-2" class="headerlink" title="原则"></a>原则</h4><ul><li>一个变量只有一个功能，不能把一个变量用作多种用途</li><li>struct 功能单一；不要设计面面俱到的数据结构</li><li>不用或者少用全局变量:<ul><li>单个文件内部可以使用static的全局变量，可以将其理解为类的私有成员变量</li></ul></li><li>防止局部变量与全局变量同名<h4 id="规则和建议"><a href="#规则和建议" class="headerlink" title="规则和建议"></a>规则和建议</h4></li><li>通讯过程中使用的结构，必须注意字节序</li><li>严禁使用未经初始化的变量作为右值</li><li>构造仅有一个模块或函数可以修改、创建，而其余有关模块或函数只访问的全局变量，防止多个不同模块或函数都可以修改、创建同一全局变量的现象</li><li>使用面向接口编程思想，通过API访问数据：如果本模块的数据需要对外部模块开放，应提供接口函数来设置、获取，同时注意全局数据的访问互斥</li><li>明确全局变量的初始化顺序，避免跨模块的初始化依赖</li></ul><h3 id="宏、常量"><a href="#宏、常量" class="headerlink" title="宏、常量"></a>宏、常量</h3><ul><li>用宏定义表达式时，要使用完备的括号：<ul><li>e.g.: #define RECTANGLE_AREA(a, b) ((a) * (b))</li></ul></li><li><p>将宏所定义的多条表达式放在大括号中, 多条语句时写成do while(0)的方式     </p><ul><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#define FOO(x) do &#123; \</span><br><span class="line">    printf(&quot;arg is %s\n&quot;, x); \</span><br><span class="line">    do_something_useful(x); \</span><br><span class="line">    &#125; while(0)</span><br></pre></td></tr></table></figure></li></ul></li><li><p>使用宏时，不允许参数发生变化</p><ul><li>e.g. 定义SQUARE(a) 为((a) * (a))， 并赋值 a++</li></ul></li><li>不允许直接使用魔鬼数字：<ul><li>对于局部使用的唯一含义的魔鬼数字，可以在代码周围增加说明注释，也可以定义局部const变量，变量命名自注释</li><li>对于广泛使用的数字，必须定义const全局变量/宏；同样变量/宏命名应是自注释的</li></ul></li><li>常量建议使用const定义代替宏</li><li>宏定义中尽量不使用return、 goto、 continue、 break等改变程序流程的语句</li></ul><h3 id="质量保证"><a href="#质量保证" class="headerlink" title="质量保证"></a>质量保证</h3><ul><li>必须了解编译系统的内存分配方式，特别是编译系统对不同类型的变量的内存分配规则，如局部变量在何处分配、静态变量在何处分配等</li><li>禁止内存操作越界<ul><li>数组的大小要考虑最大情况，避免数组分配空间不够</li><li>避免使用危险函数sprintf /vsprintf/strcpy/strcat/gets操作字符串，使用相对安全的函数 snprintf/strncpy/strncat/fgets代替    </li><li>使用memcpy/memset时一定要确保长度不要越界</li><li>字符串考虑最后的’ \0’， 确保所有字符串是以’ \0’结束</li><li>指针加减操作时，考虑指针类型长度</li><li>数组下标进行检查</li><li>使用时sizeof或者strlen计算结构/字符串长度，避免手工计算</li></ul></li><li>禁止内存泄漏<ul><li>内存和资源（包括定时器/文件句柄/Socket/队列/信号量/GUI等各种资源）泄漏是常见的错误</li><li>异常出口处检查内存、定时器/文件句柄/Socket/队列/信号量/GUI等资源是否全部释放</li><li>删除结构指针时，必须从底层向上层顺序删除</li><li>使用指针数组时，确保在释放数组时，数组中的每个元素指针是否已经提前被释放了</li><li>避免重复分配内存</li><li>小心使用有return、 break语句的宏，确保前面资源已经释放</li><li>检查队列中每个成员是否释放</li></ul></li><li>禁止引用已经释放的内存空间    <ul><li>内存释放后，把指针置为NULL；使用内存指针前进行非空判断</li><li>耦合度较强的模块互相调用时，一定要仔细考虑其调用关系，防止已经删除的对象被再次使用</li><li>避免操作已发送消息的内存</li><li>自动存储对象的地址不应赋值给其他的在第一个对象已经停止存在后仍然保持的对象（具有更大作用域的对象或者静态对象或者从一个函数返回的对象）</li></ul></li><li>函数中分配的内存，在函数退出之前要释放<ul><li>有很多函数申请内存，保存在数据结构中，要在申请处加上注释，说明在何处释放</li></ul></li><li>if语句尽量加上else分支，对没有else分支的语句要小心对待</li><li>不要滥用goto语句</li></ul><h3 id="程序效率"><a href="#程序效率" class="headerlink" title="程序效率"></a>程序效率</h3><ul><li>将不变条件的计算移到循环体外</li><li>对于多维大数组，避免来回跳跃式访问数组成员</li><li>创建资源库，以减少分配对象的开销</li><li>将多次被调用的 “小函数”改为inline函数或者宏实现</li></ul><h3 id="注释"><a href="#注释" class="headerlink" title="注释"></a>注释</h3><ul><li>文件头部应进行注释，注释必须列出：版权说明、版本号、生成日期、作者姓名、工号、内容、功能说明、与其它文件的关系、修改日志等，头文件的注释中还应有函数功能简要说明。</li><li>函数声明处注释描述函数功能、性能及用法，包括输入和输出参数、函数返回值、可重入的要求等；定义处详细描述函数功能和实现要点，如实现的简要步骤、实现的理由、 设计约束等</li><li>全局变量要有较详细的注释，包括对其功能、取值范围以及存取时注意事项等的说明</li></ul><h3 id="安全性"><a href="#安全性" class="headerlink" title="安全性"></a>安全性</h3><ul><li>对用户输入进行检查：<ul><li>用户输入作为循环条件，数组下标，内存分配的尺寸参数，格式化字符串，业务数据（如作为命令执行参数、拼装sql语句、以特定格式持久化）等时需尤为注意</li><li>用户输入作为数值的，做数值范围检查</li><li>用户输入是字符串的，检查字符串长度</li><li>用户输入作为格式化字符串的，检查关键字“ %”</li><li>用户输入作为业务数据，对关键字进行检查、转义</li></ul></li><li>确保所有字符串是以NULL结束<ul><li>C语言中‟\0‟作为字符串的结束符，即NULL结束符。</li><li>标准字符串处理函数（如strcpy()、 strlen()）依赖NULL结束符来确定字符串的长度。没有正确使用NULL结束字符串会导致缓冲区溢出和其它未定义的行为</li></ul></li><li>不要将边界不明确的字符串写到固定长度的数组中<ul><li>边界不明确的字符串（如来自gets()、 getenv()、 scanf()的字符串），长度可能大于目标数组长度，直接拷贝到固定长度的数组中容易导致缓冲区溢出</li></ul></li><li>避免整数溢出<ul><li>当一个整数被增加超过其最大值时会发生整数上溢，被减小小于其最小值时会发生整数下溢</li><li>带符号和无符号的数都有可能发生溢出</li></ul></li><li>避免符号错误<ul><li>有时从带符号整型转换到无符号整型会发生符号错误，符号错误并不丢失数据，但数据失去了原来的含义</li></ul></li><li>避免截断错误<ul><li>将一个较大整型转换为较小整型，并且该数的原值超出较小类型的表示范围，就会发生截断错误，原值的低位被保留而高位被丢弃。截断错误会引起数据丢失</li></ul></li><li>避免使用strlen()计算二进制数据的长度<ul><li>strlen()函数用于计算字符串的长度，它返回字符串中第一个NULL结束符之前的字符的数量。因此用strlen()处理文件I/O函数读取的内容时要小心，因为这些内容可能是二进制也可能是文本</li></ul></li></ul><h3 id="文档引用资源"><a href="#文档引用资源" class="headerlink" title="文档引用资源"></a>文档引用资源</h3><ul><li>google C++ Style Guide</li><li>《 敏捷软件开发：原则、模式与实践》 （ Robert C.Martin 著 ） 第二部分“敏捷设计”章节</li><li>《 敏捷软件开发：原则、模式与实践》 第八章，单一职责原则(SRP)</li><li>《代码整洁之道》 </li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;头文件&quot;&gt;&lt;a href=&quot;#头文件&quot; class=&quot;headerlink&quot; title=&quot;头文件&quot;&gt;&lt;/a&gt;头文件&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;在一个设计良好的系统中， 修改一个文件，只需要重新编译数个，甚至是一个文件：&lt;ul&gt;
&lt;li&gt;e.g. 若文件A包含B，
      
    
    </summary>
    
    
      <category term="Coding" scheme="http://tracyxinwang.site/blog/tags/Coding/"/>
    
      <category term="Algorithm" scheme="http://tracyxinwang.site/blog/tags/Algorithm/"/>
    
  </entry>
  
  <entry>
    <title>后会有期</title>
    <link href="http://tracyxinwang.site/blog/2019/04/20/life-in-Melbourne02/"/>
    <id>http://tracyxinwang.site/blog/2019/04/20/life-in-Melbourne02/</id>
    <published>2019-04-20T07:34:34.000Z</published>
    <updated>2019-04-20T06:33:14.000Z</updated>
    
    <content type="html"><![CDATA[<p>消耗了18kg的米，3.8L的油，2瓶老干妈，1.5瓶豆瓣酱，8T的硬盘，4支笔芯，1个草稿本，半年的交流就这样结束了。</p><p>到土澳的第一天坐在巴士开往city的时候，想起了17年的圣诞节，Angel邀请我们去她朋友家吃饭玩游戏。游戏大致是每个人抽一张卡，上面有个问题，你必须如实回答。我抽到的问题大概描述是，如果不考虑其他的一切，你最想居住的一个地方是哪里，为什么。我想了一下，说澳大利亚，理由是可能是受初中语文老师影响，觉得那边日子很诗意，大牧场放牛羊做自己喜欢的事情，多爽。<br>从着手申请交流到最终选择墨大再到到达的前一刻，我都没有想起这件事，却在实实在在踏上这片土地的时候，想起了当时说的话，顿时感叹或许是念念不忘，冥冥之中？</p><p>这半年里我逐渐想明白了一件事情，合适的才是最好的。其实道理都知道，可人就是这样，总想争取最好的。当时最终确定的时候我给丁哥说我选择墨大，不去斯坦福了。丁哥说他老板绝对不会同意他去一个排名跟中大差不多的学校。（墨大：???）现在结束交流了，我只想说我一定是花光了前几年积攒的运气，才遇到Andrew这样一个好supervisor. Angel带我入了neuroscience的门，Andrew让我看到用数学、工程和统计的方法研究neuroscience有多美。原来可以这么简单！原来这样做的原因是这样的！如果早一点遇到Andrew，我还会不会像现在这样，对不留学术界的态度这样决绝。毕竟我可是抱着要研究这个世界上最复杂的系统这个信念来读phd的呀。<br>有次我遇到一个问题，觉得无法解决，有点愁眉苦脸那种，跑去问Andrew。Andrew噼里啪啦一下给我好几个解决方案。然后完了问我，are you happy now? 让我第一次觉得做科研就是为了快乐呀。</p><p>除了Andrew，其他最让我想说感谢的就是组里面的人了。随便问谁什么问题，都是手把手教，一步一步解释那种。我还记得有次我问 Caio 一个问题，他先是给我在草稿纸上讲了整个流程，然后一行一行代码给我演示，最后让我自己操作了一下确保真的完全ok了才走。实验室的中国学姐在她忙得不行的时候，都花时间特别仔细地给我讲问她的问题。大概是继承了Andrew的优良传统吧，毕竟他给我讲完之后都会让我复述一遍确保我没有哪里出问题, 还说如果我忘了就再问他他会提醒我。所谓，慢即是快。我那个草稿本，有很大一部分，都是这些可爱的人讲解时留下的笔迹。</p><p>严谨，是这里给我留下的另一个印象。每个study的 sanity check 是必不可少的，这在现在灌水日益严重的学术界太难得了。我记得我来这里第一个月做的东西，其实结果当时还不错的，后来Andrew提醒了一下初始化的问题（伪随机），然后我又把程序跑了几遍，发现结果不太稳定，模型并不robust，也没想出解决办法，于是后来就暂放了这个项目。结果上一周吧发现有人发了一篇跟我们当时想法一模一样的paper，我们很惊喜，联系到作者，结果一问发现人家根本就没考虑这个问题，不知道还有伪随机这种东西。。。Andrew说我应该写一篇techinical report 告诉大家这个模型不可靠，使用需谨慎。我说那这不会得罪很多人吗（提出这个模型的组也是个大牛组）。。。他说可是这是事实啊，没办法，科研就是这样的。</p><p>他们一起组成了我对磕盐的一切幻想。愿你们一直可以这样快乐地磕盐下去。</p><p>在这里其实比较遗憾的是自己口语太渣了，所以没能跟来自世界各个地方的学生深度交流。他们真的对这个世界，自己的国家，发生的事情有自己的看法，他们也常问起中国的发展，tell us more about China. 每次听他们讲对一个事情的看法并坚持自己的看法都是一件很享受的事情。</p><p>当然还有house mates了，一问人多大，妈呀99年，吓死人，全是比自己小的。做饭最多的就是我和一楼小哥，他顿顿都是新鲜菜，我是做一次吃一天。其实我觉得还好啊，据我所知办公室有人做一次吃一周…他就老觉得我就是裹腹而已。。。嗯，这下可以回去吃食堂了。今天走之前室友们还一起吃了个饭，饭后每个人吃了两三个汤圆，寓意还挺好，谢谢大家了。</p><p>Angel还在的时候，曾经吃饭时说起quit这个问题，我说很佩服那些读了一两年还毅然选择quit的同学，他们真的很有勇气。Angel说，其实选择继续读下去，不是一件更有勇气的事情吗。<br>可能是吧。</p><p>谢谢这里遇见的每个人，祝你们在接下来的日子里，平安喜乐。<br>后会有期</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;消耗了18kg的米，3.8L的油，2瓶老干妈，1.5瓶豆瓣酱，8T的硬盘，4支笔芯，1个草稿本，半年的交流就这样结束了。&lt;/p&gt;
&lt;p&gt;到土澳的第一天坐在巴士开往city的时候，想起了17年的圣诞节，Angel邀请我们去她朋友家吃饭玩游戏。游戏大致是每个人抽一张卡，上面有个
      
    
    </summary>
    
    
      <category term="杂文" scheme="http://tracyxinwang.site/blog/tags/%E6%9D%82%E6%96%87/"/>
    
      <category term="碎碎念" scheme="http://tracyxinwang.site/blog/tags/%E7%A2%8E%E7%A2%8E%E5%BF%B5/"/>
    
  </entry>
  
  <entry>
    <title>NetworK Reduction Algorithm - Disparity filter</title>
    <link href="http://tracyxinwang.site/blog/2019/04/11/Net_Reduction/"/>
    <id>http://tracyxinwang.site/blog/2019/04/11/Net_Reduction/</id>
    <published>2019-04-11T01:29:13.000Z</published>
    <updated>2019-07-21T12:43:06.070Z</updated>
    
    <content type="html"><![CDATA[<p>The thing that network reduction algorithm does is to extract the backbone structure of undirected weighted network. There are different algorithms to e.g. k-core decomposition, minimum spanning tree and disparity filter. The main idea is to reduce the density to make the matrix or the graph more sparse.</p><h3 id="Disparity-filter"><a href="#Disparity-filter" class="headerlink" title="Disparity filter"></a>Disparity filter</h3><p>The disparity filter algorithm depends on the statistical null model.<br>The steps are as follows:</p><ul><li>Create the null model of normalised weighted distribution<ul><li>we define the strength of a node $i$ is $s_i = \sum_jw_{ij}$, where $w_{ij}$ is the weight of link between i and j.</li><li>The null model needs to be normalised to make sure that the nodes with low strength will not be biased. A normalized weight $p_{ij}$ is defined as $p_{ij} = w_{ij}/s_i$</li><li>Distribute the strength to nodes randomly: the normalized weights of a certain node with degree k is generated like this: k − 1 pins are randomly assigned between the interval 0 and 1. The interval is divided into k subintervals. The length of the subinterval represents the normalized weight of each link in the null model.</li><li>Based on the above null model. we can derive that the normalized weight distribution of a node with degree k follows $\rho (x)\,dx=(k-1)(1-x)^{ {k-2} }\,dx$</li></ul></li><li>Disparity filter<ul><li>For a given normalized weight $p_{ij}$, the p-value $α<em>{ij}$ of $p</em>{ij}$ based on the null model is given by $\alpha _{ {ij} }=1-(k-1)\int <em>{0}^{ {p</em>{ {ij} } } }(1-x)^{ {k-2} }\,dx$ which reduces to ${\displaystyle \alpha <em>{ij}=(1-p</em>{ij})^{k-1} }$. </li><li>The meaning of $α<em>{ij}$ is the probability of having normalized weight larger or equal to $p</em>{ij}$ in the framework of the given null model. By setting a significance level α (between 0 and 1), for any link of normalized weight $p_{ij}$, if $α_{ij}$ is larger than α, it will be filtered out (set as 0).</li></ul></li><li>MATLAB code:  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">w_thresh = disparity_func(s)</span><br><span class="line">    w=s;   % s is the input matrix (e.g. similarity matrix, connectivity matrix)</span><br><span class="line">    w_null=zeros(length(w),length(w));</span><br><span class="line">    <span class="keyword">for</span> j=1:length(w) % column</span><br><span class="line">        w_null(:,j)=w(:,j)/sum(w(:,j)); % compute the node strength <span class="keyword">for</span> each </span><br><span class="line">    end</span><br><span class="line">    ind_upper=find(triu(ones(length(w),length(w)),1));</span><br><span class="line">    </span><br><span class="line">    fprintf(<span class="string">'Find the smallest p-value needed for graph to remain connected...\n'</span>);</span><br><span class="line">    dns=linspace(0,1,200); % P-value</span><br><span class="line">    <span class="keyword">for</span> i=1:length(dns)</span><br><span class="line">        w_thresh=s;                 % Initialize the w_thresh every time</span><br><span class="line">        <span class="keyword">for</span> j=1:length(ind_upper)</span><br><span class="line">            [ii,jj]=ind2sub(size(w),ind_upper(j));</span><br><span class="line">            <span class="keyword">if</span> (1-w_null(ii,jj))^(K-1)&gt;dns(i) &amp;&amp; (1-w_null(jj,ii))^(K-1)&gt;dns(i)</span><br><span class="line">                w_thresh(ii,jj)=0; w_thresh(jj,ii)=0;</span><br><span class="line">            end</span><br><span class="line">        end</span><br><span class="line">        [~,comp_sizes]=get_components(~~w_thresh);</span><br><span class="line">        <span class="keyword">if</span> length(comp_sizes)==1</span><br><span class="line">            <span class="built_in">break</span></span><br><span class="line">        end</span><br><span class="line">    end</span><br></pre></td></tr></table></figure></li></ul><p>Reference:<br>wiki</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;The thing that network reduction algorithm does is to extract the backbone structure of undirected weighted network. There are different 
      
    
    </summary>
    
    
      <category term="Algorithm" scheme="http://tracyxinwang.site/blog/tags/Algorithm/"/>
    
      <category term="Network" scheme="http://tracyxinwang.site/blog/tags/Network/"/>
    
  </entry>
  
  <entry>
    <title>Hidden Markov Model - Multivariate Autoregressive model</title>
    <link href="http://tracyxinwang.site/blog/2019/03/11/HMM-MAR/"/>
    <id>http://tracyxinwang.site/blog/2019/03/11/HMM-MAR/</id>
    <published>2019-03-11T01:24:13.000Z</published>
    <updated>2019-03-11T03:09:38.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Moedel-description"><a href="#Moedel-description" class="headerlink" title="Moedel description"></a>Moedel description</h3><p>The HMM-MAR has two key ingredients: </p><ul><li>the Hidden Markov Model (HMM): <ul><li>An HMM describes a time series as a sequence of states, where each state has its own model of the observed data (i.e., the observation model) and the probability of being at a given state at each time point depends on the states assignment in the previous time point.</li><li>The transition probabilities (how likely is to be in state j if we were in state i just before) are also estimated by the model.</li></ul></li><li>and the Multivariate Autoregressive model (MAR):<ul><li>the observation model corresponds to a MAR model</li><li>characterises the behaviour of time series by linear historical interactions between the observed time series from different brain regions. </li><li>In different words, a MAR model aims to predict the multichannel signal value at each time point as a linear combination of signal values at previous time points. </li><li>MARs are able to characterise the <u>frequency structure of the data</u>, and by making the model multivariate, are able to capture <u>interactions (e.g., coherence) between multiple brain regions</u>. </li><li>Therefore, each state is related to a different set of multi-region autoregression coefficients describing the neural oscillations.</li><li>When the order of the MAR model is set to zero, the states are modelled using Gaussian distributions, in which case the segmentation will be based on instantaneous activation and connectivity.</li></ul></li><li>use variational Bayes inference</li></ul><h3 id="MAR-parametrisation"><a href="#MAR-parametrisation" class="headerlink" title="MAR parametrisation"></a>MAR parametrisation</h3><ul><li>order parameter P: defines how far we go back in time to predict each time point.</li><li>When the number of regions is high, it is easy that for the MAR to overfit the data. <ul><li>That is, a relatively simple MAR model can explain a lot of variance, which will induce the HMM-MAR inference process to <u>drop most of the states of the model</u> by letting a few (or even one) dominant states to control the entire time series, thus hindering the discovery of quasi-stationary connectivity networks. </li></ul></li><li>To solve this:<ul><li>To use a low order, for example 3, and, if needed, increase that value and see how the segmentation changes.</li><li>To work on a low-dimensional version of the data using PCA (see below).</li><li>To avoid using the cross-channel terms, such that each state is characterised by their spectra but not the cross-spectra</li></ul></li></ul><h3 id="Model-selection"><a href="#Model-selection" class="headerlink" title="Model selection"></a>Model selection</h3><ul><li>In order to determine the number of HMM states, K, a possible strategy is to fix the maximum number, and then the Bayesian inference process can discard some of them if there is insufficient evidence to support their presence in the data. </li><li>The free energy, a quantity that approximates the model evidence, can also be used to choose K. </li></ul><h3 id="Spectral-description-of-the-states"><a href="#Spectral-description-of-the-states" class="headerlink" title="Spectral description of the states"></a>Spectral description of the states</h3><ul><li>MAR corresponds with the frequency domain</li><li>Hence the state segmentation is driven by the spectral content of each separate channel and the spectral relations between channels. </li><li>Once the HMM-MAR model is trained and we have the state time courses, we can estimate the spectral content of the model, including the following measures:<ul><li>Power spectral density (PSD)</li><li>Coherence</li><li>Partial directed coherence (PDC)</li><li>Phase</li></ul></li><li>The estimation of these quantities can be done by one of these two methods:<ul><li>A parametric estimation, using the MAR coefficients.</li><li>A nonparametric estimation, using a novel statewise version of the multitaper. This would be the way to do it for example if the states were specified to be Gaussian distributions (i.e. MAR order equal to zero).</li></ul></li><li>In the parametric case<ul><li>we can use the MAR coefficients as returned by the model. </li><li>These coefficients correspond to a maximum a posteriori estimation (which means that they have been regularised by the prior), and, as described above, can have an incomplete parametrisation. </li><li>For the sake of spectral estimation, we prefer to re-estimate the MAR coefficients using maximum likelihood, as is standard in the signal processing literature, and use a complete parametrisation, i.e. using lags (t-1,t-2,…,t-P).</li></ul></li><li>In the non-parametric case:<ul><li>take advantage of the inferred HMM state time courses as temporal windows for estimating the state-specific spectral properties using a weighted version of the multitaper. PDC has not a closed solution in the non-parametric case, so that we need to use the so-called Wilson factorisation</li></ul></li></ul><h3 id="Analysis-of-results"><a href="#Analysis-of-results" class="headerlink" title="Analysis of results"></a>Analysis of results</h3><ul><li>The <strong>mean pattern of activity</strong> of each state. The function getMean(hmm,k) outputs the mean of the Gaussian distribution, assuming that the option zeromean was set to 0. Note that this is mostly useful for the Gaussian distribution, but not that much for the MAR model.</li><li>The <strong>functional connectivity</strong> of each state. The function getFuncConn(hmm,k) outputs the covariance and correlation matrices of state k, when the states are distributed Gaussian (order=0). In the case of a MAR state model, these refer to the covariance matrix of the residual.</li><li>The <strong>transition probabilities</strong>. The function getTransProbs(hmm) returns the transition probabilies from any state to any other state, without considering the persistence probabilities (i.e. the probability to remain in the same state). The transition probability matrix including the <strong>persistence probabilities</strong> is contained in hmm.P.</li><li>The <strong>transition probabilities for a subset of the subjects</strong>. The function getMaskedTransProbMats returns the transition probabilities (including persistencies) for subsets of the data as specified in the parameter Masks. This is useful for example if we wish to find differences in the state transitions between groups.</li><li>The state time <strong>fractional occupancies</strong>, using getFractionalOccupancy(Gamma,T,dim). This can refer to either (i) how much time the HMM spends on each state at each time point on average (across trials), or (ii) how much time each subject/trial/session spends in each state (i.e. the average state probability across time, per session or subject). The former, useful for task, is computed when dim=1; the latter, useful to investigate differences in occupancies between subjects, is computed when dim=2.</li><li>The state <strong>switching rates</strong>. The function getSwitchingRate provides a measure of the state switching rate for each session/subject, and can be understood as a measure of stability per subject.</li><li>The state <strong>life times</strong>. The function getStateLifeTimes returns, per subject/session/trial, a vector of life times per state, containing the number of time points per visit. This reflects the temporal stability of the states.</li><li>The state <strong>interval times</strong>. The function getStateIntervalTimes returns, per subject/session/trial, a vector of interval times per state, containing the number of time points between visits. The interval times, the life times, the fractional occupancies and the switching rates are sometimes referred to collectively as the “chronnectome”.</li><li><strong>maximum fractional occupancy</strong>, used to measure whether the HMM is effectively capturing the dynamics on the data. The function getMaxFractionalOccupancy finds the maximum fractional occupancy for each subject/trial. This is a useful statistic to diagnose whether the HMM solution is “mixing well” or states are assigned to describe entire subjects (in which case the HMM is doing a poor job in finding the data dynamics).</li><li>The <strong>onset time</strong> of the states for each session. The function getStateOnsets provides a vector per session and state of when specifically the state becomes active. That can be used to relate to task information.</li><li>The <strong>evoked state probability</strong> relative to a stimulus. The function evokedStateProbability() can be used to examine how the stimulus modulates the state probabilities.</li><li>The <strong>similarity between two HMM runs</strong>. There are multiple ways to measure the similarity between HMM runs (on the same or comparable data). One of them is to measure the statistical dependence between the state time courses between the two runs. This is done with the function getGammaSimilarity(gamma1,gamma2), which measures the overlapping between the state probabilities after optimally reordering the states.</li></ul><p>Reference:<br><a href="https://github.com/OHBA-analysis/HMM-MAR/wiki/User-Guide" target="_blank" rel="noopener">https://github.com/OHBA-analysis/HMM-MAR/wiki/User-Guide</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;Moedel-description&quot;&gt;&lt;a href=&quot;#Moedel-description&quot; class=&quot;headerlink&quot; title=&quot;Moedel description&quot;&gt;&lt;/a&gt;Moedel description&lt;/h3&gt;&lt;p&gt;The HM
      
    
    </summary>
    
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
      <category term="Brain" scheme="http://tracyxinwang.site/blog/tags/Brain/"/>
    
  </entry>
  
  <entry>
    <title>Wiener Process</title>
    <link href="http://tracyxinwang.site/blog/2019/03/01/WienerProcess/"/>
    <id>http://tracyxinwang.site/blog/2019/03/01/WienerProcess/</id>
    <published>2019-03-01T01:03:13.000Z</published>
    <updated>2019-02-28T23:00:44.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Wiener-process"><a href="#Wiener-process" class="headerlink" title="Wiener process"></a>Wiener process</h3><p>The Wiener process</p><ul><li>also called Brownian motion, is a kind of <strong>Markov stochastic process</strong>.</li><li><strong>Stochastic process</strong>: <ul><li>whose value changes over time in an uncertain way</li><li>we only know the distribution of the possible values of the process at any time point. - In contrast to the stochastic process, a deterministic process is with an exact value at any time point.</li></ul></li><li><strong>Markov process</strong>: the likelihood of the state at any future time point depends only on<br>its present state but not on any past states</li></ul><p>The properties of the Wiener process ${Z(t)}$ for $t ≥ 0$:</p><ul><li>(Normal increments) $Z(t) − Z(s) ∼ N(0,t − s)$.</li><li>(Independence of increments) $Z(t) − Z(s)$ and $Z(u)$ are independent, for $u ≤ s &lt; t$.</li><li>(Continuity of the path) $Z(t)$ is a continuous function of t.</li><li>$W(0) = 0$.</li><li>$E(W(t)) = 0, E(W^2(t)) = t$ for each time $t ≥ 0$.</li></ul><h3 id="Stochastic-differential-equation-SDE"><a href="#Stochastic-differential-equation-SDE" class="headerlink" title="Stochastic differential equation (SDE)"></a>Stochastic differential equation (SDE)</h3><ul><li>is a differential equation in which one or more of the terms is a stochastic process, resulting in <u>a solution which is also a stochastic process</u>.</li><li>SDEs contain a variable which represents random white noise calculated as the derivative of Brownian motion or the Wiener process.</li><li>A typical SDE: $$dX = a(t, X) dt + b(t, X) dW_t$$</li><li>The solution to SDE could be: Euler-Maruyama Method, Milstein Method, Runge-Kutta Method and Taylor Method</li></ul><p>Reference:<br><a href="http://math.gmu.edu/~tsauer/pre/sde.pdf" target="_blank" rel="noopener">http://math.gmu.edu/~tsauer/pre/sde.pdf</a><br><a href="http://ft-sipil.unila.ac.id/dbooks/AN%20INTRODUCTION%20TO%20STOCHASTIC%20DIFFERENTIAL%20EQUATIONS%20VERSION%201.2.pdf" target="_blank" rel="noopener">http://ft-sipil.unila.ac.id/dbooks/AN%20INTRODUCTION%20TO%20STOCHASTIC%20DIFFERENTIAL%20EQUATIONS%20VERSION%201.2.pdf</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;Wiener-process&quot;&gt;&lt;a href=&quot;#Wiener-process&quot; class=&quot;headerlink&quot; title=&quot;Wiener process&quot;&gt;&lt;/a&gt;Wiener process&lt;/h3&gt;&lt;p&gt;The Wiener process&lt;/p&gt;
      
    
    </summary>
    
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
      <category term="Stochastic" scheme="http://tracyxinwang.site/blog/tags/Stochastic/"/>
    
  </entry>
  
  <entry>
    <title>EM, MAP</title>
    <link href="http://tracyxinwang.site/blog/2019/02/23/EM/"/>
    <id>http://tracyxinwang.site/blog/2019/02/23/EM/</id>
    <published>2019-02-23T07:49:13.000Z</published>
    <updated>2019-02-24T23:16:16.000Z</updated>
    
    <content type="html"><![CDATA[<ul><li>Probabilistic models, such as hidden Markov models or Bayesian networks, are commonly used to model biological data. </li><li>But models are models, which means we need to first choose the model type, and then estimate the parameters based on the observations.</li><li>The expectation maximization algorithm is a natural generalization of maximum likelihood estimation to the incomplete data case. </li><li>other numerical optimization techniques, such as gradient descent or Newton-Raphson, could be used instead of expectation maximization; in practice, however, expectation maximization has the advantage of being simple, robust and easy to implement.</li></ul><p>The expectation maximization algorithm enables parameter estimation in probabilistic models with incomplete data.</p><p>Reference:<br><a href="http://ai.stanford.edu/~chuongdo/papers/em_tutorial.pdf" target="_blank" rel="noopener">http://ai.stanford.edu/~chuongdo/papers/em_tutorial.pdf</a><br><a href="https://math.stackexchange.com/questions/25111/how-does-expectation-maximization-work" target="_blank" rel="noopener">https://math.stackexchange.com/questions/25111/how-does-expectation-maximization-work</a><br><a href="https://stats.stackexchange.com/questions/235070/relation-between-map-em-and-max-likelihood" target="_blank" rel="noopener">https://stats.stackexchange.com/questions/235070/relation-between-map-em-and-max-likelihood</a><br><a href="https://www.cs.utah.edu/~piyush/teaching/EM_algorithm.pdf" target="_blank" rel="noopener">https://www.cs.utah.edu/~piyush/teaching/EM_algorithm.pdf</a><br><a href="https://people.eecs.berkeley.edu/~pabbeel/cs287-fa13/slides/Likelihood_EM_HMM_Kalman.pdf" target="_blank" rel="noopener">https://people.eecs.berkeley.edu/~pabbeel/cs287-fa13/slides/Likelihood_EM_HMM_Kalman.pdf</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ul&gt;
&lt;li&gt;Probabilistic models, such as hidden Markov models or Bayesian networks, are commonly used to model biological data. &lt;/li&gt;
&lt;li&gt;But 
      
    
    </summary>
    
    
      <category term="Algorithm" scheme="http://tracyxinwang.site/blog/tags/Algorithm/"/>
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
  </entry>
  
  <entry>
    <title>Numerical differentiation - ways to find derivative</title>
    <link href="http://tracyxinwang.site/blog/2019/02/19/SolDerivative/"/>
    <id>http://tracyxinwang.site/blog/2019/02/19/SolDerivative/</id>
    <published>2019-02-19T01:22:33.000Z</published>
    <updated>2019-02-18T22:22:30.000Z</updated>
    
    <content type="html"><![CDATA[<p><br></p><blockquote><p>In numerical analysis, numerical differentiation describes algorithms for estimating the derivative of a mathematical function using values of the function and perhaps other knowledge about the function.</p></blockquote><p>There are mainly two ways to calculate the derivative of a function. (And useful when finding Jacobian matrix)</p><h3 id="Finite-difference-formulas-Newton’s-difference-quotient"><a href="#Finite-difference-formulas-Newton’s-difference-quotient" class="headerlink" title="Finite difference formulas (Newton’s difference quotient)"></a>Finite difference formulas (Newton’s difference quotient)</h3><p>This way is the same as what we learn in high school course. That is to compute the slope of a nearby secant line with a tiny tiny increament h:$$\dfrac {f(x+h)-f(x)}{h}$$<br>And in implementation, we just need to make sure that the h is very very small.</p><p>The above formula is also called the Newton’s forward approximation when $h &gt; 0$. Since it uses the point that are forward to the current point. If $h&lt;0$, then it is called Newton’s backward approximation.<br>If we don’t use the current point and chooce one tiny step both forward and backward to calculate the derivative: $\dfrac {f(x+h)-f(x-h)}{2h}$, then it is called central approximation. And as the error item in this way is proportional to $h^2$, for small values of h, the approximation is more accurate than one-sided(forward/backward) estimation.</p><h3 id="Complex-step-approximation"><a href="#Complex-step-approximation" class="headerlink" title="Complex-step approximation"></a>Complex-step approximation</h3><p>The classical finite difference approximations for numerical differentiation are ill-conditioned. However, if f is a holomorphic function, real-valued on the real line, which can be evaluated at points in the complex plane near x then there are stable methods. The first derivative can be calculated by the complex-step derivative formula as follows: $$f’(x) = \frac{Im(f(x+ih))}{h}$$<br>where $i$ is the imaginary unit, h is the small step size.</p><p>The derivation can be as follows:</p><ul><li>Let $f(x)$ be a function, let $x_0$ be a point on the real axis, and let $h$ be a real parameter. </li><li>Expand $f(x)$ in a Taylor series off the real axis: $$f(x_0+ih) = f(x_0) = ihf’(x_0) - h^2f’’(x_0)/2! - ih^3F^{(3)}/3! + \cdots$$</li><li>Take the imaginary part of both sides and divide by h: $$f’(x_0) = \frac {Im(f(x_0+ih))}{h} + O(h^2)$$</li><li>Therefore, the above gives an approximation to the value of the derivative, $f′(x_0)$, and that is accurate to order $O(h^2)$.</li></ul><p>$h = 1.0E-20$ usually works very well in nearly all cases, and results in derivatives no less accurate than the original algorithm.</p><p>Note that the above formula is only valid for calculating a first-order derivative.</p><h3 id="Differential-quadrature"><a href="#Differential-quadrature" class="headerlink" title="Differential quadrature"></a>Differential quadrature</h3><blockquote><p>Differential quadrature is the approximation of derivatives by using weighted sums of function values. The name is in analogy with quadrature meaning Numerical integration where weighted sums are used in methods such as Simpson’s method or the Trapezium rule. There are various methods for determining the weight coefficients. Differential quadrature is used to solve partial differential equations.</p></blockquote><p><br></p><p>Reference:<br><a href="https://wiki2.org/en/Numerical_differentiation" target="_blank" rel="noopener">https://wiki2.org/en/Numerical_differentiation</a><br><a href="https://blogs.mathworks.com/cleve/2013/10/14/complex-step-differentiation/" target="_blank" rel="noopener">https://blogs.mathworks.com/cleve/2013/10/14/complex-step-differentiation/</a><br><a href="http://mdolab.engin.umich.edu/content/guide-complex-step-derivative-approximation-0" target="_blank" rel="noopener">http://mdolab.engin.umich.edu/content/guide-complex-step-derivative-approximation-0</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In numerical analysis, numerical differentiation describes algorithms for estimating the derivative of a mathema
      
    
    </summary>
    
    
      <category term="Algorithm" scheme="http://tracyxinwang.site/blog/tags/Algorithm/"/>
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
  </entry>
  
  <entry>
    <title>读《浅谈人工智能》有感</title>
    <link href="http://tracyxinwang.site/blog/2019/02/16/UnifyAI/"/>
    <id>http://tracyxinwang.site/blog/2019/02/16/UnifyAI/</id>
    <published>2019-02-16T06:51:13.000Z</published>
    <updated>2019-02-18T06:08:38.567Z</updated>
    
    <content type="html"><![CDATA[<p>之前看一个师兄写的文章里面，提到推荐做AI的人看下朱松纯教授写的那篇《人工智能的现状、任务、构架和统一》。我虽然不做纯AI，但我一直在想找一个人脑与AI的结合点，非常希望能建立起自己的一个认知框架。隔了大半年了，终于有时间找来读一读。下面大概介绍一下朱教授的观点和我自己的思考。</p><p>朱教授把人工智能分为六大板块：</p><ul><li>计算机视觉： 包括模式识别，图像处理</li><li>自然语言理解与交流： 包括语音识别，对话</li><li>认知与推理： 包括物理和社会常识</li><li>机器人学： 机械，控制，设计，运动规划和任务规划等</li><li>博弈与伦理： multi-agent 的交互，对抗与合作等</li><li>机器学习： 各种统计的建模，分析工具</li></ul><p>在我读PhD的初期，其实是有机会做真的图像处理，做deep learning那一套东西的，可我大致研究了一下，我觉得太火了，不管是本来就是这个领域的，还是其他领域的，都在朝这个方向转，都在发相关的paper。这让我当时就想起了一个词，大跃进。虽然我理解得也不深刻，但我觉得其实还远不到人们想的那样，DL可以实现真正的人工智能。我当时想，别人都在做的，那我不做，既然有这样一个机会让我搞一下真的人脑，那我就来看看，到底真的人脑是什么样子的？然后一直搞到现在，我发现这个坑是真的多，神经科学这个领域从我开始踏入，到现在，一直没有什么质的进展。但是AI的大潮，已经从CV，转到NLP了。上个月参加谷歌组织的机器学习冬令营，我发现做视觉的相对来说少一些，但是做NLP的，一大把。这是一个很有趣的现象，因为CV那块，像朱教授说的那样，刷榜刷得差不多了，在图像识别本身来说，已经没有什么可以进步的了，除非和其他的领域结合。于是人们又自然而然转到NLP上面去。下一个浪潮是哪里呢？我猜是机器人学，因为前两者都要结合啊，需要一个载体或者说agent来帮助表明这东西有多牛逼啊。而且机器人本身，也是需要加上前两者，才能实现智能这一特性的。可是这还是缺思考，缺认知这一块，所以认知和推理，我觉得是下下个浪潮，也是我现在想研究的方向。</p><p>这其实有点像一个统一的过程，分而治之，再合成一个完整的学科。从朱教授的介绍来讲，人工智能发展的60年有两个阶段：</p><ol><li>前30年以数理逻辑的表达和推理为主： 这一期的领军人物懂很多认知科学的东西，有很强的全局观念，但是没有落地，所以不了了之。</li><li>后30年以概率统计的建模、学习和计算为主： 几大学科独立发展，基于概率建模和随机计算，AI再度繁荣</li></ol><p>后30年的代表人物中，朱教授有提到Judea Pearl这个人，11年的图灵奖获得者。巧的是我当时也追过这个人的paper，因为他的因果模型，我觉得是很有希望用在大脑建模过程当中的，找来他的那本著作看，无奈数学推导对我太难，而后放弃，但这个理论，还依然在我的to do list里面。</p><p>那这几大学科怎么统一到AI上面呢？框架是什么？<br>教授给出的方向是：小数据，大任务范式</p><p>他认为智能系统的根源可以追溯到两个基本前提条件：</p><ol><li>物理环境客观的现实与因果链条：这个我理解的是input, 也就是所见所观所得，这些是外部条件来的</li><li>智能物种与生俱来的任务与价值链条：这个我理解的是 inner sense。也就是所思所做，即文章提到的价值观和决策函数。<br>这有点像一个控制里面的系统，有自己内部的构造和决策，加上外界的input，然后推导出output. 而其实我们想达到的AI，也就是一个智能系统罢了。</li></ol><p>但是这个系统不是一层不变的，就像我们的人脑，每时每刻的状态其实都是不一样的。那为什么会变呢，也就是为什么会有学习这个过程呢？</p><ol><li>外来的数据：外部世界通过各种感知信号，传递到人脑，塑造模型。这些数据来源于观察和实践。观察的数据用于学习各种统计模型，即相关性。实践的数据用于学习因果模型，即将行为和结果联系在一起。</li><li>内在的任务：即由内在的价值函数驱动行为，以达到某种目的。</li></ol><p>这个学习的缘由其实和上面的前提条件很像，都是一个是input的东西，一个是inner的东西。不同的在于，前面那个是初始状态，是静止的，后面那个是学习的过程，是动态的，且一直都在变的。</p><p>那怎么根据这些前提条件和驱动因子实现小数据，大任务范式这个统一框架呢？朱教授提到了暗物质，这个暗物质不是物理学中的那个暗物质。我理解的是，它其实代表了一种 common sense 的建立和因果的推理。你看到的，不仅仅是你看到的，还有那些物体背后的联系和因果关系。而这些，就是那些在暗处的东西，那些能促使小数据完成大任务的因子。那这需要什么学科的知识呢？答案是认知，mind。这就涉及到心理学和神经科学相关的东西了。</p><p>在介绍到认知的时候，朱教授引入了博弈伦理。其中提到了两大类的学习方法，我觉得是很有必要单独拿出来看看的，因为这两个学习的方法，其实也是我们真的学习的过程：</p><ol><li><strong>归纳学习(Inductive learning)</strong>: 通过观察大量数据样本来学习，这些样本就是对某个时期、某个地域、某个人群达成的准平衡态的观察。归纳学习的结果就是一个时空因果的概率模型。</li><li><strong>演绎学习(Deductive learning)</strong>: 这个东西文献中很少，也就是从价值函数（还有物理因果）出发，直接推导出这些准平衡态。<br>这就像我们人类早期的学习，都是归纳学习来的，通过观察别人，学习别人，来逐步形成自己的人生观价值观世界观。而后成长到一定年纪的时候，就是演绎学习了，没有见过的东西，通过分析和推理，依然可以得出正确的结论。<br>只可惜我们很多人，一辈子都没有到演绎学习的阶段，从来只是从别人那里听来读来，并没有形成自己的一套方法论。</li></ol><p>我还想提的一点是，归纳学习有点像现在的强化学习，用很少的样本，就是不断去尝试啊，然后得出结果，有一套因果推导在里面。这也是为什么我很关注强化学习的另一个原因。</p><p>之后朱教授讲到学习的极限，停机问题，说实话我对这个方向不是很了解，就不过多分析了。</p><p>最后文章的总结题目是：智能科学-牛顿与达尔文理论体系的统一。提到物理学的责任是寻找支配自然各种现象的统一的力。而智能科学的研究对象是什么呢？是把物理学排除在外的生物意志给拿进来，研究一个物理与生物混合的复杂系统。这里朱教授提到了力的概念，提到了人与人之间，人与物，物与物之间，那些联系其实可用看成一种力，因为这些力是可以真实用数学表达式表达出来的，而且在物理学上是已经很统一很规范了的。那我们要做的其实就是把生物这块的东西，跟物理结合起来。</p><p>在我以前最开始思考AI与人脑的结合的时候，并没有从物理这个方向去想，一是完全没有意识，二是觉得没有什么联系。对物理的理解并不深，所以我对这个观点的看法不加评论。但是有没有一种大统一，是可以独立于物理啊这些理论，在智能的内部（包括人工智能和真人智能），有一个统一的理论，来解释所有的因果和相关呢？我觉得是有的，这也是我一直想找到的一个统一的理论来链接AI和human brain.</p><p>整篇文章让我特别感动的是介绍到David Mumford的时候，说他念念不忘人工智能，从头开始学统计概率，直奔关键体系，而不是拿着锤子找钉子。这恰恰是我目前想追求的，但现实里我却智能拿着锤子找钉子，如果条件允许，我想我还是会钻到统计概率那边，再去学习的，因为我目前的知识体系，还缺少这一块，而这一块又是我认为很重要的。当然，再学个物理也是极好的。</p><p>All in all, 现在的Artificial intelligence 只能算是 engineering，而不是一门真正的science，等真正有人站出来统一这个学科了，或许才能真正称之为 Science of Intelligence。 我希望自己能在有生之年，能够成为这个science of intelligence 建立的推动者。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;之前看一个师兄写的文章里面，提到推荐做AI的人看下朱松纯教授写的那篇《人工智能的现状、任务、构架和统一》。我虽然不做纯AI，但我一直在想找一个人脑与AI的结合点，非常希望能建立起自己的一个认知框架。隔了大半年了，终于有时间找来读一读。下面大概介绍一下朱教授的观点和我自己的思
      
    
    </summary>
    
    
      <category term="杂文" scheme="http://tracyxinwang.site/blog/tags/%E6%9D%82%E6%96%87/"/>
    
      <category term="碎碎念" scheme="http://tracyxinwang.site/blog/tags/%E7%A2%8E%E7%A2%8E%E5%BF%B5/"/>
    
  </entry>
  
  <entry>
    <title>Gauss-Newton method to solve Nonlinear Least Square Problem</title>
    <link href="http://tracyxinwang.site/blog/2019/02/08/Nonlinear/"/>
    <id>http://tracyxinwang.site/blog/2019/02/08/Nonlinear/</id>
    <published>2019-02-08T06:28:13.000Z</published>
    <updated>2019-02-18T06:26:12.837Z</updated>
    
    <content type="html"><![CDATA[<p><br></p><h3 id="先验知识"><a href="#先验知识" class="headerlink" title="先验知识"></a>先验知识</h3><ul><li><strong>Jacobian</strong>:<ul><li>is the matrix of all first-order partial derivatives of a <strong>vector-valued</strong> function.</li><li>that is to say, the function $f(x)$ maps $R^n \to R^m$</li><li>the Jacobian of $f(x)$ is </li><li>$$\mathbf {J} = {\begin{bmatrix}{\frac {\partial \mathbf {f} }{\partial x_{1}}} &amp; \cdots &amp; {\frac {\partial \mathbf {f} }{\partial x_{n}}} \end{bmatrix}} = {\begin{bmatrix} {\dfrac {\partial f_{1}}{\partial x_{1}}} &amp; \cdots &amp; {\frac {\partial f_{1}}{\partial x_{n}}} \\ \vdots &amp; \ddots &amp; \vdots \\ {\dfrac {\partial f_{m}}{\partial x_{1}}} &amp; \cdots  &amp; {\dfrac {\partial f_{m}}{\partial x_{n}}}\end{bmatrix}}$$</li></ul></li><li><strong>Hessian</strong>:<ul><li>a square matrix of second-order partial derivatives of a <strong>scalar-valued</strong> function, or scalar field.</li><li>that is to say, the function $f(x)$ maps $R^n \to R$</li><li>the Hessian of $f(x)$ is </li><li>$$\mathbf {H} ={\begin{bmatrix}{\dfrac {\partial ^{2}f}{\partial x_{1}^{2}}}&amp;{\dfrac {\partial ^{2}f}{\partial x_{1}\,\partial x_{2}}} &amp; \cdots &amp; {\dfrac {\partial ^{2}f}{\partial x_{1}\,\partial x_{n}}} \\ {\dfrac {\partial ^{2}f}{\partial x_{2}\,\partial x_{1}}}&amp;{\dfrac {\partial ^{2}f}{\partial x_{2}^{2}}}&amp;\cdots &amp;{\dfrac {\partial ^{2}f}{\partial x_{2}\,\partial x_{n}}}\\ \vdots &amp;\vdots &amp;\ddots &amp;\vdots \\ {\dfrac {\partial ^{2}f}{\partial x_{n}\,\partial x_{1}}}&amp;{\dfrac {\partial ^{2}f}{\partial x_{n}\,\partial x_{2}}}&amp;\cdots &amp;{\dfrac {\partial ^{2}f}{\partial x_{n}^{2}}}\end{bmatrix}} $$</li></ul></li><li>Newton’s method in optimization<ul><li>generally, Newton’s method is an iterative method to find the roots of a differentiable function: $f(x)=0$</li><li>在优化当中，找极值时，我们一般会用过求导的方式来找该函数导数为零的点，因为这个点就意味着极值。</li><li>所以Newton’s method在优化运用中，is to find the root of th ederivative of function f: $f’(x)=0$</li><li>In one-dimensional problem, we hope to find the min or max to satisfy: $f’(x^*)=0$</li><li>将f(x)泰勒展开：$$f(x) = f(x_n+\Delta x) \approx f(x_n) + f’(x_n)\Delta x + \frac12 f’’(x_n)\Delta x^2$$</li><li>我们希望在n次迭代后，能找到那个 $x^*$, 此时这个点满足 $f’(x)$, 即：$$f’(x)=0 \to f’(x_n+\Delta x) = 0$$ $$\frac {\partial f(x_n+\Delta x)}{\partial \Delta x} = 0$$ $$\frac {\partial (f(x_n)+f’(x_n)\Delta x + \frac 12 f’’(x_n)\Delta x^2)}{\partial \Delta x} = 0$$ $$f’(x_n) + \frac 12 f’’(x_n)\Delta x^2 =0 $$ $$\therefore \Delta x = - \frac {f’(x_n)}{f’’(x_n)}$$</li><li>所以在Newton’s method中, 寻找极值的方向就是$\Delta x = - \frac {f’(x_n)}{f’’(x_n)}$</li><li>在高阶当中，$\Delta x = - [Hf(x_n)]^{-1} \Delta {f(x_n)}$</li></ul></li></ul><h3 id="Gauss-Newton-method"><a href="#Gauss-Newton-method" class="headerlink" title="Gauss-Newton method"></a>Gauss-Newton method</h3><ul><li>the problem is as follows:$$min_{x\in R^n} f(x) = \frac 12 \sum_{i=1}^m r_i(x)^2$$<ul><li>where $m \ge n$</li><li>n is thge number of parameters</li><li>m is the number of observations</li><li>r(x) is the vector of residuals $r(x) = {\begin{bmatrix} r_1(x) \\ r_2(x) \\ \vdots \\ r_m(x) \end{bmatrix}}$</li></ul></li><li>Note that there could be 3 spaces when considering such probelm:<ul><li>the parameter space</li><li>the observation space</li><li>the model space </li></ul></li><li>the gradient of f(x) is: $$\Delta f(x) = \Delta r(x) r(x) = J(x)^Tr(x)$$<ul><li>where $J(x) = \Delta r(x)^T$, the Jacobian of r(x). (Note only r(x) can have Jacobian but not f(x))</li><li>推导过程直接对原式求导即可</li></ul></li><li>the Hessian of f(x) is: $$\Delta^2 f(x) = \Delta r(x) \Delta r(x)^T + \sum_{i=1}^m r_i(x) \Delta^2 r_i(x)$$ $$= J(x)^TJ(x) + Q(x)$$\</li><li>In optimization, we hope that the residual can approximate 0, if so, $r(x)=0$, and $Q(x) = 0$</li><li><strong>A method that uses the approximation Q(x)=0 is called Gauss-Newton method</strong></li><li>If the search direction using Newton equation: $$\Delta^2 f(x) p^N = - \Delta f(x)$$<ul><li>代入以上的hessian式子： $$(J^T(x)J(x) + Q(x))P^N = - \Delta f(x)$$</li><li>if Q(x) 接近0，$$J^T(x)J(x)P^{GN} = - \Delta f(x) = -J(x)^Tr(x)$$</li><li>if J(x) is full rank, we can have a unique solution; but if not, the problem gets under-deterined ot over-determined.</li></ul></li></ul><h4 id="Pros-amd-Cons"><a href="#Pros-amd-Cons" class="headerlink" title="Pros amd Cons"></a>Pros amd Cons</h4><ul><li>If $r(x^∗) = 0$, then the approximation $Q(x) ≈ 0$ is good and the Gauss-Newton method will behave like the Newton method close to the solution, i.e. converge quadratically if $J(x^∗)$ has full rank. </li><li>The advantage over the Newton method is that we do not need to calculate the second-order derivatives $∇^2 r_i(x)$.</li><li>However, if any residual component $r_i(x^∗)$ and/or the corresponding curvature $∇^2 r_i(x)$ is large, the approximation $Q(x) ≈ 0$ will be poor, and the Gauss-Newton method will converge slower than the Newton method.</li><li>For such problems, the Gauss-Newton method may not even be locally convergent, i.e. without a global strategy such as the line search, it wouldn’t converge no matter how close to the solution we start.</li></ul><p><br></p><p>Reference:<br><a href="https://www8.cs.umu.se/kurser/5DA001/HT07/lectures/lsq-handouts.pdf" target="_blank" rel="noopener">https://www8.cs.umu.se/kurser/5DA001/HT07/lectures/lsq-handouts.pdf</a><br><a href="http://fourier.eng.hmc.edu/e176/lectures/NM/" target="_blank" rel="noopener">http://fourier.eng.hmc.edu/e176/lectures/NM/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3 id=&quot;先验知识&quot;&gt;&lt;a href=&quot;#先验知识&quot; class=&quot;headerlink&quot; title=&quot;先验知识&quot;&gt;&lt;/a&gt;先验知识&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Jacobian&lt;/strong&gt;:&lt;ul&gt;
&lt;li&gt;is the ma
      
    
    </summary>
    
    
      <category term="Algorithm" scheme="http://tracyxinwang.site/blog/tags/Algorithm/"/>
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
  </entry>
  
  <entry>
    <title>Command line II</title>
    <link href="http://tracyxinwang.site/blog/2019/01/15/Linux/"/>
    <id>http://tracyxinwang.site/blog/2019/01/15/Linux/</id>
    <published>2019-01-15T11:55:13.000Z</published>
    <updated>2019-02-23T04:46:54.000Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># create a 线程</span></span><br><span class="line">screen -S name</span><br><span class="line"></span><br><span class="line"><span class="comment"># detach the screen</span></span><br><span class="line">ctrl+a+d</span><br><span class="line"></span><br><span class="line"><span class="comment"># recover the screen</span></span><br><span class="line">screen -r </span><br><span class="line"></span><br><span class="line"><span class="comment"># see the list of the screen </span></span><br><span class="line">screen -ls</span><br><span class="line"></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">nvidia-smi</span><br></pre></td></tr></table></figure><p>f = open(“mini_classes.txt”,”r”)</p><h1 id="And-for-reading-use"><a href="#And-for-reading-use" class="headerlink" title="And for reading use"></a>And for reading use</h1><p>classes = f.readlines()<br>f.close()<br>classes = [c.replace(‘\n’,’’).replace(‘ ‘,’_’) for c in classes]</p><p>ctl+shift+\: terminate python run</p><p>zip -r data.zip data/</p><p>Reference:<br><a href="https://www.tecmint.com/screen-command-examples-to-manage-linux-terminals/" target="_blank" rel="noopener">https://www.tecmint.com/screen-command-examples-to-manage-linux-terminals/</a><br><a href="https://linuxize.com/post/how-to-use-linux-screen/" target="_blank" rel="noopener">https://linuxize.com/post/how-to-use-linux-screen/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=
      
    
    </summary>
    
    
      <category term="Linux" scheme="http://tracyxinwang.site/blog/tags/Linux/"/>
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
  </entry>
  
  <entry>
    <title>MIT6006 Lec21 DP III &amp; IV</title>
    <link href="http://tracyxinwang.site/blog/2019/01/11/MIT6006-Lec21/"/>
    <id>http://tracyxinwang.site/blog/2019/01/11/MIT6006-Lec21/</id>
    <published>2019-01-11T04:47:13.000Z</published>
    <updated>2019-02-23T04:47:56.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Parenthesization"><a href="#Parenthesization" class="headerlink" title="Parenthesization"></a>Parenthesization</h3><p>Optimal evaluation of associative expression $A[0] · A[1] · · · A[n−1]$ — e.g., multiplying rectangular matrices</p><ol start="2"><li>Guessing = outermost multiplication ${…(k-1)}{…(k)}$<ul><li>choices = O(n)</li></ul></li><li>subproblem = cost of substring A[i:j]<ul><li>subproblem = $\Theta (n^2)$</li></ul></li><li>recurrence:<ul><li>DP[i,j] = min(DP[i,k]+DP[k,j]+cost of multiplying (A[i]…A[k-1]) b (A[k]…A[j-1]) for k in range(i+1,j))</li><li>DP[i,i+1] = 0: cost per subproblem = O(j-i) = O(n)</li></ul></li><li>topological order: increasing substring size. Total time = $O(n^3)$</li><li>original problem = DP[0,n]</li></ol><h3 id="Edit-Distance"><a href="#Edit-Distance" class="headerlink" title="Edit Distance"></a>Edit Distance</h3><h3 id="Snapsack"><a href="#Snapsack" class="headerlink" title="Snapsack"></a>Snapsack</h3><p>### </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;Parenthesization&quot;&gt;&lt;a href=&quot;#Parenthesization&quot; class=&quot;headerlink&quot; title=&quot;Parenthesization&quot;&gt;&lt;/a&gt;Parenthesization&lt;/h3&gt;&lt;p&gt;Optimal evalua
      
    
    </summary>
    
    
      <category term="Algorithm" scheme="http://tracyxinwang.site/blog/tags/Algorithm/"/>
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
  </entry>
  
  <entry>
    <title>Deep learning in Matlab II</title>
    <link href="http://tracyxinwang.site/blog/2019/01/07/Matlab-DL2/"/>
    <id>http://tracyxinwang.site/blog/2019/01/07/Matlab-DL2/</id>
    <published>2019-01-07T07:40:51.000Z</published>
    <updated>2019-04-09T05:14:32.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="neural-network-theory"><a href="#neural-network-theory" class="headerlink" title="neural network theory"></a>neural network theory</h2><h3 id="Interpreting-Network-Behavior"><a href="#Interpreting-Network-Behavior" class="headerlink" title="Interpreting Network Behavior"></a>Interpreting Network Behavior</h3><p><strong>Extracting and Visualizing Activations</strong>:</p><ul><li>use the <code>activations</code> function to extract features from an input image: <ul><li>it accepts three inputs: the network, the input image, and the layer to extract features from.</li><li><code>features = activations(net,img,layerName)</code></li></ul></li><li>Each convolution layer consists of many 2-D arrays called channels. </li><li>Most CNNs learn to detect features like color and edges in the first convolution layer. In deeper layers, the network learns more complicated features.</li><li>use the function <code>mat2gray</code> to normalize the activations</li><li>use <code>montage</code> to show the images side by side</li></ul><p><strong>Representing Signal Data as Images</strong></p><ul><li>CNN use the images as input, which means every 2-D array can be input to CNN. Therefore, we can represent the signals in to 2-D array for use of CNN</li><li>There are two ways to convert 1-D signal to images: use <code>spectrogram</code> or a continuous wavelet transform using <code>cwt</code>. </li></ul><p><strong>Feature Extraction for Machine Learning</strong>:</p><ul><li>It is difficult to perform deep learning on a computer without a GPU because of the long training time. </li><li>An alternative is to use pretrained networks for feature extraction. Then you can use traditional machine learning methods to classify these features. </li><li>CNNs learn to extract useful features while learning how to classify image data. As you’ve seen, <u>the early layers read an input image and extract features. Then, fully connected layers use these features to classify the image.</u></li><li>With deep learning, you can use the <code>activations</code> function to extract features. These features can be used as the predictor variables for machine learning.</li><li>We can set the <code>OutputAs</code> option to store the features from activation as rows for the machine learning model: <code>testFeatures = activations(net,testImgs,&#39;fc7&#39;,&#39;OutputAs&#39;,&#39;rows&#39;)</code></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># extract the features from a pretrained net</span></span><br><span class="line">trainingFeatures = activations(net,trainImgs,<span class="string">'fc7'</span>,<span class="string">'OutputAs'</span>,<span class="string">'rows'</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment"># train the maching leanring classifier e.g. naive bayes</span></span><br><span class="line">classifier = fitcnb(trainingFeatures,trainImgs.Labels)</span><br><span class="line"></span><br><span class="line"><span class="comment">#W extract the features for test data and use the trained classifer above to predict</span></span><br><span class="line">testFeatures = activations(net,testImgs,<span class="string">'fc7'</span>,<span class="string">'OutputAs'</span>,<span class="string">'rows'</span>);</span><br><span class="line">predictedLabels = predict(classifier,testFeatures)</span><br><span class="line"></span><br><span class="line"><span class="comment"># compute accuracy and plot the confusion matrix</span></span><br><span class="line">accuracy = nnz(predictedLabels==testImgs.Labels)/numel(predictedLabels)</span><br><span class="line">confusionchart(testImgs.Labels, predictedLabels)</span><br></pre></td></tr></table></figure><h3 id="Create-Networks"><a href="#Create-Networks" class="headerlink" title="Create Networks"></a>Create Networks</h3><p>Many pretrained networks need the input to be 3-D data and some restriction for the size of the images. If the data you want to train doesn’t satisfy these requirment (like the have more than 3 dimensions), we then need to build our own model.</p><p><strong>Create Network Architectures</strong></p><ul><li>The first layer of any convolutional neural network is an image input layer. Function <code>imageInputLayer(inputSize)</code> can do this. The input size is a three-element vector corresponding to the height, width, and number of channels of that image: <code>inLayer = imageInputLayer([28 28 3])</code></li><li>Convolution layers learn features in the input image by applying different filters to the image. To create a convolution layer, you need to specify the filter size and the number of filters: <code>convolution2dLayer([h w],n)</code>, <code>convLayer = convolution2dLayer([5 5],20)</code></li><li><strong>Convolution layers</strong> are generally followed by rectified linear unit (ReLU) and max pooling layers.</li><li>A <strong>ReLU</strong> layer sets all negative values to zero: <code>reluLayer()</code>. The function does not require any inputs.</li><li><strong>Max pooling layers</strong> perform down-sampling by “pooling” rectangular regions together and computing the maximum of each region. Use the pool size as input: <code>maxPooling2dLayer([h w])</code></li><li>The last three layers of a convolutional neural network are<ul><li><strong>fullyConnectedLayer</strong>: it requires the output size as input. This is the number of classes that the network can predict.</li><li><strong>softmaxLayer</strong>: does not require any inputs.</li><li><strong>classificationLayer</strong>: does not require any inputs.</li></ul></li><li>To train a network, we need an array of your entire network architecture. The last step is to stack all the layers you have created into a single array.</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># To create an architecture that can be used to classify 28-by-28 color images into two classes.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create input layer that expects RGB images sized 28-by-28.</span></span><br><span class="line">inLayer = imageInputLayer([28 28 3])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create convolution layer with 20 filters sized 5-by-5.</span></span><br><span class="line">convLayer = convolution2dLayer([5 5],20)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create middle layers with a ReLU layer and a max pooling layer with a pool size of 2-by-2. </span></span><br><span class="line">midLayers = [reluLayer(); maxPooling2dLayer([2 2])]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create output layers with a fully connected layer for two classes and a softmax layer and a classification layer.</span></span><br><span class="line">outLayers = [fullyConnectedLayer(2); softmaxLayer(); classificationLayer()]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Combine layers</span></span><br><span class="line">layers = [inLayer; convLayer; midLayers; outLayers]</span><br><span class="line"></span><br><span class="line"><span class="comment"># set the training options and train</span></span><br><span class="line">options = trainingOptions(<span class="string">'sgdm'</span>,<span class="string">'MaxEpochs'</span>,5,<span class="string">'InitialLearnRate'</span>,0.0001)</span><br><span class="line">net = trainNetwork(XTrain,YTrain,layers,options);</span><br><span class="line"></span><br><span class="line"><span class="comment"># Prediction</span></span><br><span class="line">testpreds = classify(net,XTest)</span><br></pre></td></tr></table></figure><p><strong>Understanding Neural Networks</strong></p><ul><li>Each layer in the network performs some operation on its inputs and outputs a new value.</li><li>The first layer is an image input layer. This layer defines the input size of the network and normalizes the input images. By default, an image input layer subtracts the mean image of the training data set. This centers the images around zero.</li><li>2-D convolution layers apply sliding filters to the input image. Convolution layers are a key part of the CNN architecture. They rely on the spatial structure of the input image.</li><li>Convolution layers are usually followed by a nonlinear activation layer such as a rectified linear unit (ReLU). A ReLU layer performs a threshold operation to each element of the input. Any value less than zero is set to zero.</li><li>A maximum pooling layer performs down-sampling by dividing the input into rectangular pooling regions and computing the maximum of each region. Pooling reduces the network complexity and creates a more general network.</li><li>Features passing through the network are stored in a collection of matrices until they reach the fully connected layer. At the fully connected layer, the input is “flattened” (which means to tansform the matrix to a vector) so that it can be mapped to the output classes. This layer is a classical neural network.</li><li>The output size for this layer is the number of classes for your classification problem. For example, if you were classifying cats and dogs, the output size would be two.</li><li>The softmax layer converts the values for each output class into normalized scores using a normalized exponential function. You can interpret each value as the probability that the input image belongs to each class.</li><li>The softmax layer converts the values for each output class into normalized scores using a normalized exponential function. You can interpret each value as the probability that the input image belongs to each class.</li><li>The classification output layer returns the name of the most likely class.</li></ul><p><strong>Convolutional Layers</strong></p><ul><li>Convolution layers in CNNs perform convolution using learned filters. </li><li>A matrix called a kernel is used to filter the image. </li><li>We can use kernel with the <code>conv2</code> function to apply a filter to an image: <code>filteredim = conv2(kernel,im)</code></li><li>Using empty brackets as the second input in <code>imshow</code> will scale the display based on the minimum and maximum values present in the image: <code>imshow(im,[])</code></li><li>Or you can also use the <code>imfilter</code> function to apply the same kernels to the entire RGB image, which means the 3-D data. <code>conv2</code> can only apply to a 2-D image.</li></ul><p><strong>Summary</strong><br><a href="https://au.mathworks.com/help/deeplearning/ug/list-of-deep-learning-layers.html" target="_blank" rel="noopener">List of layer functions</a></p><h3 id="Train-Networks"><a href="#Train-Networks" class="headerlink" title="Train Networks"></a>Train Networks</h3><p><strong>Understand the network training</strong>:</p><ul><li>Mini-Batch</li><li>Learning rate</li><li>Learning algorithm</li></ul><p><strong>Monitor Training Progress</strong></p><ul><li>can use the <code>Plots</code> option to monitor network training: <code>options = trainingOptions(&#39;sgdm&#39;,&#39;MaxEpochs&#39;,2,&#39;InitialLearnRate&#39;,0.0001,&#39;Plots&#39;,&#39;training-progress&#39;);</code></li></ul><p><strong>Validation</strong></p><ul><li>About different dataset:<ul><li>Training data: used during training to update weights.</li><li>Validation data: used during training to evaluate performance.</li><li>Testing data: used after training to evaluate performance.</li></ul></li><li>Validation data is useful to detect if your network is overfitting. Even if the training loss is decreasing, if the validation loss is increasing, you should stop training because the network is learning details about the training data that aren’t relevant to new images. </li><li>There are three training options related to validation. <ul><li><code>ValidationData</code>: Validation data and labels.</li><li><code>ValidationFrequency</code>: Number of iterations between each evaluation of the validation data.</li><li><code>ValidationPatience</code>: The number of validations to check before stopping training. Fluctuations in the loss from one iteration to another are normal, so you generally don’t want to stop training as soon as the validation loss increases. Instead, perform several validations. If the loss has not reached a new minimum in that time, then stop the training.</li></ul></li></ul><h3 id="Improve-Performance"><a href="#Improve-Performance" class="headerlink" title="Improve Performance"></a>Improve Performance</h3><p>After testing on the test dataset, if the accuracy is not adequate. We need to improve the network. Any of the inputs to trainNetwork can be modified to train a different network that may perform better.</p><ul><li>From <strong>training algorithm options</strong>: Modifying the training options is generally the first place to begin improving a network. </li><li><strong>Training Data</strong>: If no enough training data, the network may not generalize to new data. If you cannot get more training data, augmentation is a good alternative.</li><li><strong>Architecture</strong>: If you are performing transfer learning, you often do not need to modify the network architecture to train an effective network. One alternative is to try using a pretrained network with a directed acyclic architecture like GoogLeNet or ResNet-50.</li></ul><p><strong>Training Options</strong>:</p><ul><li>Decrease learning rate: If there is a large spike in loss, or loss values are no longer being plotted, your initial learning rate is probably too high. Decrease the learning rate by a power of ten until your loss decreases.</li><li>When you train a network, there is always a trade-off between accuracy and training time.</li><li>The following chart shows some general guidelines when training a convolutional neural network.<br><img src="/blogs/images/DLmatlab_01.jpg" width="50%" height="80%"></li></ul><p><strong>Augmented Datastores</strong>:</p><ul><li>The <code>imageDataAugmenter</code> function can be used to choose your augmentation. Possible augmentations include transformations like reflection, translation, and scaling.</li><li>Generally, you should choose an augmentation that is relevant to your data set: <code>imageDataAugmenter(&#39;RandRotation&#39;,[min max])</code></li><li>When you create an augmented image datastore, you need to specify the output image size, the source of the files, and the augmenter using <code>augmentedImageDatastore</code>: <code>augmentedImageDatastore(size,ds,&#39;DataAugmentation&#39;,augmenter)</code></li><li>You can read data from an augmented datastore with the <code>read</code> function. Instead of returning one image, <code>read</code> will return a batch of data. Each returned image has a different random augmentation: <code>data = read(augImds)</code></li><li>The variable containing the augmented images is named <code>input</code>: <code>im = data.input{n}</code></li></ul><p><strong>Directed Acyclic Graphs</strong>:</p><ul><li>All the networks we have used or created are represented in MATLAB as a column vector of layers. This is called a <strong>series architecture</strong>. </li><li>An alternate way to organize layers in a network is called a <strong>directed acyclic graph</strong> (DAG). DAGs have a more complex architecture where layers can have inputs from, or outputs to, multiple layers.</li><li>A DAG architecture is defined with layers and connections between these layers. In MATLAB, these are represented in separate network properties. Some pretrained networks – e.g., GoogLeNet, ResNet-50, and SqueezeNet – are DAG networks. </li><li>Transfer learn from a DAG:<ul><li>To modify the architecture of DAG network, we first need to get a graph of its layers. A layer graph contains both the layers and connections of a DAG: <code>lgraph = layerGraph(net)</code></li><li>view the architecture by using the layer graph as input to the plot function: <code>plot(lgraph)</code></li><li>Connections between layers in a DAG are defined by each layer’s name. When creating a new layer for a DAG network, you should name it by setting the ‘Name’ option: <code>newly = fullyConnectedLayer(n,&#39;Name&#39;,&#39;layerName&#39;)</code></li><li>replace a layer using the <code>replaceLayer</code> function. The three inputs are the layer graph, the name of the layer to replace, and the variable containing the new layer: <code>newgraph = replaceLayer(graph,&#39;oldLayerName&#39;,newly)</code></li></ul></li></ul><h2 id="sequence-classification-and-regression"><a href="#sequence-classification-and-regression" class="headerlink" title="sequence classification and regression."></a>sequence classification and regression.</h2><h3 id="Perform-Regression"><a href="#Perform-Regression" class="headerlink" title="Perform Regression"></a>Perform Regression</h3><p><strong>Transfer learning for regression</strong></p><ul><li>Use Alexnet to perform transfer learning</li><li>We need to delete the last three layers before replacing them with the correct layers because they are for classification. Now is a regression problem: <code>layers(end-n+1:end) = []</code></li><li>For regression problems, the last two layers must be a fully connected layer and a regression layer. The corresponding functions are <code>fullyConnectedLayer(outputSize)</code> and <code>regressionLayer()</code>. Regression networks do not need a softmax layer.</li><li>When a regression network is trained, <strong>root-mean-square error (RMSE)</strong> is calculated instead of accuracy. </li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># build and train a netwotk</span></span><br><span class="line">net = alexnet;</span><br><span class="line">ly = net.Layers;</span><br><span class="line">ly(end-2:end) = [];</span><br><span class="line">newlayers = [fullyConnectedLayer(1);regressionLayer()];</span><br><span class="line">ly = [ly;newlayers];</span><br><span class="line"></span><br><span class="line"><span class="comment"># evaluate regression network</span></span><br><span class="line">pred = predict(mynet,testImage);</span><br><span class="line">err = trueValue - pred;</span><br><span class="line"><span class="comment"># RMSE</span></span><br><span class="line">rmse = sqrt(sum(err.^2));</span><br></pre></td></tr></table></figure><h3 id="Detect-Objects-in-images"><a href="#Detect-Objects-in-images" class="headerlink" title="Detect Objects in images"></a>Detect Objects in images</h3><ul><li>use <code>insertObjectAnnotation</code> to add the bounding box to a image: <code>alteredImg = insertObjectAnnotation(image,&#39;rectangle&#39;,boxposition,label)</code></li></ul><p><strong>Regions with Convolutional Neural Networks (R-CNN)</strong></p><ul><li>R-CNN workflow:<ul><li>Find regions likely to contain objects</li><li>Extract and resize each region to CNN input size</li><li>Use CNN to predict class of each region</li></ul></li><li>Training and Using an R-CNN: <ul><li>There are three different types of object detectors in MATLAB: R-CNN, Fast R-CNN, and Faster R-CNN. The corresponding functions are <code>trainRCNNObjectDetector</code>, <code>trainFastRCNNObjectDetector</code>, and <code>trainFasterRCNNObjectDetector</code>. </li><li>These networks differ between training time and detection time. For example, a R-CNN can be trained quickly, but the time to detect a new image is slower than a Faster R-CNN network. You should choose between these networks depending on your application. </li><li>All of these functions have the same inputs and outputs: data, network, options</li><li>data is the ground truth stored as a table. The first variable is a directory and filename for each image. The remaining variables are labels and the corresponding bounding boxes.</li><li>use <code>detect</code> function to detect new images: <code>[bboxes,scores,labels] = detect(detector,image)</code></li></ul></li><li>Evaluating an Object Detector:<ul><li><strong>Precision</strong>: function <code>evaluateDetectionPrecision</code> calculates a precision metric using an overlap threshold between the predicted and true bounding boxes. Precision is a ratio of true positive instances to all positive instances of objects in the detector.</li><li><strong>Miss rate</strong>:  we also need to consider the case when the detector fails to find an object. This is called the miss rate. You can calculate a miss rate metric using <code>evaluateDetectionMissRate</code>.</li></ul></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># train a RCNN</span></span><br><span class="line">net = alexnet;</span><br><span class="line">options = trainingOptions(<span class="string">'sgdm'</span>,<span class="string">'InitialLearnRate'</span>,0.0001,<span class="string">'MaxEpochs'</span>,2);</span><br><span class="line">rcnn = trainRCNNObjectDetector(petGroundTruth,net,options);</span><br><span class="line"></span><br><span class="line"><span class="comment"># test on a image</span></span><br><span class="line">[dbox,dscore,dlabel] = detect(rcnn,dogim)</span><br><span class="line">detectedDogs = insertObjectAnnotation(dogim,<span class="string">'rectangle'</span>,dbox,cellstr(dlabel))</span><br><span class="line">imshow(detectedDogs)</span><br></pre></td></tr></table></figure><h3 id="Classify-Sequence-Data-with-Recurrent-Networks"><a href="#Classify-Sequence-Data-with-Recurrent-Networks" class="headerlink" title="Classify Sequence Data with Recurrent Networks"></a>Classify Sequence Data with Recurrent Networks</h3><p><strong>Long Short-term memory network (LSTM)</strong></p><ul><li>Sequence classification</li><li>Bidirectional LSTMs</li></ul><p><strong>Structuring Sequence Data</strong></p><ul><li>Training an LSTM requires the data to be stored in a particular format: <ul><li>The input data is a cell array with one column.</li><li>Each element in the cell array is one sample, or sequence. This sample is a numeric matrix.</li><li>The columns in each sample are the time steps. Every sample can have a different number of time steps.<br>-The rows correspond to the feature dimension of the sample. This could be signal data from different sensors, or different letters in a vocabulary. All samples must have the same number of rows.</li></ul></li></ul><p><strong>Sequence Classification</strong>：</p><ul><li>Create LSTM architecture<ul><li>The network begins with an input layer, follows with a BiLSTM layer, and ends with the same output layers as a CNN.</li><li>The first layer of an LSTM is a sequence input layer: <code>sequenceInputLayer(inputSize)</code>. The input to this function is the number of features, or the number of rows in a sample.</li><li>Next is a bidirectional LSTM layer. You should set the number of nodes and the output mode when creating this layer: <code>bilstmLayer(numNodes,&#39;OutputMode&#39;,&#39;last&#39;)</code></li><li>The last three layers in the LSTM are the same layers as a CNN for classification: fullyConnectedLayer, softmaxLayer and classificationLayer</li></ul></li><li>Train an LSTM</li><li>Use LSTM to classify sequences<ul><li>The classify function can be used with an LSTM: <code>predictedLabel = classify(net,testdata)</code></li></ul></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">inLayer = sequenceInputLayer(1)</span><br><span class="line">lstm = bilstmLayer(100,<span class="string">'OutputMode'</span>,<span class="string">'last'</span>)</span><br><span class="line">outLayers = [fullyConnectedLayer(3); softmaxLayer(); classificationLayer()]</span><br><span class="line"><span class="comment"># combine all layers</span></span><br><span class="line">layers = [inLayer; lstm; outLayers]</span><br><span class="line"></span><br><span class="line"><span class="comment"># train the network</span></span><br><span class="line">options = trainingOptions(<span class="string">'adam'</span>, ...</span><br><span class="line"><span class="string">'MaxEpochs'</span>,250, ...</span><br><span class="line"><span class="string">'InitialLearnRate'</span>,0.005, ...</span><br><span class="line"><span class="string">'GradientThreshold'</span>,1, ...</span><br><span class="line"><span class="string">'Shuffle'</span>,<span class="string">'every-epoch'</span>, ...</span><br><span class="line"><span class="string">'Plots'</span>,<span class="string">'training-progress'</span>, ...</span><br><span class="line"><span class="string">'LearnRateDropPeriod'</span>,200,...</span><br><span class="line"><span class="string">'LearnRateSchedule'</span>,<span class="string">'piecewise'</span>);</span><br><span class="line"></span><br><span class="line">net = trainNetwork(Xtrain,Ytrain,layers,options);</span><br><span class="line"></span><br><span class="line">testPred = classify(net,XTest)</span><br><span class="line">confusionchart(YTest,testPred)</span><br></pre></td></tr></table></figure><p><strong>Improving LSTM Performance</strong></p><ul><li>Sequences can be normalized using a variety of methods. </li><li>Sequence length and padding is specific to LSTMs. </li><li>Sequence length: <ul><li>Sequences can contain any number of time steps. This is convenient, but you should be cautious if your sequences have different lengths. </li><li>During training, the sequences in each mini-batch are padded with a number, usually zero, to equalize the lengths. A network cannot distinguish between values created for padding and values that are part of the sequence. </li><li>You should minimize the amount of padding by <strong>sorting your data</strong> by sequence length and carefully choosing the mini-batch size. </li><li>You can also use the ‘shortest’ option to trim longer sequences to the same length as the shortest sequence. This option has no padding, but can remove important data from your sequences.</li></ul></li></ul><h3 id="Classify-Categorical-Sequences"><a href="#Classify-Categorical-Sequences" class="headerlink" title="Classify Categorical Sequences"></a>Classify Categorical Sequences</h3><ul><li>Training an LSTM requires the sequences to be numeric. If your sequences are categorical, how can you train a deep network? </li><li>Categorical sequences could be a sequence of the weather, DNA, or music notes. </li><li>One option is to assign a number to each category. However, this results in imposing a false numerical structure on the observations. For example, if you assign the numbers 1 through 4 to four categories in a predictor, it implies that the distance between the categories 1 and 4 is longer than the distance between the categories 3 and 4. </li><li>Instead of assigning a number to each category, create dummy predictors for the categories. Each dummy predictor can have only two values – 0 or 1. For any given observation, only one of the dummy predictors can have the value equal to 1. You can create a matrix of dummy variables using the function dummyvar: <code>d = dummyvar(c)</code></li><li>You can train a network on text data by creating dummy predictors from a categorical representation of your text. The rows of the dummy predictor matrix correspond to each letter in the vocabulary.</li><li><strong>Classify Text Data</strong>:  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># suppose we have some sequences of text: tDickens, etc</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># convert to lowercases</span></span><br><span class="line">tDickens = lower(tDickens)</span><br><span class="line"><span class="comment"># create the vocabulary that contains all the types (with lowercase)</span></span><br><span class="line">vocab = uint8(<span class="string">' !"&amp;'</span><span class="string">'()*,-.0123456789:;?_abcdefghijklmnopqrstuvwxyz'</span>);</span><br><span class="line"><span class="comment"># dummy the variables</span></span><br><span class="line">m = dummyvar(categorical(uint8(tDickens),vocab)<span class="string">')'</span>; <span class="comment"># remember to transpose</span></span><br><span class="line"><span class="comment"># classify using a trained network</span></span><br><span class="line">[author,score] = classify(net,mDickens)</span><br></pre></td></tr></table></figure></li></ul><h3 id="Generate-Sequences-of-Output"><a href="#Generate-Sequences-of-Output" class="headerlink" title="Generate Sequences of Output"></a>Generate Sequences of Output</h3><ul><li>Sequence-to-Sequence Classification:<ul><li>Rather than classifying a recording as a single label, sometimes we also need to classify a sequence with multiple labels, e.g. multiple instruments in one recording. </li><li>In this case,the ‘OutputMode’ property need to be set to ‘sequence’</li></ul></li><li>Sequence Forecasting<ul><li>Long short-term memory networks can be used to forecast future time steps of a sequence. Forecasting is often performed with time series data.</li><li>The data used with the network is the sequence you want to forecast. You will use a subset of the sequence to train, and the rest to test.</li><li>The input data is the training sequence, except the last value. The response is the sequence shifted by one time step.</li><li>To predict with this network, use function <em>predictAndUpdateState</em> with the training data as input. This function predicts and updates the state of the network so it will remember this sequence during its next prediction.</li><li>The output is a prediction for the next value in the sequence. You can evaluate the network by comparing the actual and predicted value.</li><li>The training data for a text-generating network is a sequence of text where <u>each label is the next letter in the sequence. The input data should be everything except the last letter in the sequence.</u></li></ul></li></ul><hr><p>Some resources:</p><ul><li>Mathwork blogs for deep learning <a href="https://blogs.mathworks.com/deep-learning/" target="_blank" rel="noopener">https://blogs.mathworks.com/deep-learning/</a></li><li>Deep learning toolbox: <a href="https://au.mathworks.com/help/deeplearning/index.html" target="_blank" rel="noopener">https://au.mathworks.com/help/deeplearning/index.html</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;neural-network-theory&quot;&gt;&lt;a href=&quot;#neural-network-theory&quot; class=&quot;headerlink&quot; title=&quot;neural network theory&quot;&gt;&lt;/a&gt;neural network theory&lt;/
      
    
    </summary>
    
    
      <category term="Deep learning" scheme="http://tracyxinwang.site/blog/tags/Deep-learning/"/>
    
      <category term="Matlab" scheme="http://tracyxinwang.site/blog/tags/Matlab/"/>
    
  </entry>
  
  <entry>
    <title>Deep learning in Matlab I</title>
    <link href="http://tracyxinwang.site/blog/2019/01/04/Matlab-DL1/"/>
    <id>http://tracyxinwang.site/blog/2019/01/04/Matlab-DL1/</id>
    <published>2019-01-04T08:07:51.000Z</published>
    <updated>2019-01-07T03:07:25.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Use-pretrained-network"><a href="#Use-pretrained-network" class="headerlink" title="Use pretrained network"></a>Use pretrained network</h3><ul><li>use <code>imread</code> function to import images: <code>I = imread(&#39;filename.png&#39;);</code></li><li><code>imshow</code> to display an image:  <code>imshow(I)</code></li></ul><p><strong>Make prediction</strong></p><ul><li>use <code>alexnet</code> function to create a copy of the predefined deep network “AlexNet” in the MATLAB workspace: <code>net = alexnet</code></li><li>use <code>classify</code> function to make a prediction on an image: <code>pred = classify(net,img)</code></li></ul><p><strong>CNN Architecture</strong></p><ul><li>use <code>Layers</code> property to inspect the layers of the network: <code>ly = net.Layers</code></li><li>The <code>Layers</code> variable is an array of network layers. use array indexing to inspect an individual layer: <code>layer3 = ly(3)</code></li><li>Each layer of the network has properties relevant to that type of layer. An important property for an input layer is <strong>InputSize</strong>, which is the size (dimensions) of images the network expects as input: <code>insz = inlayer.InputSize</code></li><li>AlexNet requires an input image of size 227-by-227-by-3, meaning a color image 227 pixels high and 227 pixels wide.</li><li>The <code>Classes</code> property of an output layer gives the names of the categories the network is trained to predict: <code>categorynames = outlayer.Classes</code></li></ul><p><strong>Investigating Predictions</strong></p><ul><li><code>classify</code> function gives the class to which the network assigns the <em>highest</em> score. </li><li>We can obtain the predicted scores for all the classes by requesting a second output from classify: <code>[pred,scrs] = classify(net,img)</code></li><li>need to set threshold for the final prediction propability to have a better view of the prediction. e.g. set the threshold of one standard deviation above the median score: <code>thresh = median(scores) + std(scores);</code></li></ul><h3 id="Managing-Collections-of-Data"><a href="#Managing-Collections-of-Data" class="headerlink" title="Managing Collections of Data"></a>Managing Collections of Data</h3><p><strong>Image Datastore</strong></p><ul><li>use the <code>imageDatastore</code> function to create a datastore in MATLAB for later use of image classification: <code>ds = imageDatastore(&#39;foo*.png&#39;)</code></li><li>use the <code>read</code>, <code>readimage</code>, and <code>readall</code> functions to read images:<ul><li><code>read</code> imports images one at a time, in order; </li><li><code>readimage</code> imports a single specific image: <code>I = readimage(ds,n)</code></li><li><code>readall</code> imports all the images into a single cell array (with each image in a separate cell).</li></ul></li><li>can use an image datastore in place of an individual image in CNN functions such as classify: <code>preds = classify(net,ds)</code>. The result will be an array of predicted classes, one for each image in the datastore.</li></ul><p><strong>Prepare Images</strong></p><ul><li>can use the <code>InputSize</code> property of input layer to see what is the expected image size: <code>expectedSize = inlayer.InputSize</code></li><li>use <code>imresize</code> function to resize an image to match the expected input size: <code>imgresz = imresize(img,[numrows numcols]);</code></li></ul><p><strong>Preprocessing Images in a Datastore</strong></p><ul><li>to perform the same preprocessing steps on the entire data set, which is more efficient </li><li>use <code>augmentedImageDatastore</code> function to perform basic preprocessing: <code>auds = augmentedImageDatastore([r c],imds)</code>, r, c are the expected image size</li><li>use <code>montage</code> function to display the images in the datastore: <code>montage(imds)</code></li><li>use ‘ColorPreprocessing’ option to convert these images to a 3-D array: <code>auds = augmentedImageDatastore([n m],imds,&#39;ColorPreprocessing&#39;,&#39;gray2rgb&#39;)</code><ul><li>This will replicate the grayscale image three times to create a 3-D array.</li></ul></li></ul><p><strong>Create Datasore Uisng Subfolders</strong></p><ul><li>use the <code>IncludeSubfolders</code> option to look for images within subfolders of the given folder: <code>ds = imageDatastore(&#39;folder&#39;,&#39;IncludeSubfolders&#39;,true)</code></li></ul><h3 id="Performing-Transfer-Learning"><a href="#Performing-Transfer-Learning" class="headerlink" title="Performing Transfer Learning"></a>Performing Transfer Learning</h3><p><strong>The benefits of transfer learning</strong></p><ul><li>It is extremely easy to get started using a pretrained network like AlexNet. But you have no flexibility in the way the network operates, and the network probably won’t solve the exact problem you are trying to solve.</li><li>You can build and train a network yourself, starting with just the network architecture and random weights. But achieving reasonable results requires a lot of effort: (1) knowledge and experience with network architecture, (2) a huge amount of training data, and (3) a lot of computer time.</li><li>Transfer learning is an efficient solution for many problems. Training requires some data and computer time, but much less than training from scratch, and the result is a network suited to your specific problem.</li></ul><p><strong>Components of transfer learning</strong></p><ul><li>Network layers of the pretrained network, which serves as the starting point</li><li>Training data</li><li>Algorithms options: batch size, max iteration, learning rate</li></ul><p><strong>Prepare Training Data</strong></p><ul><li>Importing labels:<ul><li>The labels needed for training can be stored in the <code>Labels</code> property of the image datastore. By default, the <code>Labels</code> property is empty.</li><li>We can have the datastore automatically determine the labels from the folder names by specifying the <code>LabelSource</code> option: <code>ds = imageDatastore(folder,&#39;IncludeSubfolders&#39;,true,&#39;LabelSource&#39;,&#39;foldernames&#39;)</code></li></ul></li><li>Split the data:<ul><li>use the <code>splitEachLabel</code> function to divide the images in a datastore into two separate datastores: <code>[ds1,ds2] = splitEachLabel(imds,p)</code>, p is the proportion of images with each label from <code>imds</code> that should be contained in <code>ds1</code>.</li><li>By default, <code>splitEachLabel</code> keeps the files in order. We can randomly shuffle the files by adding the optional <code>randomized</code> flag: <code>[ds1,ds2] = splitEachLabel(imds,p,&#39;randomized&#39;)</code></li><li>To avoid the unbalanced classes in training dataset, we can also specify an exact number of files to take from each label to assign to ds1: <code>[ds1,ds2] = splitEachLabel(imds,n)</code>.</li><li>This ensures that every label in <code>ds1</code> has <code>n</code> images, even if the categories do not all contain the same number of images.</li><li>We can also split your data into three sets: training, validation during training, and testing. This can be made by specifying multiple values of p or n as inputs, and ask for the appropriate number of datastores as outputs.</li></ul></li><li>Augmented traning data:<ul><li>use <code>augmentedImageDatastore</code> function to add the variaty to the images</li><li>use <code>imageDataAugmenter</code> function to set the tranformation to the images: rotation, reflection, translation, shear, scaling</li></ul></li></ul><p><strong>Modify Network Layers</strong></p><ul><li>Normally transfer learnig only need to change the last few layers, which means they apply the same feature extraction but output different classes</li><li>To modify a preexisting network, you create a new layer. Then index into the layer array that represents the network and overwrite the chosen layer with the newly created layer: <code>fc= fullyConnectedLayer(12); layers(23) = fc;</code></li><li>The <code>fullyConnectedLayer</code> function creates a new fully connected layer, with a given number of neurons: <code>fclayer = fullyConnectedLayer(n)</code></li><li>Also the output layer still uses the previous labels in the pretrained network. We need to replace the output layer with a new, blank output layer.</li><li>use the <code>classificationLayer</code> function to create a new output layer for an image classification network: <code>cl = classificationLayer</code></li></ul><p><strong>Set Training Options</strong></p><ul><li>use the <code>trainingOptions</code> function to see the available options for the training algorithm: <code>opts = trainingOptions(&#39;sgdm&#39;)</code>. This creates a variable <code>opts</code> that contains the default options for the training algorithm, “stochastic gradient descent with momentum”.</li><li>when performing transfer learning, you will typically want to start with the <code>InitialLearnRate</code> set to a smaller value than the default of 0.01: <code>opts = trainingOptions(&#39;sgdm&#39;,&#39;InitialLearnRate&#39;,0.001)</code></li></ul><p><strong>Train the Network</strong></p><ul><li>“Mini-batch”<ul><li>At each iteration, a subset of the training images, known as a <strong>mini-batch</strong>, is used to update the weights. Each iteration uses a different mini-batch. Once the whole training set has been used, that’s known as an <strong>epoch</strong>.</li><li>The maximum number of epochs (<code>MaxEpochs</code>) and the size of the mini-batches (<code>MiniBatchSize</code>) are parameters you can set in the training algorithm options.</li><li>Note that the loss and accuracy reported during training are for the mini-batch being used in the current iteration.</li><li>By default, the images are shuffled once prior to being divided into mini-batches. You can control this behavior with the <code>Shuffle</code> option.</li></ul></li><li>Using GPUs<ul><li>If have an appropriate GPU and Parallel Computing Toolbox installed, the trainNetwork function will automatically perform the training on the GPU – no special coding required.</li><li>If not, the training will be done on your computer’s CPU instead.</li></ul></li><li>Transfer Learning Example Script:</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Get training images</span></span><br><span class="line">flower_ds = imageDatastore(<span class="string">'Flowers'</span>,<span class="string">'IncludeSubfolders'</span>,<span class="literal">true</span>,<span class="string">'LabelSource'</span>,<span class="string">'foldernames'</span>);</span><br><span class="line">[trainImgs,testImgs] = splitEachLabel(flower_ds,0.6);</span><br><span class="line">numClasses = numel(categories(flower_ds.Labels));</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Create a network by modifying AlexNet</span></span><br><span class="line">net = alexnet;</span><br><span class="line">layers = net.Layers;</span><br><span class="line">layers(end-2) = fullyConnectedLayer(numClasses);</span><br><span class="line">layers(end) = classificationLayer;</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Set training algorithm options</span></span><br><span class="line">options = trainingOptions(<span class="string">'sgdm'</span>,<span class="string">'InitialLearnRate'</span>, 0.001);</span><br><span class="line"></span><br><span class="line"><span class="comment"># Perform training</span></span><br><span class="line"><span class="comment"># The variable flowernet contains the network obtained by performing transfer learning on AlexNet with the flower species data. </span></span><br><span class="line"><span class="comment"># The variable info is a structure containing information on the training.</span></span><br><span class="line">[flowernet,info] = trainNetwork(trainImgs, layers, options);   </span><br><span class="line"></span><br><span class="line"><span class="comment"># Use trained network to classify test images</span></span><br><span class="line">testpreds = classify(flowernet,testImgs);</span><br></pre></td></tr></table></figure><p><strong>Evaluate Performance</strong></p><ul><li>The fields <code>TrainingLoss</code> and <code>TrainingAccuracy</code> in <code>info</code> variable above contain a record of the performance of the network on the training data at each iteration.</li><li>Determine how many of the test images the network correctly classified by comparing the predicted classification with the known classification. The known classifications are stored in the <code>Labels</code> property of the datastore: <code>flwrActual = testImgs.Labels; numCorrect = nnz(flwrPreds == flwrActual)</code></li><li>Investigate Performance by class:<ul><li>The <code>confusionchart</code> function calculates and displays the confusion matrix for the predicted classifications: <code>confusionchart(knownclass,predictedclass)</code></li><li>The (j,k) element of the confusion matrix is a count of how many images from class j the network predicted to be in class k. Hence, diagonal elements represent correct classifications; off-diagonal elements represent misclassifications.</li></ul></li></ul><h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p><strong>Create a model</strong></p><table><thead><tr><th>Function</th><th>Description</th></tr></thead><tbody><tr><td><code>alexnet</code></td><td>Load pretrained network “AlexNet”</td></tr><tr><td><a href="https://au.mathworks.com/solutions/deep-learning/models.html" target="_blank" rel="noopener">supported networks</a></td><td>a list of available pretrained networks</td></tr><tr><td><code>fullyConnectedLayer</code></td><td>Create new fully connected network layer</td></tr><tr><td><code>classificationLayer</code></td><td>Create new output layer for a classification network</td></tr></tbody></table><p><strong>Get training images</strong></p><table><thead><tr><th>Function</th><th>Description</th></tr></thead><tbody><tr><td><code>imageDatastore</code></td><td>Create datastore reference to image files</td></tr><tr><td><code>augmentedImageDatastore</code></td><td>Preprocess a collection of image files</td></tr><tr><td><code>splitEachLabel</code></td><td>Divide datastore into multiple datastores</td></tr></tbody></table><p><strong>Set training algorithm options</strong></p><table><thead><tr><th>Function</th><th>Description</th></tr></thead><tbody><tr><td><code>trainingOptions</code></td><td>Create variable containing training algorithm options</td></tr></tbody></table><p><strong>Perform training</strong></p><table><thead><tr><th>Function</th><th>Description</th></tr></thead><tbody><tr><td><code>trainNetwork</code></td><td>Perform training</td></tr></tbody></table><p><strong>Use trained network to perform classifications</strong></p><table><thead><tr><th>Function</th><th>Description</th></tr></thead><tbody><tr><td><code>classify</code></td><td>Obtain trained network’s classifications of input images</td></tr></tbody></table><p><strong>Evaluate trained network</strong></p><table><thead><tr><th>Function</th><th>Description</th></tr></thead><tbody><tr><td><code>nnz</code></td><td>Count non-zero elements in an array</td></tr><tr><td><code>confusionchart</code></td><td>Calculate confusion matrix</td></tr><tr><td><code>heatmap</code></td><td>Visualize confusion matrix as a heatmap</td></tr></tbody></table><hr><p>Some resources:</p><ul><li>Mathwork blogs for deep learning <a href="https://blogs.mathworks.com/deep-learning/" target="_blank" rel="noopener">https://blogs.mathworks.com/deep-learning/</a></li><li>Deep learning toolbox: <a href="https://au.mathworks.com/help/deeplearning/index.html" target="_blank" rel="noopener">https://au.mathworks.com/help/deeplearning/index.html</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;Use-pretrained-network&quot;&gt;&lt;a href=&quot;#Use-pretrained-network&quot; class=&quot;headerlink&quot; title=&quot;Use pretrained network&quot;&gt;&lt;/a&gt;Use pretrained netwo
      
    
    </summary>
    
    
      <category term="Deep learning" scheme="http://tracyxinwang.site/blog/tags/Deep-learning/"/>
    
      <category term="Matlab" scheme="http://tracyxinwang.site/blog/tags/Matlab/"/>
    
  </entry>
  
  <entry>
    <title>MIT6006 Lec19 DP I &amp; II</title>
    <link href="http://tracyxinwang.site/blog/2018/12/30/MIT6006-Lec19/"/>
    <id>http://tracyxinwang.site/blog/2018/12/30/MIT6006-Lec19/</id>
    <published>2018-12-30T12:52:13.000Z</published>
    <updated>2019-01-11T01:46:27.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Dynamic-Programming-DP"><a href="#Dynamic-Programming-DP" class="headerlink" title="Dynamic Programming (DP)"></a>Dynamic Programming (DP)</h3><ul><li>Powerful algorithmic design technique</li><li>Large class of seemingly exponential problems have a <u>polynomial</u> solution (“only”) via DP</li><li>Particularly for optimization problems (min / max) (e.g., shortest paths)</li><li>DP $\approx$ “controlled brute force”</li><li>DP $\approx$ recursion + re-use</li></ul><p><br></p><blockquote><p>Dynamic Programming is mainly an optimization over plain recursion. Wherever we see a recursive solution that has repeated calls for same inputs, we can optimize it using Dynamic Programming. The idea is to simply store the results of subproblems, so that we do not have to re-comupute them when needed later. This simple optimization reduces time complexities from exponential to polynomial. For example, if we write simple recursive solution for Fibonacci Numbers, we get exponential time complexity and if we optimize it by storing solutions of subproblems, time complexity reduces to linear.</p></blockquote><h4 id="Fibonacci-Numbers"><a href="#Fibonacci-Numbers" class="headerlink" title="Fibonacci Numbers"></a>Fibonacci Numbers</h4><p>$$F1 = F2 = 1; \qquad F_n = F_{n−1} + F_{n−2}$$<br>Goal: compute $F_n$</p><p><strong>Naive Algorithm</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">fib(n):</span><br><span class="line">    if n &lt;= 2: return f=1</span><br><span class="line">    else: return f = fib(n-1) + fib(n-2)</span><br></pre></td></tr></table></figure></p><p>⇒ $T(n) = T(n − 1) + T(n − 2) + O(1) ≥ Fn ≈ ϕ^n$<br>$≥ 2T(n − 2) + O(1) ≥ 2n/2$<br>EXPONENTIAL — BAD!<br>(As some items will be calculated twice, which consumes times)</p><p><strong>Memoized DP Algorithm</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">memo = &#123; &#125;</span><br><span class="line">fib(n):</span><br><span class="line">    if n in memo: return memo[n]</span><br><span class="line">    else: if n ≤ 2 : f = 1</span><br><span class="line">        else: f = fib(n − 1) + fib(n − 2)</span><br><span class="line">        memo[n] = f</span><br><span class="line">        return f</span><br></pre></td></tr></table></figure></p><p>Remember:<br>• ⇒ fib(k) only recurses first time called, ∀k<br>• ⇒ only n nonmemoized calls: k = n, n − 1, . . . , 1<br>• memoized calls free ($Θ(1)$ time)<br>• ⇒ $Θ(1)$ time per call (ignoring recursion)<br>POLYNOMIAL — GOOD!</p><p>DP ≈ recursion + memoization</p><ul><li>memoize (remember) &amp; re-use solutions to subproblems that help solve problem<ul><li>in Fibonacci, subproblems are F1, F2, . . . , Fn</li></ul></li><li>⇒ time = # of subproblems x time/subproblem<ul><li>Fibonacci: # of subproblems is n, and time/subproblem is Θ(1) = Θ(n) (ignore recursion!).</li></ul></li></ul><p><strong>Bottom-up DP Algorithm</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">fib = &#123;&#125;</span><br><span class="line">for k in [1, 2, . . . , n]:</span><br><span class="line">    if k ≤ 2: f = 1</span><br><span class="line">    else: f = fib[k − 1] + fib[k − 2]</span><br><span class="line">    fib[k] = f</span><br><span class="line">return fib[n]</span><br></pre></td></tr></table></figure></p><ul><li>exactly the same computation as memoized DP (recursion “unrolled”)</li><li>in general: topological sort of subproblem dependency DAG</li><li>practically faster: no recursion</li><li>analysis more obvious</li><li>can save space: just remember last 2 fibs ⇒ Θ(1)</li></ul><h4 id="Shortest-Paths"><a href="#Shortest-Paths" class="headerlink" title="Shortest Paths"></a>Shortest Paths</h4><ul><li>Recursive formulation:<br>$$δ(s, v) = min{δ(s, u) + w(u, v) | (u, v) ∈ E}$$</li><li>Memoized DP algorithm: takes infinite time if cycles!<ul><li>in some sense necessary to handle negative cycles</li></ul></li><li>works for directed acyclic graphs in $O(V + E)$<ul><li>effectively DFS/topological sort + Bellman-Ford round rolled into a single recursion<br>Subproblem dependency should be acyclic</li></ul></li><li>more subproblems remove cyclic dependence:<br>$$δ_k(s, v) = shortest \quad s → v \quad path \quad using ≤ k \quad edges$$</li><li>recurrence:<br>$δ<em>k(s, v) = min{δ</em>{k−1}(s, u) + w(u, v)|(u, v) ∈ E}$<br>$δ_0(s, v) = ∞$ for s $\ne$ v (base case)<br>$δ_k(s, s) = 0$ for any k (base case, if no negative cycles)$</li><li>Goal: $δ(s, v) = δ_{|V|−1}(s, v)$ (if no negative cycles)</li><li>memorize</li><li>time: # of subproblems($|V|·|V|$) x time/subproblem($O(v) = 0(V^3)$)</li><li>actually $Θ(indegree(v))$ for $δ_k(s, v)$</li><li>⇒ time = $Θ(V\sum_{v∈V} indegree(V)) = Θ(VE)$</li></ul><h3 id="Guessing"><a href="#Guessing" class="headerlink" title="Guessing"></a>Guessing</h3><p>How to design recurrence:</p><ul><li>want shortest s → v path</li><li>what is the last edge in path? dunno</li><li>guess it is (u, v)</li><li>then path is shortest s → u path + edge(u, v)</li><li>the cost is $δ<em>{k−1}(s, u) + w(u, v)$, and $δ</em>{k−1}(s, u)$ is another subproblem</li><li>to find best guess, try all (|V| choices) and use best</li><li>key: small (polynomial) # possible guesses per subproblem — typically this dominates time/subproblem<br>DP ≈ recursion + memoization + guessing</li></ul><h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><ul><li>DP $\approx$ “careful brute force”</li><li>DP $\approx$ guessing + recursion + memoization</li><li>DP ≈ dividing into reasonable # of subproblems whose solutions relate -  acyclicly - usually via guessing parts of solution.</li><li>time = # subproblems × time/subproblem<ul><li>essentially an amortization</li><li>count each subproblem only once; after first time, costs O(1) via memoization</li></ul></li><li>DP ≈ shortest paths in some DAG</li></ul><h4 id="5-Easy-Steps-to-Dynamic-Programming"><a href="#5-Easy-Steps-to-Dynamic-Programming" class="headerlink" title="5 Easy Steps to Dynamic Programming"></a>5 Easy Steps to Dynamic Programming</h4><ol><li>define subproblems           count # subproblems</li><li>guess (part of solution)     count # choices</li><li>relate subproblem solutions  compute time/subproblem</li><li>recurse + memoize            time = time/subproblem x # subproblems<ul><li>OR build DP table bottom-up</li><li>check subproblems acyclic/topological order</li></ul></li><li>solve original problem: = a subproblem<ul><li>OR by combining subproblem solutions ⇒ extra time</li></ul></li></ol><h3 id="Examples"><a href="#Examples" class="headerlink" title="Examples"></a>Examples</h3><h4 id="Text-Justification"><a href="#Text-Justification" class="headerlink" title="Text Justification"></a>Text Justification</h4><p>Content:<br>Split text into good lines</p><ul><li>obvious(MS Word) algorithm: put as many words that fit on first line, repeat</li><li>but this can make very bad lines<br>Redefine the problem:</li><li>Define badness(i,j) for line of words: [i,j]<ul><li>e.g. if $\inf$ total length &gt; page width, else (page width - total length)^3</li></ul></li><li>goal: split words into lines to min $\sum$ badness</li></ul><ol><li><strong>subproblem</strong> = min. badness for suffix words[i :]<br>⇒ number of subproblems = Θ(n) where n = number of words</li><li><strong>guessing</strong> = where to end first line, say i:j<br>⇒ number of choices = $n − i = O(n)$</li><li><strong>recurrence</strong>:<br>• DP[i] = min(badness (i,j) + DP[j] for j in range (i+1,n+1))<br>• DP[n] = 0<br>⇒ time per subproblem = Θ(n)</li><li><strong>order</strong>: for i=n,n-1,…,1,0<br>total time = $Θ(n^2)$</li><li>solution = DP[0]</li></ol><p><br></p><p>Reference:<br><a href="https://www.geeksforgeeks.org/dynamic-programming/" target="_blank" rel="noopener">https://www.geeksforgeeks.org/dynamic-programming/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;Dynamic-Programming-DP&quot;&gt;&lt;a href=&quot;#Dynamic-Programming-DP&quot; class=&quot;headerlink&quot; title=&quot;Dynamic Programming (DP)&quot;&gt;&lt;/a&gt;Dynamic Programmin
      
    
    </summary>
    
    
      <category term="Algorithm" scheme="http://tracyxinwang.site/blog/tags/Algorithm/"/>
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
  </entry>
  
  <entry>
    <title>MIT6006 Lec18 Speeding up Dijkstra</title>
    <link href="http://tracyxinwang.site/blog/2018/12/20/MIT6006-Lec18/"/>
    <id>http://tracyxinwang.site/blog/2018/12/20/MIT6006-Lec18/</id>
    <published>2018-12-20T09:50:13.000Z</published>
    <updated>2018-12-22T07:33:45.962Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Bi-Directional-Search"><a href="#Bi-Directional-Search" class="headerlink" title="Bi-Directional Search"></a>Bi-Directional Search</h3><ul><li>Bidirectional search means to start search from both direction simutaneously.</li><li>The reason to use bidirectional is that in many cases it is faster, it dramatically reduce the amount of required exploration.</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Alternate forward search from s</span><br><span class="line">          backward search from t</span><br><span class="line">          (follow edges backward)</span><br><span class="line">df(u) distances <span class="keyword">for</span> forward search</span><br><span class="line">db(u) distances <span class="keyword">for</span> backward search</span><br></pre></td></tr></table></figure><p>Note:</p><ul><li>Algorithm terminates when some vertex w has been processed, i.e., deleted from the queue of both searches, $Q_f$ and $Q_b$</li><li>Subtlety: After search terminates, find node x with minimum value of df(x) + db(x). x may not be the vertex w that caused termination as in example to the left!</li><li>Find shortest path from s to x using $Π_f$ and shortest path backwards from t to x using $Π_b$. Note: x will have been deleted from either $Q_f$ or $Q_b$ or both.</li></ul><h3 id="Goal-directed-search-or-A"><a href="#Goal-directed-search-or-A" class="headerlink" title="Goal directed search or A*"></a>Goal directed search or A*</h3><ul><li>A* Search algorithm is one of the best and popular technique used in path-finding and graph traversals.</li></ul><p>Modify edge weights with potential function over vertices.<br>$$\bar w(u,v) = w(u,v) - \lambda (u) + \lambda (v)$$</p><p>For A* algorithm, one of the item is the real distance, another one is heuristic distance, which can be manhattan, eucliean or other distance. </p><p><br></p><p>Reference:<br><a href="https://www.geeksforgeeks.org/a-search-algorithm/" target="_blank" rel="noopener">https://www.geeksforgeeks.org/a-search-algorithm/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;Bi-Directional-Search&quot;&gt;&lt;a href=&quot;#Bi-Directional-Search&quot; class=&quot;headerlink&quot; title=&quot;Bi-Directional Search&quot;&gt;&lt;/a&gt;Bi-Directional Search&lt;/
      
    
    </summary>
    
    
      <category term="Algorithm" scheme="http://tracyxinwang.site/blog/tags/Algorithm/"/>
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
  </entry>
  
  <entry>
    <title>MIT6006 Lec17 Bellman-Ford algorithm</title>
    <link href="http://tracyxinwang.site/blog/2018/12/20/MIT6006-Lec17/"/>
    <id>http://tracyxinwang.site/blog/2018/12/20/MIT6006-Lec17/</id>
    <published>2018-12-20T08:50:13.000Z</published>
    <updated>2018-12-22T07:31:38.573Z</updated>
    
    <content type="html"><![CDATA[<p><br></p><ul><li>Dijkstra doesn’t work for graphs with negative weight edges, Bellman-Ford works for such graphs. </li><li>Bellman-Ford is also simpler than Dijkstra and suites well for distributed systems. </li><li>But time complexity of Bellman-Ford is $O(VE)$, which is more than Dijkstra.</li></ul><p><strong>Steps</strong></p><ul><li>Initialize d’s, π’s, and set s.d = 0 ⇒ $O(V)$</li><li>Loop |V|-1 times through all edges checking the relaxation condition to compute minimum distances ⇒ $(|V|-1) O(E) = O(VE)$</li><li>Loop through all edges checking for negative weight cycles which occurs if any of the relaxation conditions fail ⇒ $O(E)$<br>The run time of the Bellman-Ford algorithm is $O(V + VE + E) = O(VE)$.</li></ul><p><strong>Pseudo Code</strong>:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">BELLMAN-FORD(G,w,s)</span><br><span class="line">  INITIALIZE-SINGLE-SOURCE(G,s)</span><br><span class="line">  <span class="keyword">for</span> i = 1 to |G.V|-1                  <span class="comment"># the reason using V-1 is that assuming the maximum edges for the shortest path have the V-1 hops through that path </span></span><br><span class="line">     <span class="keyword">for</span> each edge (u,v) ∈ G.E          <span class="comment"># Note: the order of update for eadges is predifined and every iteration use the same order</span></span><br><span class="line">        RELAX(u,v,w)</span><br><span class="line">  <span class="keyword">for</span> each edge (u,v) ∈ G.E</span><br><span class="line">     <span class="keyword">if</span> v.d &gt; u.d + w(u,v)</span><br><span class="line">        <span class="built_in">return</span> FALSE            <span class="comment"># so no solution if detecting a negative circle</span></span><br><span class="line">  <span class="built_in">return</span> TRUE</span><br><span class="line"></span><br><span class="line">INITIALIZE-SINGLE-SOURCE(G,s)</span><br><span class="line">  <span class="keyword">for</span> each vertex v ∈ G.V</span><br><span class="line">     v.d = ∞</span><br><span class="line">     v.pi = NIL</span><br><span class="line">  s.d = 0</span><br><span class="line"></span><br><span class="line">RELAX(u,v,w)</span><br><span class="line">  <span class="keyword">if</span> v.d &gt; u.d + w(u,v)</span><br><span class="line">     v.d = u.d + w(u,v)</span><br><span class="line">     v.pi = u       <span class="comment"># pi is the predecessor</span></span><br></pre></td></tr></table></figure></p><p>Note that if the graph is a DAG (which means no cycles), we can make Bellman-Ford more efficient by first topologically sorting G ($O(V+E)$), performing the same initialization ($O(V)$), and then simply looping through each vertex u in topological order relaxing only the edges in Adj[u] ($O(E)$). This method only takes $O(V + E)$ time. </p><p><br></p><p>Reference:<br><a href="https://www.programiz.com/dsa/bellman-ford-algorithm" target="_blank" rel="noopener">https://www.programiz.com/dsa/bellman-ford-algorithm</a><br><a href="https://www-m9.ma.tum.de/graph-algorithms/spp-bellman-ford/index_en.html" target="_blank" rel="noopener">https://www-m9.ma.tum.de/graph-algorithms/spp-bellman-ford/index_en.html</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Dijkstra doesn’t work for graphs with negative weight edges, Bellman-Ford works for such graphs. &lt;/li&gt;
&lt;li&gt;Bellman-Ford
      
    
    </summary>
    
    
      <category term="Algorithm" scheme="http://tracyxinwang.site/blog/tags/Algorithm/"/>
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
  </entry>
  
  <entry>
    <title>MIT6006 Lec15 Shortest Paths I&amp;II Intro and Dijkstra</title>
    <link href="http://tracyxinwang.site/blog/2018/12/10/MIT6006-Lec15/"/>
    <id>http://tracyxinwang.site/blog/2018/12/10/MIT6006-Lec15/</id>
    <published>2018-12-10T03:10:23.000Z</published>
    <updated>2018-12-14T05:19:11.475Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Part-I"><a href="#Part-I" class="headerlink" title="Part I"></a>Part I</h2><p>Two algorithms: </p><ul><li>Dijkstra $O(VlgV + E)$ assumes non-negative edge weights</li><li>Bellman Ford $O(VE)$ is a general algorithm</li></ul><h3 id="Weighted-graphs"><a href="#Weighted-graphs" class="headerlink" title="Weighted graphs"></a>Weighted graphs</h3><p><strong>Single Source Shortest Paths</strong>:</p><p>Given $G = (V, E)$, $w$ and a source vertex $S$, find $δ(S, V)$ [and the best path] from $S$ to each $v∈V$.</p><p>Data structures:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">d[v] = value inside circle</span><br><span class="line">     = 0, <span class="keyword">if</span> v = s</span><br><span class="line">     = ∞, otherwise     ⇐ initially</span><br><span class="line">d[v] = δ (s,v)          ⇐ at end</span><br><span class="line">d[v] \le δ (s,v)        at all <span class="built_in">times</span></span><br></pre></td></tr></table></figure></p><p>$d[v]$ decreases as we find better paths to v<br>$Π[v]$ = predecessor on best path to $v$, $Π[s] = NIL$</p><p><strong>Negative-Weight Edges</strong>:</p><p>If negative weight edges are present, s.p. algorithm should find negative weight cycles (e.g., Bellman Ford)</p><h3 id="General-approach"><a href="#General-approach" class="headerlink" title="General approach"></a>General approach</h3><p>General structure of S.P. Algorithms (no negative cycles):<br><img src="/blog/images/MIT15_01.jpg"></p><h3 id="Optimal-substructure"><a href="#Optimal-substructure" class="headerlink" title="Optimal substructure"></a>Optimal substructure</h3><p><strong>Theorem</strong>: Subpaths of shortest paths are shortest paths<br>Let $p = &lt; v_0, v_1, . . . v_k &gt;$ be a shortest path<br>Let $p_{ij} = &lt; v_i, v_{i+1}, . . . v_j &gt;$  $0 ≤ i ≤ j ≤ k$<br>Then $p_{ij}$ is a shortest path.</p><h2 id="Part-II"><a href="#Part-II" class="headerlink" title="Part II"></a>Part II</h2><h3 id="DAG"><a href="#DAG" class="headerlink" title="DAG"></a>DAG</h3><ul><li>Topologically sort the DAG. Path from u to v implies that u is before v in the linear ordering.</li><li>One pass over vertices in topologically sorted order relaxing each edge that leaves each vertex. </li></ul><p>Note: Can’t have negative cycles because there are no cycles!</p><h3 id="Dijkstra’s-Algorithm"><a href="#Dijkstra’s-Algorithm" class="headerlink" title="Dijkstra’s Algorithm"></a>Dijkstra’s Algorithm</h3><ul><li>The idea is to maintain two sets</li><li>one set contains vertices included in existing shortest path</li><li>another set includes vertices not yet included. </li><li>At every step of the algorithm, find a vertex <ul><li>which is in the set with not included vertex and </li><li>has a minimum distance from the source.</li><li>update the distance of the shorted path set</li></ul></li></ul><p>For each edge $(u, v) \in E$, assume $w(u, v) ≥ 0$, maintain a set S of vertices whose final shortest path weights have been determined. Repeatedly select $u \in V − S$ with minimum shortest path estimate, add u to S, relax all edges out of u.</p><p><strong>Pseudo-code</strong><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Dijkstra (G, W, s)          //uses priority queue Q</span><br><span class="line">    Initialize (G, s)</span><br><span class="line">    S ← φ</span><br><span class="line">    Q ← V[G]               //Insert into Q</span><br><span class="line">    <span class="keyword">while</span> Q = φ</span><br><span class="line">        <span class="keyword">do</span> u ← EXTRACT-MIN(Q)   //deletes u from Q</span><br><span class="line">        S = S ∪ &#123;u&#125;</span><br><span class="line">        <span class="keyword">for</span> each vertex v $\<span class="keyword">in</span>$ Adj[u]</span><br><span class="line">            <span class="keyword">do</span> RELAX (u, v, w) ← this is an implicit DECREASE KEY operation</span><br></pre></td></tr></table></figure></p><p><u>Strategy</u>: Dijkstra is a greedy algorithm: choose closest vertex in V − S to add to set S.<br><u>Correctness</u>: We know relaxation is safe. The key observation is that each time a vertex u is added to set S, we have $d[u] = δ(s, u)$.</p><h4 id="Dijkstra-Complexity"><a href="#Dijkstra-Complexity" class="headerlink" title="Dijkstra Complexity"></a>Dijkstra Complexity</h4><p>$Θ(v)$ inserts into priority queue<br>$Θ(v)$ EXTRACT_MIN operations<br>$Θ(E)$ DECREASE_KEY operations</p><p><strong>Array impl</strong>:</p><ul><li>Θ(v) time for extra min</li><li>Θ(1) for decrease key<br>Total: Θ(V.V + E.1) = Θ(V^2 + E) = Θ(V^2)</li></ul><p><strong>Binary min-heap</strong>:</p><ul><li>Θ(lgV) for extract min</li><li>Θ(lgV) for decrease key<br>Total: Θ(VlgV + ElgV )</li></ul><p><strong>Fibonacci heap</strong>:</p><ul><li>Θ(lgV ) for extract min</li><li>Θ(1) for decrease key</li><li>amortized cost<br>Total: Θ(VlgV + E)</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Part-I&quot;&gt;&lt;a href=&quot;#Part-I&quot; class=&quot;headerlink&quot; title=&quot;Part I&quot;&gt;&lt;/a&gt;Part I&lt;/h2&gt;&lt;p&gt;Two algorithms: &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Dijkstra $O(VlgV + E)$ a
      
    
    </summary>
    
    
      <category term="Algorithm" scheme="http://tracyxinwang.site/blog/tags/Algorithm/"/>
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
  </entry>
  
  <entry>
    <title>MIT6006 Lec14 Graphs II Depth-First Search</title>
    <link href="http://tracyxinwang.site/blog/2018/12/09/MIT6006-Lec14/"/>
    <id>http://tracyxinwang.site/blog/2018/12/09/MIT6006-Lec14/</id>
    <published>2018-12-09T07:49:23.000Z</published>
    <updated>2018-12-09T07:11:43.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Depth-First-Search"><a href="#Depth-First-Search" class="headerlink" title="Depth-First Search"></a>Depth-First Search</h3><p><strong>Depth First Search Algorithm</strong>:</p><ul><li>follow path until you get stuck</li><li>backtrack along breadcrumbs(面包屑…) until reach unexplored neighbor</li><li><strong>recursively</strong> explore</li><li>careful not to repeat a vertex</li></ul><p>Pseudo codes are as follows:<br><img src="/blog/images/MIT14_01.jpg"></p><p>Note that DFS and DFS-visit are two things. DFS is the top level of DFS-visit and it makes sure that all the vertex will be visited.</p><p><strong>Edge Classification</strong></p><ul><li>tree edges (parent pointer): visit new vertex via edge</li><li>forward edges: node -&gt; descendant in tree</li><li>backward edges: node -&gt; ancestor in tree</li><li>cross edges: other edges (from one tree to another) between two non-ancestor-related subtrees<br>To compute this classification (back or not), mark nodes for duration they are “on the stack”</li><li>only tree and back edges in undirected graph</li></ul><p><strong>Analysis</strong></p><ul><li>DFS-visit gets called with a vertex s only once (because then parent[s] set)<ul><li>⇒ time in DFS-visit = $\sum_{s∈V}|Adj[s]| = O(E)$</li></ul></li><li>DFS outer loop adds just $O(V)$<ul><li>⇒ $O(V + E)$ time (linear time)</li></ul></li></ul><h3 id="Cycle-Testing"><a href="#Cycle-Testing" class="headerlink" title="Cycle Testing"></a>Cycle Testing</h3><p>For directed graph:</p><ul><li>DFS can be used to detect a cycle in a Graph.</li><li>DFS for a connected graph produces a tree. There is a cycle in a graph only if there is a <strong>back edge</strong> present in the graph. </li><li>For a disconnected graph, get the DFS forest as output. To detect cycle, we can check for a cycle in <em>individual trees</em> by checking back edges.</li></ul><h3 id="Topological-Sort"><a href="#Topological-Sort" class="headerlink" title="Topological Sort"></a>Topological Sort</h3><p>Topological sorting for <u>Directed Acyclic Graph (DAG)</u> is a linear ordering of vertices such that for every directed edge uv, vertex u comes before v in the ordering. Topological Sorting for a graph is not possible if the graph is not a DAG.</p><ul><li>The first vertex in topological sorting is always a vertex with in-degree as 0 (a vertex with no incoming edges).</li><li>We can modify DFS to find Topological Sorting of a graph. </li><li>In DFS, we start from a vertex, we first print it and then recursively call DFS for its adjacent vertices. </li><li>In topological sorting, we use a temporary stack. We don’t print the vertex immediately, we first recursively call topological sorting for all its adjacent vertices, then push it to a stack. Finally, print contents of stack. Note that a vertex is pushed to stack only when all of its adjacent vertices (and their adjacent vertices and so on) are already in stack.</li></ul><p><br><br>Reference:<br><a href="https://www.geeksforgeeks.org/topological-sorting/" target="_blank" rel="noopener">https://www.geeksforgeeks.org/topological-sorting/</a><br><a href="https://www.geeksforgeeks.org/detect-cycle-in-a-graph/" target="_blank" rel="noopener">https://www.geeksforgeeks.org/detect-cycle-in-a-graph/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;Depth-First-Search&quot;&gt;&lt;a href=&quot;#Depth-First-Search&quot; class=&quot;headerlink&quot; title=&quot;Depth-First Search&quot;&gt;&lt;/a&gt;Depth-First Search&lt;/h3&gt;&lt;p&gt;&lt;stron
      
    
    </summary>
    
    
      <category term="Algorithm" scheme="http://tracyxinwang.site/blog/tags/Algorithm/"/>
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
  </entry>
  
  <entry>
    <title>MIT6006 Lec13 Graphs I Breadth First Search</title>
    <link href="http://tracyxinwang.site/blog/2018/12/09/MIT6006-Lec13/"/>
    <id>http://tracyxinwang.site/blog/2018/12/09/MIT6006-Lec13/</id>
    <published>2018-12-09T03:25:23.000Z</published>
    <updated>2018-12-09T07:16:49.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Graph-Representations"><a href="#Graph-Representations" class="headerlink" title="Graph Representations"></a>Graph Representations</h3><p><strong>Adjacency lists</strong>:</p><ul><li>Array $Adj$ of $|V|$ linked lists<ul><li>for each vertex $u∈V$, $Adj[u]$ stores $u$’s neighbors, i.e., ${v∈V|(u,v)∈E}$</li></ul></li></ul><p><strong>Implicit Graphs</strong>:</p><ul><li>$Adj(u)$ is a function — compute local structure on the fly</li></ul><p><strong>Object-oriented Variations</strong>:</p><ul><li>object for each vertex $u$</li><li>u.neighbors = list of neighbors i.e. $Adj[u]$</li></ul><p><strong>Incidence Lists</strong>:</p><ul><li>can also make edges objects</li><li>u.edges = list of (outgoing) edges from u.</li><li>advantage: store edge data without hashing</li></ul><p><strong>Graph traversal</strong> means visiting every vertex and edge exactly once in a well-defined order. BFS is the most commonly used approach.</p><h3 id="Breadth-First-Search"><a href="#Breadth-First-Search" class="headerlink" title="Breadth-First Search"></a>Breadth-First Search</h3><p>Explore graph level by level from $s$ (that is to say, you will not move to another layer until you visit all the nodes of the current layer):</p><ul><li>level 0 = {s}</li><li>level i = vertices reachable by path of i edges but not fewer</li><li>build level $i &gt; 0$ from level $i − 1$ by trying all outgoing edges, but ignoring vertices from previous levels<br><img src="/blog/images/MIT13_01.jpg" width="50%" height="50%"></li></ul><p><strong>Breadth-First-Search Algorithm</strong><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">BFS (V,Adj,s): </span><br><span class="line">    level = &#123;s: 0&#125;</span><br><span class="line">    parent = &#123;s: None&#125;</span><br><span class="line">    i = 1</span><br><span class="line">    frontier = [s]      <span class="comment"># previous level, i − 1</span></span><br><span class="line">    <span class="keyword">while</span> frontier:</span><br><span class="line">        next = [ ]          <span class="comment"># next level, i</span></span><br><span class="line">        <span class="keyword">for</span> u <span class="keyword">in</span> frontier:</span><br><span class="line">            <span class="keyword">for</span> v <span class="keyword">in</span> Adj[u]:</span><br><span class="line">                <span class="keyword">if</span> v not <span class="keyword">in</span> level:  <span class="comment"># not yet seen</span></span><br><span class="line">                    level[v] = i    <span class="comment"># = level[u] + 1</span></span><br><span class="line">                    parent[v] = u</span><br><span class="line">                    next.append(v)</span><br><span class="line">        frontier = next</span><br><span class="line">        i + =1</span><br></pre></td></tr></table></figure></p><p>Example:<br><img src="/blog/images/MIT13_02.jpg"></p><p><strong>Analysis</strong>:</p><ul><li>vertex $V$ enters next (&amp; then frontier) only once (because level[v] then set)</li><li>⇒ $Adj[v]$ looped through only once</li><li>⇒ $O(E)$ time</li><li>$O(V + E)$ (“LINEAR TIME”) to also list vertices unreachable from v (those still not assigned level)</li></ul><p><strong>Shortest Paths</strong>:</p><ul><li>for every vertex v, fewest edges to get from s to v is:<ul><li>level[v], if v assigned level</li><li>$∞$, if no path</li></ul></li><li>parent pointers form <u>shortest-path tree</u> = union of such a shortest path for each v<ul><li>⇒ to find shortest path, take v, parent[v], parent[parent[v]], etc., until s (or None)</li></ul></li></ul><p><br><br>Reference:<br><a href="https://www.hackerearth.com/zh/practice/algorithms/graphs/breadth-first-search/tutorial/" target="_blank" rel="noopener">https://www.hackerearth.com/zh/practice/algorithms/graphs/breadth-first-search/tutorial/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;Graph-Representations&quot;&gt;&lt;a href=&quot;#Graph-Representations&quot; class=&quot;headerlink&quot; title=&quot;Graph Representations&quot;&gt;&lt;/a&gt;Graph Representations&lt;/
      
    
    </summary>
    
    
      <category term="Algorithm" scheme="http://tracyxinwang.site/blog/tags/Algorithm/"/>
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
  </entry>
  
  <entry>
    <title>Visualization in Matlab</title>
    <link href="http://tracyxinwang.site/blog/2018/12/01/Matlab-visualization/"/>
    <id>http://tracyxinwang.site/blog/2018/12/01/Matlab-visualization/</id>
    <published>2018-12-01T10:07:20.000Z</published>
    <updated>2018-12-09T00:30:06.000Z</updated>
    
    <content type="html"><![CDATA[<p><br></p><h3 id="Import-Tabular-Data"><a href="#Import-Tabular-Data" class="headerlink" title="Import Tabular Data"></a>Import Tabular Data</h3><ul><li>Tabular data can be in a single spreadsheet or a delimited text file</li><li><code>readtable</code> function: <ul><li><code>myTable = readtable(&#39;tablename.txt&#39;);</code></li><li>access the variable using dot notation: <code>P=myTable.Pressure;</code></li><li>when there is additional header in text file, provide additional inputs to indicate the number of header lines in the file: <code>myTable = readtable(&#39;tablename.txt&#39;,&#39;HeaderLines&#39;,5)</code></li><li>use the option <code>CommentStyle</code> to ignore some lines with specific symbols: <code>myTable = readtable(&#39;tablename.txt&#39;,&#39;CommentStyle&#39;,&#39;##&#39;);</code></li></ul></li><li><p>Representing Discrete Categories:</p><ul><li>By default, the values of finite variables are imported as a cell array. But it may consume the memory</li><li>therefore using <code>categorical</code> variables to store those data.</li><li><code>x = categorical(x)</code></li><li><p>can specify all the possible values as additional inputs to <code>categorical</code>: the <em>second</em> input indicates the unique category values in the original array, and the <em>third</em> input indicates the names that correspond to these categories:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">v = [ 10 5 0 0 ];</span><br><span class="line">levels = &#123; <span class="string">'beg'</span> <span class="string">'mid'</span> <span class="string">'last'</span> &#125;;</span><br><span class="line">categorical(v,[0 5 10],levels)</span><br><span class="line">ans = </span><br><span class="line">    last      mid      beg      beg</span><br></pre></td></tr></table></figure></li><li><p>to remain the inherent ordering, use <code>Ordinal</code>: </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">v = [2 4 1 1];</span><br><span class="line">levels = &#123;<span class="string">'tiny'</span>,<span class="string">'small'</span>,<span class="string">'big'</span>,<span class="string">'huge'</span>&#125;;</span><br><span class="line">c = categorical(v,[1 2 3 4],levels,<span class="string">'Ordinal'</span>,<span class="literal">true</span>)</span><br><span class="line">ans = </span><br><span class="line">    small huge tiny tiny</span><br></pre></td></tr></table></figure></li><li><p>Categorical arrays allow the use of <code>==, &gt;, &lt;</code> for comparison: <code>y==&#39;small&#39;</code></p></li></ul></li></ul><h3 id="Preprocessing-Data"><a href="#Preprocessing-Data" class="headerlink" title="Preprocessing Data"></a>Preprocessing Data</h3><ul><li>Calculations Involving NaNs:<ul><li>mean without NaN: <code>y=mean(y,&#39;omitnan&#39;)</code></li><li>median without NaN: <code>y=median(y,&#39;omitnan&#39;)</code></li><li>test an array for numeric equality, as well as determining if the NaNs align, use <code>isequaln</code>: <code>test = isequaln(x,y)</code></li></ul></li><li>Locating Missing Data:<ul><li>replace the NaN value with zero: <code>x(isnan(x)) = 0</code></li><li>delete the NaN value: <code>x(isnan(x)) = [];</code></li><li>use <code>ismissing</code> on a table to identify location of any kind of missing values: <code>missingDataLocations = ismissing(tableName);</code></li><li>Use <code>any</code> function to determine which <em>rows</em> have any true values: <code>trueRows = any(grid,2)</code>, <code>2</code> indicates that the function should search for nonzero elements along the 2nd (column) dimension.</li></ul></li><li>Categories and Set Operations:<ul><li><code>categories</code> function returns the unique categories within a categorical array: <code>cats = categories(variableName);</code></li><li><code>setdiff</code> function performs the set difference between the first and the second input: <code>d = setdiff(a,b)</code>, returned variable d has values in a that are not present in b.</li><li>merge different categories in a categorical array: <code>a = mergecats(a,{&#39;small&#39; &#39;medium&#39; &#39;large&#39;},&#39;size&#39;)</code></li></ul></li><li>Discretizing Continuous Data:<ul><li><code>discretize</code> function to categorize values into discrete bins: <code>binNum = discretize(x,0:0.2:1)</code>. </li><li>Note that any NaNs or values outside the range of the bins are unclassified. Add <code>-Inf</code> or <code>Inf</code> to the vector of bin edges if want to include bins for values outside of the edges.</li><li>To discretize data into categories, use the <code>Categorical</code> option: <code>cats = {&#39;on&#39;,&#39;off&#39;}; binNum = discretize(x,0:0.5:1,&#39;Categorical&#39;,cats);</code></li></ul></li></ul><h3 id="Graphics-Formatting-Function"><a href="#Graphics-Formatting-Function" class="headerlink" title="Graphics Formatting Function"></a>Graphics Formatting Function</h3><ul><li>A plot in MATLAB is a collection of graphics objects. You can change the properties of the graphics object by providing additional inputs to the function that created the graphics object.</li><li>Plot line properties:<ul><li><code>plot(x,y,&#39;*&#39;,&#39;MarkerSize&#39;,8,&#39;MarkerFaceColor&#39;,[0.5 0.5 1])</code></li></ul></li><li>Scatter plot:<ul><li>scale the size of the markers by supplying it as the <em>third</em> optional input which must be either a scalar or the same length as the input values: <code>scatter([4 5 6 7],[9 11 13 15],[25 50 75 100])</code></li><li>specify marker style: <code>plot(xData,yData,15,&#39;kd&#39;)</code> to plot with black diamond markers</li><li>fill the marker: <code>scatter(xData,yData,15,&#39;kd&#39;,&#39;filled&#39;)</code></li></ul></li><li>Functions for Customizing Appearance:<ul><li><code>xlim</code> function will change the limits of the x-axis: <code>xlim([1 10])</code></li><li><code>grid</code> command to control whether or not grid lines are displayed: <code>grid(&#39;on&#39;)</code> or <code>grid(&#39;minor&#39;)</code></li><li><code>axis</code> command to change the style of the axes: <code>axis(&#39;tight&#39;)</code> <code>axis(&#39;square&#39;)</code></li></ul></li></ul><h3 id="Importing-Data-from-Multiple-Files"><a href="#Importing-Data-from-Multiple-Files" class="headerlink" title="Importing Data from Multiple Files"></a>Importing Data from Multiple Files</h3><ul><li>Create Datastores:<ul><li>A datastore is just a reference to a file or a set of files. Creating a datastore does not automatically import any data into MATLAB.</li><li>use <code>datastore</code> function with the file or folder location as the input: <code>ds = datastore(&#39;dirName/fileName.txt&#39;);</code> At this point, we have only created a reference to the data file.  </li><li><code>preview</code> function help see the first few lines of data in the file: <code>preview(datastoreVariable)</code></li><li>Since the datastore variable does not contain any data but only the information about the file, we can access this information through its properties: <code>ds.propertyName</code>. The properties can be <code>VariableNames</code>, <code>Files</code>, <code>NumHeaderLines</code>, <code>MissingValue</code></li></ul></li><li>Modify Datastore Properties<ul><li>ignore that begin with the character sequence ‘//‘ by modifying the <code>CommenStyle</code> property: <code>dat.CommentStyle = &#39;//&#39;</code></li><li>set the <code>ReadVariableNames</code> property to false if there isn’t a line containing the variable names: <code>dat.ReadVariableNames = false</code></li><li>Set the variable name: <code>dat.VariableNames ={&#39;color&#39;,&#39;size&#39;,&#39;act&#39;,&#39;age&#39;,&#39;inflated&#39;}</code></li></ul></li><li>Import Data into MATLAB<ul><li><code>read</code> and <code>readall</code>: to read data using datastore:  <code>data = ds.read;</code></li><li>the <code>read</code> function will read data up to the number of lines specified by the <code>ReadSize</code> property of the datastore (20000 by default).</li><li>If File1.txt has more than 20000 rows, only first 20000 are read. When <code>read</code> again, the rest part are readed.</li><li><code>reset</code> function: reset the datastore to the beginning of the first data file.</li><li>After resetting, use the function <code>readall</code> to read all the data.</li></ul></li><li>Importing Datatypes Directly<ul><li><code>TextscanFormats</code> property will return a cell array with the format used to read in each column of data: <code>fmt = dat.TextscanFormats</code></li><li>By default, the numeric columns are represented with <code>%f</code> and non-numeric columns are interpreted to be strings denoted by <code>%q</code>. The format specifier for a categorical is <code>%C</code>. Datatime is <code>%D</code></li><li>To modify the datatype of a variable while importing, use curly braces to index into a cell of TextscanFormats and set it to the appropriate value: <code>ds.TextscanFormats{1} = &#39;%q&#39;</code></li></ul></li><li>Skipping Columns of Data<ul><li>to import only a subset of columns, use <code>SelectedVariableNames</code>. Only the variables listed in the <code>SelectedVariableNames</code> property are imported: <code>ds.SelectedVariableNames = {&#39;Name&#39;,&#39;Date&#39;}</code></li></ul></li></ul><h3 id="Analyzing-Groups-within-Data"><a href="#Analyzing-Groups-within-Data" class="headerlink" title="Analyzing Groups within Data"></a>Analyzing Groups within Data</h3><ul><li>Find unique groups of data<ul><li><code>findgroups</code> function can group the values in an array and get the group numbers for each value: <code>v = {&#39;tiger&#39; &#39;lion&#39; &#39;lion&#39; &#39;tiger&#39;}; grpNums = findgroups(v)</code></li><li>return the group values from findgroups by requesting a second output: <code>[grpNum,grpVal] = findgroups(v)</code>, then <code>grpval=&#39;lion&#39;, &#39;tiger&#39;</code></li><li><code>histcounts</code> can count the number of observations in each group: <code>counts = histcounts(grpNum,&#39;BinMethod&#39;,&#39;integers&#39;);</code></li><li><code>findgroups</code> allows for grouping with multiple inputs. In addition to the group number, it can also return the group values from each input variable: <code>[grpNum,petVals,genderVals] = findgroups(pets,gender)</code></li></ul></li><li>Aggregating Grouped Data<ul><li>function <code>splitapply</code> to perform different operations on groups of data: <code>splitapply(@min,data,grpNums)</code></li><li>after that, you can plot the grouped results using <code>bar</code> chart: <code>[gNum1,gName1] = findgroups(mnth); avgWS = splitapply(@mean,hurrs.Windspeed,gNum1); bar(avgWS);xticklabels(gName1)</code></li><li><code>monthNum2Name</code> can help convert month to names: <code>xticklabels(monthNum2Name(gName1)); xtickangle(45)</code></li></ul></li><li>Aggregating Grouped Data into a Prescribed Format<ul><li>You might want to see the correlations between the groups by aggregating groups and storing the results in a particular structure. <code>accumarray</code> can do that.</li><li>The first input to <code>accumarray</code> is the results from <code>findgroups</code>, with columns representing the group numbers. The second input is the data to be aggregated. The third input is left blank and the fourth input is the function to be used for aggregation: <code>avgP = accumarray([G1 G2],Price,[],@mean)</code></li></ul></li></ul><h3 id="Customizing-Graphics-Objects"><a href="#Customizing-Graphics-Objects" class="headerlink" title="Customizing Graphics Objects"></a>Customizing Graphics Objects</h3><ul><li>Accessing Graphics Objects<ul><li>To modify the properties of a graphics object, the first step is to obtaining a variable (sometimes called a handle) that refers to the particular graphics object.</li><li>Obtain the graphics object variable by assigning output from the graphics functions: <code>f = figure</code></li><li>By assigning output from the <code>plot</code> command, you can obtain a line object variable: <code>p=plot(x,y)</code></li><li>To get the graphics object variables for a plot that is already created, use the functions <code>gcf</code>, <code>gca</code>, and <code>gco</code> to obtain the current figure, axes and selected object (“get current figure/axes/object”): <code>fig = gcf;</code></li></ul></li><li><p>Querying and Modifying Properties:</p><ul><li>use dot notation with the property name to return object property value, e.g.: <code>ax = gca; fw = ax.FontWeight</code></li><li>use the dot notation to assign a value to an object property: <code>ax.FontWeight = &#39;bold&#39;</code>, <code>ax.XTick = [1,4,8,12]</code></li><li>modify the data values of an existing plot: <code>p.XData = linspace(0,1,12)</code></li><li>rememeber that if you want to change the property of axes, then use gca.<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># create a figure containing 2 axes and 2 line plots </span></span><br><span class="line">fig = figure;</span><br><span class="line">ax1 = axes;</span><br><span class="line">l1 = plot(t,y1)</span><br><span class="line">axis tight;</span><br><span class="line">ax2 = axes(<span class="string">'Position'</span>,[.6 .6 .25 .25])</span><br><span class="line">l2 = plot(ax2,t,y2);</span><br></pre></td></tr></table></figure></li></ul></li><li><p>The Graphics Object Hierarchy</p><ul><li>All graphics objects are part of a hierarchy that starts with the root, the main display containing the MATLAB environment. You can make use of the graphics object hierarchy to obtain a specific graphics object after a plot is created.</li><li>besides using <code>gca</code> to get axes object, we can also get the axes graphics object using the <code>Children</code> property of the figure: <code>ax = fig.Children</code></li><li>The scatter and line plots are the children of the axes: <code>p = ax.Children</code></li><li><p>X Y axis are the children of axes: </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">xLab = ax.XLabel; </span><br><span class="line">xLab.FontName = <span class="string">'Garamond'</span>; % only change the font of x axis</span><br><span class="line">xAx = ax.XAxis; </span><br><span class="line">xAx.TickDirection = <span class="string">'out'</span>;</span><br><span class="line">xAx.FontName = <span class="string">'Courier'</span>;</span><br></pre></td></tr></table></figure></li><li><p>After ploting a bar chart with two or more bars, if you want to change the property of only one of the bars:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ax = gca;</span><br><span class="line">b = ax.Children;</span><br><span class="line">b(1).FaceColor = [1 0 0];</span><br><span class="line"></span><br><span class="line">xAx = ax.XAxis;</span><br><span class="line">xAx.FontWeight = <span class="string">'bold'</span>;</span><br></pre></td></tr></table></figure></li></ul></li><li><p>The following is a summary of this section:</p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">ds = datastore(<span class="string">'fuelEconomy2.txt'</span>)</span><br><span class="line">ds.ReadSize = 362;</span><br><span class="line">data = ds.read;</span><br><span class="line"> </span><br><span class="line">[gNum, gNames] = findgroups(data.NumCyl )</span><br><span class="line">avgMPG = splitapply(@mean, data.CombinedMPG, gNum)</span><br><span class="line"> </span><br><span class="line">b = bar(avgMPG);</span><br><span class="line">xlabel(<span class="string">'Number of cylinders'</span>)</span><br><span class="line">title(<span class="string">'Average MPG'</span>)</span><br><span class="line"></span><br><span class="line">% Customize the chart</span><br><span class="line">f = gcf;</span><br><span class="line">a = gca;</span><br><span class="line"></span><br><span class="line">f.Color = [0.81 0.87 0.9];</span><br><span class="line"></span><br><span class="line">a.Color = [0.81 0.87 0.9];</span><br><span class="line">a.Box = <span class="string">'off'</span>;</span><br><span class="line">a.YAxisLocation = <span class="string">'right'</span>;</span><br><span class="line">a.YGrid = <span class="string">'on'</span>;</span><br><span class="line">a.GridColor = [1 1 1];</span><br><span class="line">a.GridAlpha = 1;</span><br><span class="line">a.XTickLabel = gVal;</span><br><span class="line">a.YLim = [0 40];</span><br><span class="line"></span><br><span class="line">ax = a.XAxis;</span><br><span class="line">ax.TickDirection = <span class="string">'out'</span>;</span><br><span class="line"></span><br><span class="line">b.FaceColor = [0,0.31,0.42];</span><br><span class="line">b.BarWidth = 0.5;</span><br></pre></td></tr></table></figure></li></ul><h3 id="Images-and-3-D-Surface-Plots"><a href="#Images-and-3-D-Surface-Plots" class="headerlink" title="Images and 3-D Surface Plots"></a>Images and 3-D Surface Plots</h3><ul><li>Making grid<ul><li><code>meshgrid</code> function converts vectors of points into matrices that can represent a grid of points in the x-y plane: <code>[X,Y] = meshgrid(x,y)</code></li></ul></li><li>Interpolating Scattered Data<ul><li>Interpolating irregularly located data to a regular grid requires two steps: 1) Using the scattered data to create an interpolating function and 2) Evaluating the interpolant at desired locations. Use <code>griddata</code></li><li><code>griddata</code> function: the first three inputs represent the original data and the next two inputs contain the locations at which you would like to get the interpolated data: <code>zInterp = griddata(xOrig,yOrig,zOrig, xNew,yNew);</code></li></ul></li><li>Visualizing Surfaces:<ul><li><code>surf(X,Y,Z)</code></li><li>The color of the lines between the patches is determined by the <code>EdgeColor</code> property: <code>s.EdgeColor = &#39;interp&#39;</code></li></ul></li><li>Colormaps and Indexed Colors:<ul><li>The colors in a surface are determined by indexing into a color lookup table associated with the parent figure window, called a <code>colormap</code>.</li><li>Each point on a surface has a color data value. These values are stored in the <code>CData</code> property of the surface.</li><li>The color data value is mapped to a range of values. The range is set by the axes using the <code>CLim</code> property of the axes: <code>c = ax.CLim</code></li><li>The default colormap of a figure is called <code>parula</code>. You can modify this using the colormap function: <code>colormap(jet)</code></li></ul></li><li>Creating Indexed-Color Images<ul><li>Using <code>pcolor</code>: the <code>pcolor</code> function has the same syntax as <code>surf</code>. In fact, it actually creates a flat surface with <code>ZData</code> all set to 0 and <code>CData</code> set to Z.</li><li>The direction of the y-axis can be changed using the axis command: <code>axis xy</code> or <code>axis ij</code></li></ul></li></ul><h3 id="Import-Unstructured-Data"><a href="#Import-Unstructured-Data" class="headerlink" title="Import Unstructured Data"></a>Import Unstructured Data</h3><ul><li>Low-Level File I/O<ul><li><code>fopen</code> function: to open a file. This does not open the file in an editor but instead opens a connection between MATLAB and the file for reading and writing the data: <code>fi = fopen(&#39;economy.txt&#39;);</code></li><li>The returned value is a unique file identifier used to reference the open file.</li><li>Once the file is opened, you can use the file identifier to read data from the file. <code>fgetl</code> function takes the file identifier as input in order to read in the first line of code.: <code>fgetl(fi) ans = date, unrate, gdp, feddebt</code></li><li>Subsequent file reads will read in subsequent lines. The file position indicator moves to the beginning of the next line after each read. So when using <code>fgetl</code> the second time, it will return the second line of the file.</li><li>use <code>frewind</code> command to move the file position indicator back to the beginning of the file: <code>frewind(fi)</code></li><li>To close a file that has been opened by <code>fopen</code>, use the <code>fclose</code> function: <code>fclose(fi)</code></li><li>if a file was opened, but an identifier was not stored, use <code>fclose(&#39;all&#39;)</code> to close all opened files.</li></ul></li><li>Importing a Block of Formatted Data:<ul><li>You can read in data from a file with arbitrary formatting using the <code>textscan</code> function</li><li><code>textscan</code> function has two required inputs: a file identifier and a format specification string, e.g. <code>data = textscan(fid,&#39;%D%q%f%f%f&#39;)</code>, this is to convert the first unit of data to a date, <code>%D</code>, the second to a string, <code>%q</code>, and the next three units to double precision numbers, <code>%f</code>. This pattern is repeated indefinitely, so the sixth unit is a date, the seventh is a string and so on.</li><li>use cell indexing to extract the data from a column； <code>secondColumn = data{2}</code></li><li><code>%q</code> specifier can read both numbers and strings</li><li>Data is read from the file sequentially in blocks delimited by whitespace (by default) or a specific delimiting character (if provided): <code>data = textscan(fid,&#39;%D%f%q%C&#39;,&#39;Delimiter&#39;,&#39;\t&#39;)</code></li><li>the data will stop being read as soon as a match was not found, even though there were additional matches later in the file. Generally, textscan matches the format string pattern as many times as possible until a match is not found.</li><li>When a text file contains header lines, you can still import data by instructing <code>textscan</code> to skip a number of lines before attempting to read data: <code>data = textscan(fid,&#39;%D%f&#39;,&#39;HeaderLines&#39;,5);</code></li><li>To read only a specific number of lines from a file, specify the number using a <em>third input</em> to textscan. The following code will read five rows: <code>data = textscan(fid,&#39;%D%f%f&#39;,5);</code> Remember there will also be an indicator in textscan, so when it’s used the second time, it will not start from the beginning but the stop point from last time been called.</li><li>Reading Sections with Headers: </li></ul></li><li>Parsing Data in Text:<ul><li>use the <code>strfind</code> function to determine the index values where certain phrases or characters appear: <code>iv = strfind(&#39;cat,dog,goat&#39;,&#39;,&#39;)  iv = 4  8</code></li><li><code>strsplit</code> function can split up a line of text into individual strings in a cell array. This function will split on whitespace unless a delimiter is provided as an optional input value: <code>C = strsplit(&#39;cat dog goat&#39;)   C = &#39;cat&#39;    &#39;dog&#39;    &#39;goat&#39;</code></li><li><code>strcmp</code> function can find a word within a list of strings in a cell array. This function will compare values and return a logical array: <code>strcmp(C,&#39;goat&#39;)   ans = 0 0 1</code></li><li><code>deblank</code> function can remove trailing white spaces.<code>data = deblank(data)</code></li></ul></li><li>Processing Data in Blocks:<ul><li>You may need to programatically adjust your format specification string that you use to read in data with textscan. <code>repmat</code> function can help out: <code>formatSpecString = repmat(&#39;%q&#39;,1,5); formatSpecString = &#39;%q%q%q%q%q&#39;</code> <code>fstr = [&#39;%D&#39; repmat(&#39;%f&#39;,1,3)]    fstr = &#39;%D%f%f%f&#39;</code></li><li><code>feof</code> function can test if a file has reached the end. This can be used in a <code>while</code> loop to read in data until the end of the file: <code>while ~feof(fid)  ... end</code></li></ul></li></ul><h3 id="Review-of-data-types"><a href="#Review-of-data-types" class="headerlink" title="Review of data types"></a>Review of data types</h3><ul><li>Extract Data from a Table:<ul><li>use {} to extract the data as numeric format</li><li>use () to extract the data as table format</li></ul></li><li>Merge data:<ul><li><code>key</code> variables are the variables that are common to all sources and uniquely identify each observation, or row: <code>T12 = join(T1,T2)</code></li><li><code>innerjoin</code>: just select the observations that have key variables common to both tables: <code>C = innerjoin(A,B);</code></li><li><code>outerjoin</code>: include every single observation (row) from both tables: <code>C = outerjoin(A,B)</code></li><li>Set the <code>Mergekeys</code> property to <code>true</code> will return a table where the key values of A and B are merged into one variable in the C: <code>C = outerjoin(A,B,&#39;MergeKeys&#39;,true);</code></li></ul></li><li>Represent Dates and Times:<ul><li>To convert a cell array of strings of dates to a datetime array, use the <code>datetime</code> function: <code>dates = datetime(dates);</code></li><li><code>hour</code> can get the hour time of the date</li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3 id=&quot;Import-Tabular-Data&quot;&gt;&lt;a href=&quot;#Import-Tabular-Data&quot; class=&quot;headerlink&quot; title=&quot;Import Tabular Data&quot;&gt;&lt;/a&gt;Import Tabular Da
      
    
    </summary>
    
    
      <category term="Notes" scheme="http://tracyxinwang.site/blog/tags/Notes/"/>
    
      <category term="Matlab" scheme="http://tracyxinwang.site/blog/tags/Matlab/"/>
    
  </entry>
  
  <entry>
    <title>MIT6006 Lec11 Numerics I</title>
    <link href="http://tracyxinwang.site/blog/2018/11/26/MIT6006-Lec11/"/>
    <id>http://tracyxinwang.site/blog/2018/11/26/MIT6006-Lec11/</id>
    <published>2018-11-26T07:42:23.000Z</published>
    <updated>2018-11-26T05:37:37.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Irrationals"><a href="#Irrationals" class="headerlink" title="Irrationals"></a>Irrationals</h3><p><strong>Digression</strong><br>Catalan numbers:</p><ul><li>Set P of balanced parentheses strings are recursively defined as<ul><li>$λ ∈ P$ (λ is empty string)</li><li>If $α, β ∈ P$, then $(α)β ∈ P$</li></ul></li><li>Every nonempty balanced paren string can be obtained via Rule 2 from a unique α, β pair</li></ul><p><strong>Enumeration</strong></p><ul><li>$C_n$: number of balanced parentheses strings with exactly n pairs of parentheses $C_0 = 1$ empty string</li><li>$C_{n+1}$? Every string with n+1 pairs of parentheses can be obtained in a unique way via rule 2.</li><li>One paren pair comes explicitly from the rule.<ul><li>$k$ pairs from $α$, $n − k$ pairs from $β$</li><li>$C_{n+1} = \sum_{n=0}^n C_k \dot C_{n-k} \qquad n \ge 0$</li><li>$C_0=1 \quad C_1=C_0^2 = 1 \quad C_2=C_0C_1 + C_1C_0 = 2 \quad C_3 = \cdots = 5$</li></ul></li></ul><h3 id="Newton’s-Method"><a href="#Newton’s-Method" class="headerlink" title="Newton’s Method"></a>Newton’s Method</h3><ul><li>Find root of $f(x) = 0$ through successive approximation e.g., $f(x) = x^2 − a$</li><li>Tangent at $(x_i, f(x_i))$ is line $y = f(x_i)+ f’(x_i)·(x− x_i)$ where $f’(x_i)$ is the derivative. $x_{i+1}$ = intercept on x-axis<br>$$x_{i+1} = x_i - \frac{f(x_i)}{f’(x_i)}$$</li></ul><h3 id="High-precision-multiply"><a href="#High-precision-multiply" class="headerlink" title="High precision multiply"></a>High precision multiply</h3><p>Multiplying two n-digit numbers (radix r = 2, 10) $0 ≤ x, y &lt; r^n$<br>$$x = x_1 · r^{n/2} + x_0 \quad x_1 = high \; half$$  $$y = y_1 · r^{n/2} + y_0 \quad x_0 = low \; half$$ $$0 \le x_0, x_1 &lt; r^{n/2}$$ $$0 \le y_0, y_1 &lt; r^{n/2}$$ $$z = x·y = x_1y_1·r^{n} + (x_0·y_1 + x_1·y_0)r^{n/2} + x_0·y_0$$</p><ul><li>4 multiplications of half-sized ⇒ quadratic algorithm $θ(n^2)$ time</li></ul><p><strong>Karatsuba’s Method</strong><br>Let<br>$$z_0 = x_0·y_0$$ $$z_2 = x_1·y_1$$ $$z_1 = (x_0+x_1)·(y_0+y_1) - z_0 - z_2 = x_0y_1+x_1y_0$$ $$z = z_2·r^n +z_1·r^{n/2} +z_0$$<br>There are three multiplies in the above calculations.<br>$$T(n) = time \; to \; multiply \; two \; n-digit \; numbers<br>        = 3T(n/2) + θ(n)<br>        = θ(n^{log_23}) = θ(n^{1.5849625···})$$</p><p>A tutorial about Karatsuba’s method can be found <a href="https://courses.csail.mit.edu/6.006/spring11/exams/notes3-karatsuba" target="_blank" rel="noopener">here</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;Irrationals&quot;&gt;&lt;a href=&quot;#Irrationals&quot; class=&quot;headerlink&quot; title=&quot;Irrationals&quot;&gt;&lt;/a&gt;Irrationals&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Digression&lt;/strong&gt;&lt;br&gt;Cat
      
    
    </summary>
    
    
      <category term="Algorithm" scheme="http://tracyxinwang.site/blog/tags/Algorithm/"/>
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
  </entry>
  
  <entry>
    <title>Higher Level Programming Technique using Matlab</title>
    <link href="http://tracyxinwang.site/blog/2018/11/24/Matlab-technique/"/>
    <id>http://tracyxinwang.site/blog/2018/11/24/Matlab-technique/</id>
    <published>2018-11-23T23:39:15.000Z</published>
    <updated>2018-11-26T06:06:22.000Z</updated>
    
    <content type="html"><![CDATA[<p>This is a note taken from MATLAB online self-paced course.</p><h3 id="Utilizing-Development-Tools"><a href="#Utilizing-Development-Tools" class="headerlink" title="Utilizing Development Tools"></a>Utilizing Development Tools</h3><p><strong>Directory reports</strong></p><ul><li>Commonly used folder reports in MATLAB<ul><li>Code Analyzer report: displays code analyzer findings for each code file</li><li>Dependency report: shows the function dependencies of the code files in the current folder</li><li>Help report: provides each code file’s help text in a single report</li><li>TODO/FIXME report: lists the instances of “TODO”, “FIXME”, or other custom text that exist in comments</li></ul></li><li>To run these reports, navigate to the desired folder in MATLAB and then use the <code>Current Folder Actions</code> menu.</li></ul><p><strong>Code Analyzer</strong></p><ul><li>出现红色波浪线(即warning)时，右键单击，就有显示的帮助fix的选项</li><li>如果没有fix，并且你觉得没有问题时，就可以右键选择”Suppress XXX”, 这时MATLAB会帮助你在后面加上一个注释 <code>#Ok&lt;AGROW&gt;</code>  来表示没有问题</li></ul><p><strong>MATLAB debugger</strong></p><ul><li>use breakpoint </li><li>run MATLAB with <code>Pause on Errors</code> can help relief the work to find where is the bug.</li></ul><p><strong>Execution time measurements</strong></p><ul><li><code>tic</code> and <code>toc</code> functions can help measure the execution time of MATLAB code<ul><li>Because tic and toc measure clock time, your computer’s background tasks can cause the timing measurements to vary slightly. Therefore, tic and toc may give different results for consecutive timings of the same code.</li></ul></li><li>Average several running times is a good idea:  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">tic; x = rand(1000); t(1) = toc;</span><br><span class="line">tic; x = rand(1000); t(2) = toc;</span><br><span class="line">tic; x = rand(1000); t(3) = toc;</span><br><span class="line">mean(t)</span><br><span class="line">    ans =</span><br><span class="line">        0.0305</span><br></pre></td></tr></table></figure></li></ul><p><strong>Code profiler</strong></p><ul><li>To know which parts of the code take the most time.</li><li>Click <code>Run and Time</code> opens <code>MATLAB Profiler</code> window</li><li>Enter a line of code in the edit box and then press Enter or click the <code>Start Profiling</code> button.</li><li>Note: The profiler report does not provide information on each individual call to a function, but rather only information on the conglomeration of all calls to a function.</li></ul><h3 id="Createing-Robust-Application"><a href="#Createing-Robust-Application" class="headerlink" title="Createing Robust Application"></a>Createing Robust Application</h3><p><strong>Custom Warnings and Errors</strong></p><ul><li>use <code>warning</code> and <code>error</code> to customize</li><li>Warnings and errors both contain two components: an <em>identifier</em> and a <em>displayed</em> message</li><li>Identifier:<ul><li>Hidden from the user</li><li>At least contains two components and separated by ‘:’</li><li>First component is typically the name of the application</li><li>Second component identifies the condition for the error or the warning</li></ul></li><li>Error or warning message<ul><li>is displayed to the user</li><li>Errors are displayed in red and warnings in orange</li></ul></li><li>e.g. <code>warning(&#39;MyProject:ValueOutOfRange&#39;,&#39;The value must be between 1 and 10.&#39;)</code></li></ul><p><strong>Validating Function Inputs</strong></p><ul><li>MATLAB provides <a href="https://au.mathworks.com/help/matlab/ref/is.html" target="_blank" rel="noopener">several</a> functions for validating the attributes of a variable.</li><li>Validating Multiple Attributes: <ul><li><code>validateattributes(name,class,attributes)</code></li><li><code>name</code>: the variable name</li><li><code>class</code>: should be a cell array containing strings, e.g: {‘double’}, {‘cell’}, {‘numeric’}, etc.</li><li><code>attributes</code>: should be a cell array containing the list of attributes and their expected values, e.g.: {‘vector’}, {‘nonempty’}, {‘scalar’,’&gt;’,10}, etc.</li><li>e.g.: checks that the data passed into the variable r is a numeric scalar greater than 0: <code>validateattributes(&#39;r&#39;,{&#39;numeric&#39;},{&#39;scalar&#39;,&#39;&gt;=&#39;,0})</code></li></ul></li><li><p>You can also provide additional flexibility to the user by converting the input provided by the user into something that is acceptable to the program.</p><ul><li>e.g. calling the following by <code>int = calculateInterest(500,2,&#39;2%&#39;)</code>, and return <code>int = 20</code>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">function</span> interest = calculateInterest(p,n,r)</span><br><span class="line">    <span class="keyword">if</span> ischar(r)</span><br><span class="line">        r = str2num(r(1:end-1));</span><br><span class="line">    end</span><br><span class="line">    interest = p*n*r/100;</span><br></pre></td></tr></table></figure></li></ul></li><li><p><code>numel</code> can be used to check the number of elements in a array</p></li></ul><p><strong>Setting Default Input Values</strong></p><ul><li><em>Missing input</em>: use function <code>nargin</code> to check if all the inputs were provided in the function call<ul><li><code>nargin</code> returns the number of inputs that were passed</li></ul></li><li><em>Empty Input</em>: <ul><li>use an empty array <code>[]</code> to skip specifying some inputs</li><li>usie function <code>isempty</code> to check if the input is given. If it is empty, we can assign a default value.</li></ul></li></ul><p>The program flow within the function goes as follows now:</p><ol><li>Are all inputs provided?(nargin) No -&gt; Set default values</li><li>Is any input empty?(isempty) No -&gt; Set default values</li></ol><p><strong>Creating Flexible Interfaces</strong></p><ul><li>use the property name-value pairs in the function syntax to allows the user to specify only a subset of the line attributes in <em>any order</em>.</li><li>Every input argument in the function call is mapped to a single variable in the function definition. However, you can map multiple input arguments to a single input variable <code>varargin</code> in the function definition.</li><li>e.g. <code>function analyzeAndPlot(x,y,varargin)</code> can be called as <code>analyzeAndPlot(time,position,&#39;LineWidth&#39;,3,&#39;Color&#39;,&#39;r&#39;)</code> </li><li><code>varargin</code> is a cell array. In the above example, starting with the third input, each input is assigned to a separate cell of varargin.</li><li>The contents of varargin can be passed to other MATLAB functions using like <code>varargin{:}</code></li><li><code>varargin</code> is the last input in the function declaration.</li></ul><p><strong>Try-Catch: Unexpected Errors</strong></p><ul><li>The MException Object: <ul><li>Error information in MATLAB is stored in a specialized datatype called an MException object.</li><li>can access the MException object for the last error that occurred using the command: <code>MException.last</code></li></ul></li><li><p>The try-catch Construct:</p><ul><li><p>This special programming construct attempts to run the code within the try block. If an error condition occurs, then the execution is interrupted and switched immediately into the catch block.</p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">try</span><br><span class="line">    % Attempt code</span><br><span class="line">catch mexc</span><br><span class="line">    % Backup <span class="keyword">case</span> – something went wrong</span><br><span class="line">    % An MException object called mexc now exists</span><br><span class="line">end</span><br></pre></td></tr></table></figure></li><li><p>You can provide the name of a variable after the keyword catch (<code>mexc</code> in the above example). </p></li><li>If an error is generated in the try block the program can then proceed in one of the following ways in the catch block:<ul><li>Try to recover from the error and continue execution.</li><li>Provide a customized error message and halt the execution.</li></ul></li></ul></li></ul><h3 id="Review-of-Data-Type"><a href="#Review-of-Data-Type" class="headerlink" title="Review of Data Type"></a>Review of Data Type</h3><ul><li><code>whos</code>: show variables in the workspace and compare their properties.</li></ul><p><strong>Table</strong>:</p><ul><li>Create a table: <ul><li>You can use the table function with the workspace variables as inputs to create a table.</li><li><code>tableName = table(variable1,variable2,variable3,&#39;VariableNames&#39;,{&#39;A&#39;,&#39;B&#39;,&#39;C&#39;})</code></li></ul></li><li>Combine tables: <code>tableC = [tableA tableB]</code></li><li>Extracting <em>portions</em> of a table: <ul><li>by using column or row number: <code>tableC = tableA(:,1:2)</code></li><li>by using variable name in single quotes: <code>tableC = tableA(:,&#39;FirstVariableName&#39;</code> or <code>tableC = tableA(:,{&#39;Var1&#39;,&#39;Var5&#39;})</code></li><li>mixied indexing: <code>tableC = tableA([1 3 5],{&#39;Var1&#39;,&#39;Var5&#39;})</code></li></ul></li><li>Extracting <em>Data</em> from a Table<ul><li>dot notation: <code>data = tableName.VariableName</code></li><li>Add new variable to a table: <code>table.NewVariable = [5 27 14]&#39;</code></li><li>Curly Braces: <code>na1 = patientData{:,{&#39;Name&#39;,&#39;Age&#39;}}</code> or <code>patientData.Name{3} = &#39;NewName&#39;</code> (可直接赋值：<code>patientData{[1 4],&#39;HeartRate&#39;} = [80 ; 75]</code>)</li></ul></li><li>use <code>tablename.Properties.VariableNames</code> to get the variabe names in a table or index into the VariableNames field to change a variable name: <code>myTable.Properties.VariableNames{2} = &#39;NewName&#39;</code></li></ul><p><strong>Cell Array</strong></p><ul><li>using <em>parentheses</em>, returns a subset cell array: <code>currencies(1)</code> -&gt; <code>ans={&#39;Euro&#39;}</code> (提取出来的还是cell)</li><li>using <em>curly braces</em> will return a string: <code>currencies{1}</code> -&gt; <code>ans=&#39;Euro&#39;</code> (提取出来的 cell 本身的类型，即自身的内容)</li><li>using <em>curly braces</em> can also replace or add a content: <code>currencies{1,3} = &#39;Yen&#39;</code></li><li>remove an element from an array, use parentheses and set the result to an empty array, <code>ezone(2) = [];</code></li></ul><p><strong>Structures</strong></p><ul><li>Structures can contain data of dissimilar types and sizes in one variable. Use dot notation to add a field to a structure.</li></ul><p><strong>Function Handles</strong></p><ul><li>You can use a function handle to store a command as a variable, which can then be passed as an input to a function.</li><li>construct a function handle by preceding the function name with an @ sign: <code>h = @sin</code></li><li>call the function handle as the same way to call the function directly: <code>h(0)</code></li><li>For functions requires an input, give the function handle (variable) as an input: <code>integral(h,0,pi)</code> , <code>integral(@log,1,2)</code></li></ul><p><strong>Anonymous Functions</strong></p><ul><li>use anonymous functions to create simple functions without creating a code file. That is to say, create a function directly in command line with only input variables.</li><li>syntax: <code>variableName = @(arg1,...) functionDefinition</code>, e.g. <code>f = @(x,y) sin(x) + y;</code></li><li><em>variableName</em> is the Function Handle</li><li>Call the function just need to give the input into the handle: <code>f(pi/6,0.5)</code></li></ul><h3 id="Structing-Data"><a href="#Structing-Data" class="headerlink" title="Structing Data"></a>Structing Data</h3><p><strong>Structuring Data Considerations</strong></p><ul><li>Data that contains values from a finite set of categories, may be converted to categorical data using the <code>categorical</code> function: <code>gender = {&#39;M&#39; &#39;M&#39; &#39;F&#39; &#39;M&#39; &#39;F&#39; &#39;F&#39;}; gender = categorical(gender);</code></li><li>use <code>cat</code> to concatenate the output: <code>allSums = cat(1,groupSum{:})</code></li></ul><p><strong>Extracting multiple elements</strong></p><p><strong>Applying scalar functions to data</strong></p><ul><li><p>use <code>cellfun</code> function to find the group attributes of each cell:</p><ul><li><code>cellfun</code> function applies the specified function to each element of the cell.</li><li>the specified function is called once per cell element.</li><li>The specified function is typically a function which accepts a single input and produces a single output. e.g.  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">groups = </span><br><span class="line">    [3x1 double]    [2x1 double]    [4x1 double]</span><br><span class="line">cellfunc(@mean, groups)</span><br><span class="line">    ans = 3.03  4.30    5.05</span><br></pre></td></tr></table></figure></li></ul></li><li><p>use <code>structfun</code> to apply the same to a structure, this returns a scalar for each cell</p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">groups = </span><br><span class="line">    group1: [3x1 double]</span><br><span class="line">    group2: [2x1 double]</span><br><span class="line">    group3: [4x1 double]</span><br><span class="line">    structfun(@mean,groups)</span><br><span class="line">        ans = 3.03    4.30    5.05</span><br></pre></td></tr></table></figure></li><li><p>Nonscalar output</p><ul><li>You may attempt to use <code>cellfun</code> or structfun with functions that return nonscalar outputs, such as sort, return an array.</li><li><p>To handle this situation, you can specify that the outputs will be different sizes using the <code>UniformOutput</code> property. This returns a nonscalar for each cell. e.g.</p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">groups = </span><br><span class="line">    [3x1 double]    [2x1 double]    [4x1 double]</span><br><span class="line">cellfun(@sort,groups,<span class="string">'UniformOutput'</span>,<span class="literal">false</span>)</span><br><span class="line">    ans = </span><br><span class="line">        [3x1 double]    [2x1 double]    [4x1 double]</span><br></pre></td></tr></table></figure></li><li><p>can also use anonymous functions as inputs to <code>cellfun</code>: <code>cellfun( @(x) mean(x.price), c)</code></p></li></ul></li></ul><p><strong>Converting data types</strong></p><ul><li><code>num2cell</code>: converts an m-by-n numeric matrix into an m-by-n cell array, where each cell contains a scalar value</li><li><code>mat2cell</code>: converts a numeric matrix into a cell array where the cells contain matrices of various sizes. <ul><li>the second input indicates how to subdivide the rows</li><li>the third input indicates how to subdivide the columns</li><li>e.g. <code>c = mat2cell(r,[2,4],[2,1])</code> means to convert the matrix r to four matrix cell, each cell has the matrix of dimension: 2x2, 2x1, 4x2, 4x1</li></ul></li><li><code>cell2struct</code>: converts a cell array into a structure.<ul><li>e.g. 4-by-2 cell array <code>c</code> is converted into a 2 element structure, <code>s</code>, with 4 fields: <code>s = cell2struct(c,{&#39;fA&#39;,&#39;fB&#39;,&#39;fC&#39;,&#39;fD&#39;},1)</code></li><li>first input: the cell array</li><li>second input: a cell of strings containing the field names</li><li>third input: the dimension on which the fields are named. (i.e. row or column)</li></ul></li><li><code>cell2table</code>: converts a cell array into a table</li><li><em>character array</em>:  <code>cellstr</code> converts a list of strings to a cell array with the trailing spaces removed.</li></ul><h3 id="Structing-Code"><a href="#Structing-Code" class="headerlink" title="Structing Code"></a>Structing Code</h3><p><strong>Private Functions</strong></p><ul><li>To prevent your application’s internal functions from being accessible outside the application, you can place them in a folder named <em>private</em></li><li>Functions in a private folder can only be called by<ul><li>Functions within the parent folder</li><li>Other functions within the private folder</li></ul></li><li>private functions can call any other functions on the MATLAB path.</li><li><em>private</em> folders cannot be added to the MATLAB path. Therefore, functions within them generally cannot be called from the command line unless the MATLAB current folder is the private folder itself.</li></ul><p><strong>Local Functions</strong></p><ul><li>To create local functions, place them below the primary function in the same code file</li><li>When using local functions<ul><li>The primary function can call the local functions</li><li>The local functions can call other local functions and the primary function</li><li>External code (outside of the code file) can call the primary function, but not the local functions</li></ul></li><li>As with functions in separate files, local functions <em>have their own workspaces</em></li><li>When creating local functions, you may or may not choose to use the <code>end</code> keyword for each function. However, whichever you choose, you must stay consistent. Some local functions have <code>end</code> while others don’t is invalid in MATLAB </li></ul><p><strong>Change the Function Interface with Anonymous Functions</strong></p><ul><li>One way to modify a function’s interface (without modifying the function itself) is to use a wrapper function.</li><li><p>Functions with multiple inputs may not be used directly with other functions like <code>fzero</code>, <code>ode45</code>, using anonymous functions can help this:</p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">function</span> y = myquad(x,a,b,c)</span><br><span class="line">    y = a*x^2 + b*x + c;</span><br><span class="line"></span><br><span class="line">a = 1; b = 5; c = -10;</span><br><span class="line"></span><br><span class="line">f = @(x) myquad(x,a,b,c)</span><br><span class="line"></span><br><span class="line">fzero(f,3)</span><br></pre></td></tr></table></figure></li><li><p>And the input variables can be the variables in the workspace.</p></li></ul><h3 id="Performance-and-Memory"><a href="#Performance-and-Memory" class="headerlink" title="Performance and Memory"></a>Performance and Memory</h3><p><strong>Datatypes and Memory</strong></p><ul><li>can determine the memory used by a variable by choosing to display the <code>&#39;Bytes&#39;</code> column in MATLAB workspace. </li><li>Container variables (tables, cell arrays, and structure arrays) require <em>overhead</em> in addition to the data they store. <ul><li>This additional memory is used to store information about the contents of the variable. </li><li>The amount of the overhead depends on the size of the variable.</li><li>Each <code>cell</code> of a cell array requires memory overhead.</li><li>A <code>table</code> requires <strong>minimal</strong> overhead for each variable and for storing table properties.</li><li>A <code>structure</code> requires 64 bytes of overhead for each field name. If a structure array has more than one element, each element will require additional overhead.</li></ul></li><li>Special Variable Types: MATLAB has datatypes that are designed to be used with data having specific characteristics. These datatypes can significantly reduce the memory consumption.<ul><li><code>Categorical arrays</code> can be used to store a list of text labels or strings containing many repeated entries.</li><li>The memory saved increases as the size of the list and the number of the repeated entries increase.</li><li><code>Datetime arrays</code> can be used to store a list of dates. They also provide memory saving over a cell array storing individual date strings.</li></ul></li></ul><p><strong>Preallocation</strong></p><ul><li>Preallocating Numeric Arrays:<ul><li>can use the functions <code>zeros</code> and <code>ones</code> to preallocate numeric arrays</li><li>another way to preallocate an array is to assign a value to the last element of the array.</li></ul></li><li>Preallocating Cells and Structures<br>:<ul><li><strong>benefit when a for loop used</strong>, since frequently change the size will consume lots of time</li><li>Preallocating a cell array or a structure array assigns space for the containers themselves, not the contents</li><li>This means that preallocation of the container variables is most beneficial when the container array itself is large, regardless of the size of the contents of the individual containers.</li><li>using <code>cell</code> to preallocate a cell array: <code>C = cell(1,4)</code> </li><li>preallocate a structure array, start by defining the last element of the array. MATLAB will automatically replicate the field names to all of the preceding elements in the array. <code>S(5) = struct(&#39;field1&#39;,6,&#39;field2&#39;,7)</code></li></ul></li></ul><p><strong>Vectorization</strong></p><ul><li>a subset of vectorized functions in MATLAB: <code>diff</code>, <code>prod</code>, <code>cumprod</code>, <code>cumsum</code>, <code>union</code>,<code>setdiff</code>,<code>setxor</code> etc.</li></ul><p><strong>Binary Singleton Expansion (bsxfun)</strong> </p><ul><li>Binary: the function should accept two inputs</li><li>Scalar: the function should return a scalar output  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">x = [4;5;6]</span><br><span class="line">y = [1 2 3; 4 5 6; 7 8 9];</span><br><span class="line">bsxfun(@gt,x,y)</span><br><span class="line">ans =</span><br><span class="line">    1   1   1</span><br><span class="line">    1   0   0</span><br><span class="line">    0   0   0</span><br></pre></td></tr></table></figure></li></ul><p><strong>Memory Usage</strong></p><ul><li>use the <code>memory</code> command to display information about the memory</li><li>or with output structures: <code>[user,sys] = memory</code></li><li>The output structures have the following information:<ul><li><em>Total System Memory</em>(sys.SystemMemory.Available): Physical RAM available + Page File (or swap) available. </li><li><em>MATLAB Process Virtual Memory</em>(sys.VirtualAddressSpace): Total and available memory associated with the whole MATLAB process. It is limited by processor architecture and operating system.</li><li><em>MATLAB Workspace</em>(user.MemAvailableAllArrays) and <em>Largest block</em>(user.MaxPossibleArrayBytes): The effective workspace available for data is the MATLAB process virtual address space minus system DLLs, Java™ (JVM), MATLAB.exe and DLLs. The largest block (for numerical arrays) is affected by fragmentation, third-party DLLs , and other running processes.</li></ul></li></ul><p><strong>Copy-on-Write Behavior</strong></p><ul><li>also named lazy-copying, ensures that no additional memory is assigned to an input variable until it is modified within the function.</li></ul><p><strong>In-Place Optimizations</strong></p><ul><li>declare and call a function using the same variable to define the input and output arguments: <code>x=myFun(x)</code></li></ul><p><strong>Nested Functions</strong></p><ul><li>a nested function is also used to organize several functions in a single function file and it often acts as a helper function to the primary function.</li><li>However, nested functions exihibit one additional feature: They allow functions in the file to <em>share workspace variables</em>.</li><li>To nest a function inside another function, the extents of the functions must be marked explicitly by using the keywords <em>function</em> and <em>end</em>.</li><li><p>When to use a nested function?</p><ul><li>Sharing large data: Auxiliary functions that are intended to modify the data of the parent function can be written as nested functions.</li><li><p>In the following example, even though <code>x</code> is not explicitly passed to the nested function <code>movingAverage</code>, the nested function can access and modify <code>x</code> from the workspace of the primary function <code>analyzeData</code>:</p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">function</span> y = analyzeData(x)</span><br><span class="line">movingAverage(3);</span><br><span class="line">...</span><br><span class="line"><span class="keyword">function</span> movingAverage(n)</span><br><span class="line">window = ones(1,n)/n;</span><br><span class="line">x = conv(x,window);</span><br><span class="line">end</span><br><span class="line">end</span><br></pre></td></tr></table></figure></li><li><p>Using a function which requires specific function <em>signature</em>: Some functions in MATLAB, such as fzero, require you to pass handles to your own functions as inputs.</p></li></ul></li></ul><h3 id="Verifying-Application-Behavior"><a href="#Verifying-Application-Behavior" class="headerlink" title="Verifying Application Behavior"></a>Verifying Application Behavior</h3><p><strong>What Is a Test?</strong></p><ul><li>A test allows you to verify that your code works correctly by testing specific inputs and validating that expected values have been created.</li><li>A simple test should:<ul><li>Set up the circumstances under which you want to test the application.</li><li>Call the application.</li><li>Define the expected value.</li><li>Compare the actual and expected behaviors.</li></ul></li></ul><p><strong>Test Response</strong></p><ul><li>A formal testing framework should produce either no response, to indicate that the test was passed, or an error, to indicate failure.</li><li><code>assert</code> function takes a logical input (or an expression that evaluates to a logical result), and generates an error only if the input is false.  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt; assert(<span class="literal">true</span>)</span><br><span class="line">    <span class="comment"># (No response)</span></span><br><span class="line">&gt;&gt; assert(<span class="literal">false</span>)</span><br><span class="line">Assertion failed.</span><br></pre></td></tr></table></figure></li></ul><p><strong>Writing and Running a Test Script</strong></p><ul><li>A test script is simply a MATLAB script that is divided into sections and uses the assert function.</li><li>Code sections allow you to compile multiple tests into a single file. The section header describes the test. Use <code>%% Test XXX</code> to seperate each section.</li><li>Each section of a test script maintains its own workspace. Thus, in each section, you must define all needed variables.</li><li>to run each and every section of a test script, use the <code>runtests</code> function: <code>result = runtests(&#39;myTests&#39;);</code><ul><li>If run the test script as a regular script, any failed tests will produce an error, halting execution. Thus, the remaining tests will not be performed. </li><li>Whereas, the runtests function will move to the next section of the script after an error is encountered so that all the tests run.</li></ul></li><li>Output variable of <code>runtests</code> is a specialized MATLAB object designed to hold test result information.</li></ul><p><strong>Avoiding Bugs in Comparisons</strong></p><ul><li><em>Numerical Precision</em>: use a tolerance value for equality comparisons: <code>abs(x-y) &lt; 1e-6</code></li></ul><p><strong>Writing Test Functions</strong></p><ul><li><p>Creating a Test Function: A test function follows a specific template:</p><ul><li>note: the test local function name should be ended with <code>Test</code><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">function</span> <span class="built_in">test</span> = mainFunctionName</span><br><span class="line">    <span class="built_in">test</span> = functiontests(localfunctions);</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> testName1(testcase)</span><br><span class="line">    % code <span class="keyword">for</span> <span class="built_in">test</span> 1</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> testName2(testcase)</span><br><span class="line">    % code <span class="keyword">for</span> <span class="built_in">test</span> 2</span><br><span class="line">end</span><br></pre></td></tr></table></figure></li></ul></li><li><p>For each test:</p><ul><li>Create a local function.</li><li>Name each test function starting or ending with the word “test.”</li><li>Pass a single input variable.</li></ul></li></ul><p><strong>Verifying Behavior</strong></p><ul><li>to verify that an application behaves in a certain way, such as generating an error or not generating warnings under specific conditions</li><li><em>Verification functions</em>: <code>verifyClass</code>, <code>verifyError</code>, <code>verifyWarningFree</code>, etc.</li><li>The local test functions have a single input, named <code>testcase</code> in the example below. Your test code should use it as the first input to the verification function.  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">function</span> posRootTest(testcase)</span><br><span class="line">x = linspace(0,pi);</span><br><span class="line">y = sqrt(x);</span><br><span class="line">verifyTrue(testcase,isreal(y))</span><br><span class="line">end</span><br></pre></td></tr></table></figure></li></ul><p><strong>Passing Commands as Inputs</strong><br>    <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">function</span> testStringInput(testcase)</span><br><span class="line">    errorMessage = <span class="string">'MATLAB:UndefinedFunction'</span>;</span><br><span class="line">    cmd = @()sqrt(<span class="string">'ZureyBug'</span>);</span><br><span class="line">    verifyError(testcase,cmd,errorMessage)</span><br><span class="line">end</span><br></pre></td></tr></table></figure></p><p><strong>Adding Pre- and Post-Test Tasks</strong></p><ul><li>It can be useful to define tasks that should be performed immediately before and after running the actual tests defined in your test code. e.g., if you keep the test code and the application in separate locations, the location of the application code can be added to the MATLAB path for the tests to successfully run.</li><li><p>you can add pre- and post-test tasks to your testing function by adding functions with the special names <code>setupOnce</code> and <code>teardownOnce</code> which have the same signature as the other test functions.</p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">function</span> setupOnce(testCase)</span><br><span class="line">    % save the name of the application folder you will add</span><br><span class="line">    % to the TestData structure</span><br><span class="line">    testCase.TestData.appDir = fullfile(<span class="string">'C:'</span>,<span class="string">'class'</span>,<span class="string">'work'</span>,<span class="string">'ApplicationDirectory'</span>);</span><br><span class="line"></span><br><span class="line">    % add the application folder to the path <span class="keyword">for</span> testing</span><br><span class="line">    addpath(testCase.TestData.appDir)</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> teardownOnce(testCase)</span><br><span class="line">    % removes the added path</span><br><span class="line">    rmpath(testCase.TestData.appDir)</span><br><span class="line">end</span><br></pre></td></tr></table></figure></li><li><p>In the above example, the test code and the application code are in separate locations. You will use the application folder in the teardown function. So, rather than redefining it, you can save it in the testCase variable to the TestData property. This property is a structure variable to which you can add fields as you desire. Any fields that are added to this variable are accessible by all functions in the test function file.</p></li><li>remove the directory from the path in the teardownOnce function. See that the variable you previously defined, appDir, is accessible through testCase.TestData. Note that the structure TestData is named automatically, whereas you can name the function input, testCase in this example, whatever you want.</li></ul><h3 id="Creating-a-Toolbox"><a href="#Creating-a-Toolbox" class="headerlink" title="Creating a Toolbox"></a>Creating a Toolbox</h3><p><strong>Creating a Toolbox</strong></p><ol><li>Open the Package Toolbox dialog: Home - Add-Ons - Package ToolBox</li><li>Specify the folder where your application is stored: need to ensure that all the required code files for the application are on the MATLAB path prior to specifying the folder.</li><li>Fill in toolbox information: like author name, company</li><li>Package the toolbox: <ul><li>will create a <code>.mltbx</code> file that contains all the dependencies and path information needed for you to share the application.</li><li>a <code>.prj</code> file is also created. This saves the project information that you just entered in the Packager window. This is useful if you later need to repackage your application after making changes to it.</li></ul></li></ol><p><strong>Installing a Toolbox</strong></p><ul><li>by double-clicking the <code>.mltbx</code> file, this will start the installation process, which adds the files to the local installation of MATLAB</li><li>The files are added to the MATLAB Add-Ons folder, and the proper folders are added to the path.</li><li>The location of the MATLAB Add-Ons folder is set in the preferences</li><li>to uninstall a toolbox, open the Add-On Manager</li></ul><p><strong>Including Custom Documentation (manual) in the Toolbox</strong></p><ul><li>To add documentation, first create an <code>info.xml</code> file at the <em>root</em> level of the toolbox folder. Use a standard template (which can be found in the documentation) to create the initial file.</li><li>modify your toolbox’s name and specify the folder where you will store the documentation. In <code>&lt;name&gt;</code> and <code>&lt;help_location&gt;</code> part in the xml file</li><li>Create the <code>doc</code> folder at the root level of your toolbox, thus matching where you specified it in info.xml.</li><li>Create a <code>helptoc.xml</code> file in the doc folder. Again, use a template found in the documentation as a starting point.</li><li>Specify the content structure of the documentation. This defines the pages that are listed in your documentation’s content tree (typically shown on the left side of the documentation).</li><li>Specify the content structure of your documentation. This defines the pages that are listed in your documentation’s content tree (typically shown on the left side of the documentation).</li><li>In the <code>doc</code> folder, create the HTML files that you specified in the helptoc.xml file. Note that you can use any tool you’d like to generate the HTML, such as hand-writing it or even using the MATLAB publish features.</li><li>Then, the document is created<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># template info.xml</span></span><br><span class="line">&lt;productinfo</span><br><span class="line">    xmlns:xsi=<span class="string">"http://www.w3.org/2001/XMLSchema-instance"</span></span><br><span class="line">    xsi:noNamespaceSchemaLocation=<span class="string">"optional"</span>&gt;</span><br><span class="line">    &lt;?xml-stylesheet <span class="built_in">type</span>=<span class="string">"text/xsl"</span> href=<span class="string">"optional"</span>?&gt;</span><br><span class="line">    &lt;matlabrelease&gt;2014b&lt;/matlabrelease&gt;</span><br><span class="line">    &lt;name&gt;My Toolbox&lt;/name&gt;</span><br><span class="line">    &lt;<span class="built_in">type</span>&gt;toolbox&lt;/<span class="built_in">type</span>&gt;</span><br><span class="line">    &lt;icon&gt;&lt;/icon&gt;</span><br><span class="line">    &lt;help_location&gt;doc&lt;/help_location&gt;</span><br><span class="line">    &lt;help_contents_icon&gt;<span class="variable">$toolbox</span>/matlab/icons/bookicon.gif&lt;/help_contents_icon&gt;</span><br><span class="line">&lt;/productinfo&gt;</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># template helpdoc.xml</span></span><br><span class="line">&lt;?xml version=<span class="string">'1.0'</span> encoding=<span class="string">"utf-8"</span>?&gt;</span><br><span class="line">&lt;toc version=<span class="string">"2.0"</span>&gt;</span><br><span class="line">    &lt;tocitem target=<span class="string">"mainPage.html"</span>&gt;Main Page</span><br><span class="line">        &lt;tocitem image=<span class="string">"HelpIcon.FUNCTION"</span>&gt;Functions</span><br><span class="line">            &lt;tocitem target=<span class="string">"fcnPage1.html"</span>&gt;Fcn 1&lt;/tocitem&gt;</span><br><span class="line">            &lt;tocitem target=<span class="string">"fcnPage2.html"</span>&gt;Fcn 2&lt;/tocitem&gt;</span><br><span class="line">        &lt;/tocitem&gt;</span><br><span class="line">    &lt;/tocitem&gt;</span><br><span class="line">&lt;/toc&gt;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;This is a note taken from MATLAB online self-paced course.&lt;/p&gt;
&lt;h3 id=&quot;Utilizing-Development-Tools&quot;&gt;&lt;a href=&quot;#Utilizing-Development-Tools
      
    
    </summary>
    
    
      <category term="Notes" scheme="http://tracyxinwang.site/blog/tags/Notes/"/>
    
      <category term="Matlab" scheme="http://tracyxinwang.site/blog/tags/Matlab/"/>
    
  </entry>
  
  <entry>
    <title>ODE in Matlab</title>
    <link href="http://tracyxinwang.site/blog/2018/11/23/Matlab-ODE/"/>
    <id>http://tracyxinwang.site/blog/2018/11/23/Matlab-ODE/</id>
    <published>2018-11-22T23:39:15.000Z</published>
    <updated>2018-11-26T05:24:37.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Basic"><a href="#Basic" class="headerlink" title="Basic"></a>Basic</h3><p>[tSol, ySol] = ode45(@odefun, tRange, y0)</p><ul><li><em>@odefun</em>: A function handle to the derivative function, need to specify</li><li><em>tRange</em>: the time range to calculate the differential function</li><li><em>y0</em>: the initial value</li><li><em>tSol</em>: indepent variable, two element vector containing the initial and final values</li><li><em>ySol</em>: dependent variable, the initial value of the dependent variable</li></ul><p>ODE general solution structure:</p><ul><li>Call ode45 with a single output variable: <code>sol = ode45(@odefun,tRange,y0)</code></li><li>use the deval function to evaluate the solution at any point in the interval tRange by passing the solution structure and the point to deval: <code>y2 = deval(sol,t)</code> t is the time point, can be a single time or an array of time</li><li>use <code>fzero</code> to find when sol evaluates to a value(e.g. 336): <code>tTermVel = fzero(@(t) deval(sol,t) - 336, 300)</code></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">tRange = [0 120];</span><br><span class="line">V0 = 6000;</span><br><span class="line">[tSol vSol] = ode45(@fallingbody, tRange, V0);</span><br><span class="line"></span><br><span class="line">plot(tSol,vSol)</span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> dvdt = fallingbody(t, v)</span><br><span class="line">    g = 3.72;</span><br><span class="line">    D = 3.3e-5;</span><br><span class="line">    dvdt = g - D*v^2;</span><br><span class="line">end</span><br></pre></td></tr></table></figure><h3 id="Solve-system-of-ODE"><a href="#Solve-system-of-ODE" class="headerlink" title="Solve system of ODE"></a>Solve system of ODE</h3><p>Writing Vector-Valued ODE functions</p><p>Creating a vector-valued ODE function can be broken down into three parts: </p><ul><li>extracting the individual elements from the vector of dependent variables</li><li>implementing the derivative functions for the dependent variables</li><li>returning the output variable as a column vector of the derivatives</li></ul><p>Initial condition is a column vector</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;Basic&quot;&gt;&lt;a href=&quot;#Basic&quot; class=&quot;headerlink&quot; title=&quot;Basic&quot;&gt;&lt;/a&gt;Basic&lt;/h3&gt;&lt;p&gt;[tSol, ySol] = ode45(@odefun, tRange, y0)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em
      
    
    </summary>
    
    
      <category term="Notes" scheme="http://tracyxinwang.site/blog/tags/Notes/"/>
    
      <category term="Matlab" scheme="http://tracyxinwang.site/blog/tags/Matlab/"/>
    
  </entry>
  
  <entry>
    <title>Neural Mass Models</title>
    <link href="http://tracyxinwang.site/blog/2018/11/22/NNM/"/>
    <id>http://tracyxinwang.site/blog/2018/11/22/NNM/</id>
    <published>2018-11-22T08:52:09.000Z</published>
    <updated>2018-11-22T10:51:51.000Z</updated>
    
    <content type="html"><![CDATA[<p>Here is a summary of neual mass models used in literatures.</p><h3 id="Wilson-Cowan-Model"><a href="#Wilson-Cowan-Model" class="headerlink" title="Wilson-Cowan Model"></a>Wilson-Cowan Model</h3><h4 id="Muldoon-2016-Stimulation-Based-Control-of-Dynamic-Brain-Networks"><a href="#Muldoon-2016-Stimulation-Based-Control-of-Dynamic-Brain-Networks" class="headerlink" title="Muldoon 2016 Stimulation-Based Control of Dynamic Brain Networks"></a>Muldoon 2016 Stimulation-Based Control of Dynamic Brain Networks</h4><p><a href="https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005076" target="_blank" rel="noopener">https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005076</a></p><p>$$\tau \frac{dE_j}{dt} = -E_j(t) + (S_{e_max}-E_j(t))S_e\lgroup c_1E_j(t) - c_2I_j(t) + c_5\sum_k A_{jk}E_k(t-\tau_d^k)+P_j(t)\rgroup + \sigma w_j(t)$$<br>$$\tau \frac{dI_j}{dt} = -I_j(t) +(S_{i_max}-I_j(t))S_i(c_3E_j(t)-c_4I_j(t))+\sigma v_j(t)$$</p><ul><li>$E(t)/I(t)$: the firing rate of the excitatory/inhibitory population respectively</li><li>$\tau$: time constant</li><li>$P(t)$: an external stimulus parameter</li><li>$w_j(t)$, $v_j(t)$: drawn from a standard normal distribution and act as additive noise to the system with σ = 0.00001. </li><li>$A$: connectivity matrix</li><li>$\tau_d$: delays between regions.(are calculated as a function of physical distance between identified brain regions, assuming a transmission velocity of 10 m/s (range $\tau_d$ = 0.8 − 14.8 ms))</li><li>$S_{e/i}(x)$:  transfer function(given by the sigmoidal function)<br>$$S_{e/i}(x) = \frac{1}{1+e^{(-a_{e/i}(x-\theta_{e/i}))}} - \frac{1}{1+e^{a_{e/i}\theta_{e/i}}} $$</li></ul><p>Parameters used in paper:<br>$c_1 = 16, c_2 = 12, c_3 = 15, c_4 = 3, a_e = 1.3, a_i = 2, θ_e = 4, θ_i = 3.7$<br>To simulate brain activity, set $P(t) = 0$ for all regions<br>Model stimulation to single brain region, $j$, by setting $P_j(t) = 1.25$. </p><h4 id="Hlinka-2012-Using-computational-models-to-relate-structural-and-functional-brain-connectivity"><a href="#Hlinka-2012-Using-computational-models-to-relate-structural-and-functional-brain-connectivity" class="headerlink" title="Hlinka 2012 Using computational models to relate structural and functional brain connectivity"></a>Hlinka 2012 Using computational models to relate structural and functional brain connectivity</h4><p><a href="https://onlinelibrary.wiley.com/doi/full/10.1111/j.1460-9568.2012.08081.x" target="_blank" rel="noopener">https://onlinelibrary.wiley.com/doi/full/10.1111/j.1460-9568.2012.08081.x</a></p><p>$$\dot u_i = -u_i +f(c_1u_i - c_2v_i + P + \epsilon \sum_j w_{ij}u_j)$$<br>$$\dot v_i = -v_i + f(c_3u_i - c_4v_i + Q)$$<br>$$f(x) = \frac{1}{1+exp(-x)}$$</p><ul><li>$f(x)$: a population firing rate function</li></ul><h3 id="Wong-Wang-Model"><a href="#Wong-Wang-Model" class="headerlink" title="Wong-Wang Model"></a>Wong-Wang Model</h3><h4 id="Deco-2013-Resting-State-Functional-Connectivity-Emerges-from-Structurally-and-Dynamically-Shaped-Slow-Linear-Fluctuations"><a href="#Deco-2013-Resting-State-Functional-Connectivity-Emerges-from-Structurally-and-Dynamically-Shaped-Slow-Linear-Fluctuations" class="headerlink" title="Deco 2013 Resting-State Functional Connectivity Emerges from Structurally and Dynamically Shaped Slow Linear Fluctuations"></a>Deco 2013 Resting-State Functional Connectivity Emerges from Structurally and Dynamically Shaped Slow Linear Fluctuations</h4><p><a href="http://www.jneurosci.org/content/33/27/11239" target="_blank" rel="noopener">http://www.jneurosci.org/content/33/27/11239</a></p><p>$$\frac{dS_i(t)}{dt} = -\frac{S_i}{\tau_S} +(1-S_i)\gamma H(x_i) +\sigma v_i(t) $$<br>$$H(x_i) = \frac{ax_i - b}{1-exp(-d(ax_i-b))}$$<br>$$x_i = wJ_NS_i + GJ_N\sum_j C_{ij}S_j + I_0  $$</p><ul><li>$H(x_i)$: population firing rate</li><li>$S_i$: the average synaptic gating variable at the local cortical area i </li><li>$w$: the local excitatory recurrence, = 0.9</li><li>$C_{ij}$: the structural connectivity matrix expressing the neuroanatomical links between the areas i and j. </li><li>$J_N$: the synaptic couplings, = 0.2609 (nA)</li><li>$I_0$: the overall effective external input, = 0.3 (nA). </li><li>$υ_i(t)$: uncorrelated standard Gaussian noise, and the noise amplitude at each node is $σ = 0.001 (nA)$.</li></ul><p>Parameters used in the paper:<br>$a = 270 (n/C), b = 108 (Hz), d = 0.154 (s), \gamma = 0.641/1000$ (the factor 1000 is for expressing everything in ms), $\tau S = 100 ms$</p><h4 id="Hansen-2014-Functional-connectivity-dynamics-Modeling-the-switching-behavior-of-the-resting-state"><a href="#Hansen-2014-Functional-connectivity-dynamics-Modeling-the-switching-behavior-of-the-resting-state" class="headerlink" title="Hansen 2014 Functional connectivity dynamics: Modeling the switching behavior of the resting state"></a>Hansen 2014 Functional connectivity dynamics: Modeling the switching behavior of the resting state</h4><p><a href="https://www.sciencedirect.com/science/article/pii/S1053811914009033" target="_blank" rel="noopener">https://www.sciencedirect.com/science/article/pii/S1053811914009033</a></p><p>$$\frac{dS_i}{dt} = -\frac{S_i}{\tau_S} +(1-S_i)\gamma R_i +\sigma \eta_i(t) $$<br>$$R_i = \frac{ax_i - b}{1-exp(-d(ax_i-b))}$$<br>$$x_i = wJ_NS_i + GJ_N\sum_j C_{ij}S_j + I_0  $$</p><ul><li>$S_i$: NMDA synaptic input currents</li><li>$\tau_S$: NMDA decay time constant</li><li>$R_i$: collective firing rates</li><li>$\gamma$: kinetic parameter, = 0.641</li><li>$x_i$: total synaptic inputs to a region</li><li>$N$: an intensity scale for synaptic currents, = 0.2609 nA</li><li>$w$: relative strength of recurrent connections within the region</li><li>$C_{ij}$: entries of the SC matrix globally reweighted by a single scalar G adjusted as a control parameter</li><li>$σ$: noise amplitude</li><li>$η$: a stochastic Gaussian variable with a zero mean and unit variance.</li><li>$I_0$: external input and sets the level of regional excitability. </li></ul><p>Parameters used in the paper:<br>$a = 270(V·nC)^{−1}, b = 108 Hz, d = 0.154, G = 2.4, σ = 0.001, w = 0.9, I_0 = 0.3 nA$</p><h4 id="Schirner-2018-Inferring-multi-scale-neural-mechanisms-with-brain-network-modelling"><a href="#Schirner-2018-Inferring-multi-scale-neural-mechanisms-with-brain-network-modelling" class="headerlink" title="Schirner 2018 Inferring multi-scale neural mechanisms with brain network modelling"></a>Schirner 2018 Inferring multi-scale neural mechanisms with brain network modelling</h4><p>Deco 2014<br><a href="https://elifesciences.org/articles/28927" target="_blank" rel="noopener">https://elifesciences.org/articles/28927</a></p><p>$$ I_i^{(E)} = W_EI_0 + G\sum_j C_{ij}S_j^{(E)} - J_iS_i^{(I)} + w_{BG}^{(E)}I_{BG} $$<br>$$I_i^{(I)} = W_II_0 - S_i^{(I)} +w_{BG}^{(I)}I_{BG} $$<br>$$r_i^{(E)} = \frac{a_EI_i^{(E)}-b_E}{1-exp(-d_E(a_EI_i^{(E)}-b_E))}$$<br>$$r_i^{(I)} = \frac{a_II_i^{(I)}-b_I}{1-exp(-d_I(a_II_i^{(I)}-b_I))}$$<br>$$\frac{dS_i^{(E)}(t)}{dt} = -\frac{S_i^{(E)}}{\tau_E} +(1-S_i^{(E)})\gamma_E r_i^{(E)} $$<br>$$\frac{dS_i^{(I)}(t)}{dt} = -\frac{S_i^{(I)}}{\tau_I} +\gamma_I r_i^{(I)} $$</p><ul><li>$r_i^{(E,I)}$: population firing rate of the excitatory (E) and inhibitory (I) population of brain area i. </li><li>$S_i^{(E,I)}$: the average excitatory or inhibitory synaptic gating variables of each brain area, while their input currents are given by $I_i^{(E,I)}$</li><li>$I_{BG}$: excitatory postsynaptic currents using region-wise aggregated EEG source activity that is added to the sum of input currents $I_i^{(E,I)}$.</li><li>$ω_{BG}^{(E,I)}$: weight parameters, rescale the z-score normalized EEG source activity independently for excitatory and inhibitory populations. </li><li>$G$: long-range coupling strength scaling factor that rescales the structural connectivity matrix $C_{ij}$ that denotes the strength of interaction for each region pair i and j. </li><li>$w_+$: Local excitatory recurrence, = 1.4</li><li>$C_{ij}$:    Structural connectivity matrix</li><li>$γ_E, γ_I$: Kinetic parameters, =    $6.41×10^{−4}, 1.0×10^{−3}$    </li><li>$a_E, b_E, d_E, τ_E, W_E$: Excitatory gating variables, = $310 (nC^{−1}), 125(Hz), 0.16(s), 100(ms), 1$    </li><li>$a_I, b_I, d_I, τ_I, W_I$: Inhibitory gating variables, $615 (nC^{−1}), 177 (Hz), 0.087 (s), 10 (ms), 0.7$</li><li>$J_{NMDA}$: Excitatory synaptic coupling, = 0.15 (nA)    </li><li>$J_I$: Feedback inhibitory synaptic coupling, Obtained by FIC heuristic (nA)</li><li>$I_0$: overall effective external input, = 0.382 (nA)</li><li>$G$: global coupling scaling factor, obtained from model fitting</li><li>$w^{(E)}_{BG}, w^{(I)}_{BG}$: weights for scaling EEG-derived input currents, obtained from model fitting</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Here is a summary of neual mass models used in literatures.&lt;/p&gt;
&lt;h3 id=&quot;Wilson-Cowan-Model&quot;&gt;&lt;a href=&quot;#Wilson-Cowan-Model&quot; class=&quot;headerli
      
    
    </summary>
    
    
      <category term="Brain" scheme="http://tracyxinwang.site/blog/tags/Brain/"/>
    
      <category term="Neural Dynamic Simulation" scheme="http://tracyxinwang.site/blog/tags/Neural-Dynamic-Simulation/"/>
    
  </entry>
  
  <entry>
    <title>MIT6006 Lec10 Hashing III Open Addressing</title>
    <link href="http://tracyxinwang.site/blog/2018/11/22/MIT6006-Lec10/"/>
    <id>http://tracyxinwang.site/blog/2018/11/22/MIT6006-Lec10/</id>
    <published>2018-11-21T23:38:23.000Z</published>
    <updated>2018-11-22T03:26:09.907Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Open-addressing"><a href="#Open-addressing" class="headerlink" title="Open addressing"></a>Open addressing</h3><ul><li>is another approach to solve collisions</li><li>no chaining; instead, all items stored in table</li><li>one item per slot ⇒ $m ≥ n$</li><li><strong>hash function</strong> will specify the order of slots to probe (try) for a key (for insert/search/delete), not just one slot. (since when collision occurs, you need to have further trials to find an spare slot)</li><li>in math notation: to design a function $h$, with the property that for all $k ∈ U$:<ul><li>the universe of keys $\times$ trial count, mapps to the slot in table<br>$$h: U \times \{0,1,…,m-1\} \to \{0,1,…,m-1\}$$</li></ul></li><li>$\langle h(k, 0), h(k, 1), . . . , h(k, m − 1)\rangle$ is a permutation of 0, 1, …, m − 1. That means if keep trying h(k, i) for increasing i, we will eventually hit all slots of the table.</li></ul><p>Operations are as follows:</p><ul><li><strong>Insert(k,v)</strong>: Keep probing until an empty slot is found. Insert item into that slot.</li><li><strong>Search(k)</strong>: As long as the slots you encounter by probing are occupied by keys = k, keep probing until you either encounter k or find an empty slot—return success or failure respectively.</li><li><strong>Deleting Items</strong>: rather than setting none in the slot of the deleted item, replace it with special flag: “DeleteMe”, which <em>Insert</em> treats as None but <em>Search</em> doesn’t</li></ul><h3 id="Probing-strategies"><a href="#Probing-strategies" class="headerlink" title="Probing strategies"></a>Probing strategies</h3><p><strong>Linear Probing</strong><br>$h(k, i) = (h’(k) +i)\; mod\; m$ where h’(k) is ordinary hash function</p><p>But have a problem: clustering—cluster: consecutive group of occupied slots as clusters become longer, it gets more likely to grow further.</p><p><strong>Double Hashing</strong><br>$h(k, i) =(h_1(k) +i·h_2(k)) \; mod\; m$ where $h_1(k)$ and $h_2(k)$ are two ordinary hash functions.</p><ul><li>actually hit all slots (permutation) if $h_2(k)$ is relatively prime to m for all k</li></ul><h3 id="Uniform-Hashing-Assumption"><a href="#Uniform-Hashing-Assumption" class="headerlink" title="Uniform Hashing Assumption"></a>Uniform Hashing Assumption</h3><ul><li>is not Simple Uniform Hashing Assumption</li><li>Each key is equally likely to have any one of the m! permutations as its probe sequence(not really true, but double hashing can come close)</li></ul><h4 id="Open-Addressing-vs-Chaining"><a href="#Open-Addressing-vs-Chaining" class="headerlink" title="Open Addressing vs. Chaining"></a>Open Addressing vs. Chaining</h4><ul><li>Open Addressing: better cache performance (better memory usage, no pointers needed)</li><li>Chaining: less sensitive to hash functions (OA requires extra care to avoid clustering) and the load factor α (OA degrades past 70% or so and in any event cannot support values larger than 1)</li></ul><h3 id="Cryptographic-Hashing"><a href="#Cryptographic-Hashing" class="headerlink" title="Cryptographic Hashing"></a>Cryptographic Hashing</h3><p><br></p><p>A demo of different probng tsrategies can be found <a href="https://www.cse.cuhk.edu.hk/irwin.king/_media/teaching/csc2100b/tu6.pdf" target="_blank" rel="noopener">here</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;Open-addressing&quot;&gt;&lt;a href=&quot;#Open-addressing&quot; class=&quot;headerlink&quot; title=&quot;Open addressing&quot;&gt;&lt;/a&gt;Open addressing&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;is another a
      
    
    </summary>
    
    
      <category term="Algorithm" scheme="http://tracyxinwang.site/blog/tags/Algorithm/"/>
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
  </entry>
  
  <entry>
    <title>MIT6006 Lec09 Hashing II</title>
    <link href="http://tracyxinwang.site/blog/2018/11/19/MIT6006-Lec09/"/>
    <id>http://tracyxinwang.site/blog/2018/11/19/MIT6006-Lec09/</id>
    <published>2018-11-18T21:36:18.000Z</published>
    <updated>2018-11-19T22:30:42.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Table-Resizing-and-Amortization"><a href="#Table-Resizing-and-Amortization" class="headerlink" title="Table Resizing and Amortization"></a>Table Resizing and Amortization</h3><p>In ‘Hashing I’, we know that we will create a hash table with chaining to save the data. The size of the table is <code>m</code>, which is smaller than <code>n</code>, the number of keys(data). But then one problem comes, how to choose <code>m</code>? the size of the table. </p><ul><li>want $m=\theta(n)$ at all times.</li><li>but don’t know how large n will get at creation</li><li>if m is too small ⇒ slow; m too big ⇒ wasteful</li></ul><p>The idea is to start small (constant) and grow (or shrink) as necessary.</p><p><strong>Rehashing</strong><br>When n reaches m, grow the table.</p><ul><li>If grow the table by <code>m+=1</code><ul><li>need to rebuild every step</li><li>n inserts cost $Θ(1+2+ \cdots +n) = Θ(n2)$</li></ul></li><li>If grow the table by <code>m ∗ =2</code><ul><li>just to rebuild at insertion $2^i$</li><li>n inserts cost $Θ(1+2+4+8+ \cdots +n)$ where n is really the next power of $2=Θ(n)$ (This is called table doubling)</li></ul></li></ul><p><strong>Pseudo code</strong><br><em>Insert</em>:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># m is the size of the table, n is the number of the elements in that table</span></span><br><span class="line"><span class="keyword">function</span> Insert(x, A, m, n)</span><br><span class="line">    <span class="keyword">if</span> (n = m) <span class="keyword">then</span></span><br><span class="line">        Create new array A2 with size 2m;</span><br><span class="line">        <span class="keyword">for</span> i ← 1 to m <span class="keyword">do</span></span><br><span class="line">            A2[i] ← A[i];</span><br><span class="line">        end</span><br><span class="line">        Replace array A with A2;</span><br><span class="line">        m ← 2m;</span><br><span class="line">    end</span><br><span class="line">    n ← n + 1;</span><br><span class="line">    A[n] ← x;</span><br></pre></td></tr></table></figure></p><p><em>Delete</em>:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">function</span> Delete(x, A, m, n)</span><br><span class="line">    x ← A[n];</span><br><span class="line">    n ← n − 1;</span><br><span class="line">    <span class="keyword">if</span> (n ≤ m/4) and (m ≥ 4) <span class="keyword">then</span></span><br><span class="line">        Create new array A2 with size m/2;</span><br><span class="line">        <span class="keyword">for</span> i ← 1 to n <span class="keyword">do</span></span><br><span class="line">            A2[i] ← A[i];</span><br><span class="line">        end</span><br><span class="line">        Replace array A with A2;</span><br><span class="line">        m ← m/2;</span><br><span class="line">    end</span><br></pre></td></tr></table></figure></p><p><strong>Amortization</strong></p><ul><li>operation has amortized cost $T(n)$ if $k$ operations cost $≤ k · T(n)$</li><li>“T(n) amortized” roughly means T(n) “on average”, but averaged over all operations.</li><li>e.g. inserting into a hash table takes O(1) amortized time.</li></ul><h3 id="String-Matching-and-Karp-Rabin"><a href="#String-Matching-and-Karp-Rabin" class="headerlink" title="String Matching and Karp-Rabin"></a>String Matching and Karp-Rabin</h3><p>Given two strings s and t, does s occur as a substring of t? </p><p><strong>Simple Algorithm</strong><br>any(s == t[i : i + len(s)] for i in range(len(t) − len(s)))<br>— O(|s|) time for each substring comparison<br>⇒ O(|s| · (|t| − |s|)) time<br>= O(|s| · |t|)<br>potentially quadratic</p><h4 id="Karp-Rabin-Algorithm"><a href="#Karp-Rabin-Algorithm" class="headerlink" title="Karp-Rabin Algorithm"></a>Karp-Rabin Algorithm</h4><ul><li>Compare h(s) == h(t[i : i + len(s)])</li><li>If hash values match, likely so do strings<ul><li>can check s == t[i : i + len(s)] to be sure ∼ cost $O(|s|)$</li><li>if yes, found match — done</li><li>if no, happened with probability &lt; $\frac 1{|s|}$ ⇒ expected cost is $O(1)$ per i.</li></ul></li><li>need suitable hash function.</li><li>expected time = O(|s| + |t| · cost(h)).<ul><li>naively h(x) costs |x|</li><li>we’ll achieve O(1)!</li><li>idea: t[i : i + len(s)] ≈ t[i + 1 : i + 1 + len(s)]</li></ul></li></ul><p>So using Rabin Karp algorithm needs to calculate hash values for strings first. The hash function suggested by Rabin and Karp calculates an integer value. The integer value for a string is numeric value of a string. </p><h3 id="Rolling-Hash"><a href="#Rolling-Hash" class="headerlink" title="Rolling Hash"></a>Rolling Hash</h3><p>The idea is to compute the hash value of a substring using the hash value of previous substring if you use the right hash function. A polynomial with the string characters as coefficients works well. </p><p>Let the following be the hash function for string c:<br>$$H(c) = c[0]a^{n-1} + c[1]a^{n-2} + \cdots + c[n-1]$$<br>All the operations will be done modulo a prime number so that we don’t have to deal with large integers.</p><p>List an example for calculating the hash value for a string:<br>$$H(S[i+1 … i+n]) = S[i+1]a^{n-1} + S[i+2]a^{n-2} + … + S[i+n]$$<br>where n is the length of the string that we want to match<br>By adding and substracting $S[i]a^n$, get $$a(S[i]a^{n-1} + S[i+1]a^{n-2} + S[i+2]a^{n-3} + … + S[i+n-1]) + S[i+n] = aH(S[i … i+n-1]) - S[i]a^n + S[i+n]$$</p><p><br></p><p>Reference:<br><a href="http://web.cse.ohio-state.edu/~rademacher.10/Sp16_2331/datastructII.pdf" target="_blank" rel="noopener">http://web.cse.ohio-state.edu/~rademacher.10/Sp16_2331/datastructII.pdf</a><br><a href="https://www.geeksforgeeks.org/rabin-karp-algorithm-for-pattern-searching/" target="_blank" rel="noopener">https://www.geeksforgeeks.org/rabin-karp-algorithm-for-pattern-searching/</a><br><a href="https://www.infoarena.ro/blog/rolling-hash" target="_blank" rel="noopener">https://www.infoarena.ro/blog/rolling-hash</a><br><a href="https://brilliant.org/wiki/rabin-karp-algorithm/" target="_blank" rel="noopener">https://brilliant.org/wiki/rabin-karp-algorithm/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;Table-Resizing-and-Amortization&quot;&gt;&lt;a href=&quot;#Table-Resizing-and-Amortization&quot; class=&quot;headerlink&quot; title=&quot;Table Resizing and Amortizatio
      
    
    </summary>
    
    
      <category term="Algorithm" scheme="http://tracyxinwang.site/blog/tags/Algorithm/"/>
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
  </entry>
  
  <entry>
    <title>MIT6006 Lec08 Hashing I</title>
    <link href="http://tracyxinwang.site/blog/2018/11/17/MIT6006-Lec08/"/>
    <id>http://tracyxinwang.site/blog/2018/11/17/MIT6006-Lec08/</id>
    <published>2018-11-17T07:07:42.000Z</published>
    <updated>2018-11-18T21:25:45.654Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Dictionary-and-Motivation"><a href="#Dictionary-and-Motivation" class="headerlink" title="Dictionary and Motivation"></a>Dictionary and Motivation</h3><h4 id="Dictionary-problem"><a href="#Dictionary-problem" class="headerlink" title="Dictionary problem"></a>Dictionary problem</h4><ul><li>Dictionary is a abstract data tupe(ADT).</li><li>Which means it maintains a set of items, each with a key</li><li>The available operations are:<ul><li>insert(item): add item to the set (The key must be unique, otherwise overide an exsiting key)</li><li>delete(item): remove item from set</li><li>search(key): return item with key if it exists<br>Balanced BST solve in $O(lg n)$ time per operation. The goal is to make each operation $O(1)$ time.</li></ul></li></ul><p>(remember that BST etc. are data structure, which can be seen as the implementation of ADT)</p><h4 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h4><p>Dictionaries are perhaps the most popular data structure in CS</p><ul><li>built into most modern programming languages (Python, Perl, Ruby, JavaScript, Java, C++, C#, . . . )</li><li>e.g. best docdist code: word counts &amp; inner product</li><li>implement databases: (DB HASH in Berkeley DB)<ul><li>English word → definition (literal dict.)</li><li>English words: for spelling correction</li><li>word → all webpages containing that word</li><li>username → account object</li></ul></li><li>compilers &amp; interpreters: names → variables</li><li>network routers: IP address → wire</li><li>network server: port number → socket/app.</li><li>virtual memory: virtual address → physical</li></ul><h3 id="Prehashing-and-Hashing"><a href="#Prehashing-and-Hashing" class="headerlink" title="Prehashing and Hashing"></a>Prehashing and Hashing</h3><p>How to solve the dictionary problem that is to make operation time to $O(1)$?</p><p><strong>Simple Approach: Direct Access Table</strong><br>This means items would need to be stored in an array, indexed by key (random access). But this has two problems:</p><ol><li>keys must be nonnegative integers (or using two arrays, integers)</li><li>if the key happens to have large range, then need large space — e.g. one key is 2256, even with no other keys, the table must have take that space.</li></ol><p><strong>Solution</strong><br><em>Solution to 1</em>: “prehash” keys to integers</p><ul><li>In theory, possible because keys are finite ⇒ set of keys is countable</li><li>In Python: hash(object) (actually hash is misnomer, should be “prehash”) where object can be a number, string, tuple, etc. or object implementing hash (default = id = memory address)</li><li>In theory, x = y ⇔ hash(x) = hash(y)</li><li>Python applies some heuristics for practicality: for example, hash(‘\0B ’) = 64 = hash(‘\0\0C’)</li><li>Object’s key should not change while in table (else cannot find it anymore)</li><li>No mutable objects like lists</li></ul><p><em>Solution to 2</em>: hashing </p><ul><li>Reduce universe U of all keys (say, integers) down to reasonable size m for table</li><li>idea: m ≈ n = number of keys stored in dictionary</li><li><strong>hash function</strong> h: $U → {0, 1, . . . , m − 1}$</li><li>two keys $k_i, k_j ∈ K$ collide if $h(k_i) = h(k_j)$</li></ul><p>Hash Function: A function that converts a given big phone number to a small practical integer value. The mapped integer value is used as an index in hash table.</p><p>How do we deal with collisions? We will see two ways</p><ol><li>Chaining</li><li>Open addressing: in Lec10</li></ol><h3 id="Chaining"><a href="#Chaining" class="headerlink" title="Chaining"></a>Chaining</h3><p>Linked list of colliding elements in each slot of table</p><ul><li>Search must go through whole list T[h(key)]</li><li>Worst case: all n keys hash to same slot ⇒ Θ(n) per operation</li></ul><h4 id="Simple-uniform-hashing"><a href="#Simple-uniform-hashing" class="headerlink" title="Simple uniform hashing"></a>Simple uniform hashing</h4><p>An assumption (cheating): Each key is equally likely to be hashed to any slot of table, independent of where other keys are hashed.</p><p>let n = number of keys stored in table<br>m = number of slots in table<br>load factor α = n/m = expected number of keys per slot = expected length of a chain</p><p><em>Performance</em>:<br>This implies that expected running time for search is $Θ(1+α)$ — the 1 comes from applying the hash function and random access to the slot whereas the $α$ comes from searching the list. This is equal to $O(1)$ if $α = O(1)$, i.e., $m = Ω(n)$.</p><h3 id="Hash-Function"><a href="#Hash-Function" class="headerlink" title="Hash Function"></a>Hash Function</h3><p>Following are three methods to achieve the above performance</p><p><strong>Division Method</strong>:<br>$$h(k) = k \; mod \; m$$<br>This is practical when m is prime but not too close to power of 2 or 10 (then just depending on low bits/digits).<br>But it is inconvenient to find a prime number, and division is slow.</p><p><strong>Multiplication Method</strong>:<br>$$h(k) = [(a · k) \; mod \; 2^w] \gg (w − r)$$<br>where a is random, k is w bits, and $m = 2^r$.<br>This is practical when a is odd &amp; $2^{w−1}$ &lt; $a$ &lt; $2^w$ &amp; a not too close to $2^{w−1}$ or $2^w$.<br>Multiplication and bit extraction are faster than division.</p><p><strong>Universal Hashing</strong>:<br>For example: $h(k) = [(ak+b) \; mod \; p] mod \; m$ where a and b are random $∈ {0, 1, . . . p−1}$, and p is a large prime ($&gt; |U|$).<br>This implies that for worst case keys $k_1 \ne k_2$, (and for a, b choice of h): $$Pr_{a,b}(event \; X_{k_1k_2}) = Pr_{a,b}\{h(k_1)=h(k_2)\} = \frac 1m$$</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;Dictionary-and-Motivation&quot;&gt;&lt;a href=&quot;#Dictionary-and-Motivation&quot; class=&quot;headerlink&quot; title=&quot;Dictionary and Motivation&quot;&gt;&lt;/a&gt;Dictionary 
      
    
    </summary>
    
    
      <category term="Algorithm" scheme="http://tracyxinwang.site/blog/tags/Algorithm/"/>
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
  </entry>
  
  <entry>
    <title>MIT6006 Lec07 Linear-Time Sorting</title>
    <link href="http://tracyxinwang.site/blog/2018/11/15/MIT6006-Lec07/"/>
    <id>http://tracyxinwang.site/blog/2018/11/15/MIT6006-Lec07/</id>
    <published>2018-11-15T03:52:42.000Z</published>
    <updated>2018-11-15T05:23:33.770Z</updated>
    
    <content type="html"><![CDATA[<p>Need to digest again!</p><p>First lists some claims:</p><ul><li>searching among n preprocessed items requires $Ω(lg n)$ time: binary search, AVL tree search optimal</li><li>sorting n items requires $Ω(nlg n)$: mergesort, heap sort, AVL sort optimal</li></ul><h3 id="Comparison-model"><a href="#Comparison-model" class="headerlink" title="Comparison model"></a>Comparison model</h3><ul><li>All the input items are black boxes (ADTs)</li><li>Only support comparisons (&gt;,&lt;, etc.)</li><li>Time cost = number of comparisons</li></ul><h4 id="Decision-tree"><a href="#Decision-tree" class="headerlink" title="Decision tree"></a>Decision tree</h4><p>Any comparison algorithm can be viewed/specified as a tree of all possible comparison outcomes &amp; resulting output.</p><ul><li>internal node = binary decision</li><li>leaf = output (algorithm is done)</li><li>root-to-leaf path = algorithm execution</li><li>path length (depth) = running time</li><li>height of tree = worst-case running time</li></ul><p>In fact, binary decision tree model is more powerful than comparison model, and lower bounds extend to it</p><blockquote><p>A sorting algorithm is comparison based if it uses comparison operators to find the order between two numbers.  Comparison sorts can be viewed abstractly in terms of decision trees. A decision tree is a full binary tree that represents the comparisons between elements that are performed by a particular sorting algorithm operating on an input of a given size. The execution of the sorting algorithm corresponds to tracing a path from the root of the decision tree to a leaf. At each internal node, a comparison ai &lt;= aj is made. The left subtree then dictates subsequent comparisons for ai &lt;= aj, and the right subtree dictates subsequent comparisons for ai &gt; aj. When we come to a leaf, the sorting algorithm has established the ordering. </p></blockquote><h3 id="Lower-Bounds"><a href="#Lower-Bounds" class="headerlink" title="Lower Bounds"></a>Lower Bounds</h3><p><strong>Search Lower Bound</strong></p><ul><li>number of leaves &gt;= number of possible answers &gt;= n</li><li>decision tree is binary</li><li>height &gt;=  $lg Θ(n) = lg n ± Θ(1)$</li></ul><p><strong>Sorting Lower Bound</strong></p><ul><li>leaf specifies answer as permutation: A[3] ≤ A[1] ≤ A[9] ≤ . . .</li><li>all n! are possible answers</li><li>number of leaves &gt;= n!</li></ul><p>$$ \begin{align*}<br>height &amp; ≥ lg n! \\<br>&amp; = lg(1·2 /cdots (n − 1)·n) \\<br>&amp; = lg 1 + lg 2 + /cdots + lg(n − 1) + lg n \\<br>&amp; = \sum^n_{i=1} lg i \\<br>&amp; \ge \sum^n_{i=n/2} lg i \\<br>&amp; \ge \sum^n_{i=n/2} lg \frac n2 \\<br>&amp; = \frac n2 lg n - \frac n2 \\<br>&amp; = \Omega (n lg n)<br>\end{align*}$$</p><p>Therefore, the lower bound for Comparison based sorting algorithm (Merge Sort, Heap Sort, Quick-Sort .. etc) is $Ω(nLogn)$, i.e., they cannot do better than $n logn$.</p><h3 id="Linear-time-Sorting"><a href="#Linear-time-Sorting" class="headerlink" title="Linear-time Sorting"></a>Linear-time Sorting</h3><h4 id="Radix-sort"><a href="#Radix-sort" class="headerlink" title="Radix sort"></a>Radix sort</h4><p><a href="https://www.geeksforgeeks.org/counting-sort/" target="_blank" rel="noopener">Counting sort</a> is a linear time sorting algorithm that sort in $O(n+k)$ time when elements are in range from 1 to k. But if the elements are in range from 1 to $n^2$, counting sort will take $O(n^2)$.</p><p>How to sort such an array in linear time? Use Radix sort.<br>The idea of Radix Sort is to do digit by digit sort starting from least significant digit to most significant digit. Radix sort uses counting sort as a subroutine to sort.</p><p><br></p><p>Reference:<br><a href="https://www.geeksforgeeks.org/lower-bound-on-comparison-based-sorting-algorithms/" target="_blank" rel="noopener">https://www.geeksforgeeks.org/lower-bound-on-comparison-based-sorting-algorithms/</a><br><a href="https://www.geeksforgeeks.org/radix-sort/" target="_blank" rel="noopener">https://www.geeksforgeeks.org/radix-sort/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Need to digest again!&lt;/p&gt;
&lt;p&gt;First lists some claims:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;searching among n preprocessed items requires $Ω(lg n)$ time: binary s
      
    
    </summary>
    
    
      <category term="Algorithm" scheme="http://tracyxinwang.site/blog/tags/Algorithm/"/>
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
  </entry>
  
  <entry>
    <title>MIT6006 Lec06 AVL trees, AVL sort</title>
    <link href="http://tracyxinwang.site/blog/2018/11/14/MIT6006-Lec06/"/>
    <id>http://tracyxinwang.site/blog/2018/11/14/MIT6006-Lec06/</id>
    <published>2018-11-14T03:52:42.000Z</published>
    <updated>2018-11-15T03:49:11.000Z</updated>
    
    <content type="html"><![CDATA[<p>Recall the properties of binary search tree:</p><ul><li>each node has <ul><li>key</li><li>left pointer</li><li>right pointer</li><li>parent pointer</li></ul></li><li>height of the node  = length (number of edges) of longest downward path to a leaf</li><li>BST will do all operations in $O(h)$ time, h = height</li><li>h is between $lg n$ and $n$.</li></ul><p>The advantage of balanced tree is that it maintains $h=O(lg n)$, therefore, all operations run in $O(lg n)$ time.</p><h3 id="Tree-rotation"><a href="#Tree-rotation" class="headerlink" title="Tree rotation"></a>Tree rotation</h3><p>The operation “rotation” is to make a tree balanced and will be used in fixing the inbalance of AVL tree.<br>There are two categories: single rotation and two rotations. </p><p><strong>Left Rotation</strong><br><em>Application scenario</em>: When a node A’s <strong>right</strong> subtree becomes inbalanced after inserting another new one. Then need to apply the left rotation of that node (A).<br>After performing the left rotation of node A, A’s right child becomes its parent and A becomes the <strong>left child</strong>.</p><p><strong>Right Rotation</strong><br><em>Application scenario</em>: When a node A’s <strong>left</strong> subtree becomes inbalanced after inserting another new one. Then need to apply the right rotation of that node (A).<br>After performing the right rotation of the unbalanced node A, it becomes the <strong>right child</strong> of its original left child.</p><p><strong>Left-Right Rotation</strong><br><em>Application scenario</em>: When a node A becomes inbalanced after inserting another new one to the <strong>right subtree of the left subtree of A</strong>.<br><em>Steps</em>: </p><ol><li>Perform left rotation to the left subtree of A</li><li>Perform right rotation of the A itself</li></ol><p><strong>Right-Left Rotation</strong><br><em>Application scenario</em>: When a node A becomes inbalanced after inserting another new one to the <strong>left subtree of the right subtree of A</strong>.<br><em>Steps</em>: </p><ol><li>Perform right rotation to the right subtree of A</li><li>Perform left rotation of the A itself</li></ol><p><strong>Implementation</strong>:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">def left_rotate(self, x):</span><br><span class="line">    y = x.right</span><br><span class="line">    y.parent = x.parent</span><br><span class="line">    <span class="keyword">if</span> y.parent is None:</span><br><span class="line">        self.root = y</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">if</span> y.parent.left is x:</span><br><span class="line">            y.parent.left = y</span><br><span class="line">        <span class="keyword">elif</span> y.parent.right is x:</span><br><span class="line">            y.parent.right = y</span><br><span class="line">    x.right = y.left</span><br><span class="line">    <span class="keyword">if</span> x.right is not None:</span><br><span class="line">        x.right.parent = x</span><br><span class="line">    y.left = x</span><br><span class="line">    x.parent = y</span><br><span class="line">    update_height(x)</span><br><span class="line">    update_height(y)</span><br><span class="line"></span><br><span class="line">def right_rotate(self, x):</span><br><span class="line">    y = x.left</span><br><span class="line">    y.parent = x.parent</span><br><span class="line">    <span class="keyword">if</span> y.parent is None:</span><br><span class="line">        self.root = y</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">if</span> y.parent.left is x:</span><br><span class="line">            y.parent.left = y</span><br><span class="line">        <span class="keyword">elif</span> y.parent.right is x:</span><br><span class="line">            y.parent.right = y</span><br><span class="line">    x.left = y.right</span><br><span class="line">    <span class="keyword">if</span> x.left is not None:</span><br><span class="line">        x.left.parent = x</span><br><span class="line">    y.right = x</span><br><span class="line">    x.parent = y</span><br><span class="line">    update_height(x)</span><br><span class="line">    update_height(y)</span><br></pre></td></tr></table></figure></p><p>Here is a very nice illustration: <a href="https://wiki2.org/en/Tree_rotation#/media/File:Tree_Rebalancing.gif" target="_blank" rel="noopener">https://wiki2.org/en/Tree_rotation#/media/File:Tree_Rebalancing.gif</a></p><h3 id="AVL-tree"><a href="#AVL-tree" class="headerlink" title="AVL tree"></a>AVL tree</h3><ul><li>named by the author.</li><li>for every node, require height of left &amp; right children to differ by at most 1<ul><li>nil tree as height -1</li><li>each node stores its height (using data structure augmentation)</li></ul></li></ul><h4 id="AVL-Insert"><a href="#AVL-Insert" class="headerlink" title="AVL Insert"></a>AVL Insert</h4><ul><li>Perform the normal BST insertion.</li><li>The current node must be one of the ancestors of the newly inserted node. Update the height of the current node.</li><li>Get the balance factor (left subtree height – right subtree height) of the current node.</li><li>If balance factor is greater than 1, then the current node is unbalanced and we are either in Left Left case or left Right case. To check whether it is left left case or not, compare the newly inserted key with the key in left subtree root.</li><li>If balance factor is less than -1, then the current node is unbalanced and we are either in Right Right case or Right-Left case. To check whether it is Right Right case or not, compare the newly inserted key with the key in right subtree root.</li><li>Time: $\theta (nlg n)$</li></ul><p><strong>Code of rebalance the tree</strong>:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">def rebalance(self, node):</span><br><span class="line">    <span class="keyword">while</span> node is not None:</span><br><span class="line">        update_height(node)</span><br><span class="line">        <span class="keyword">if</span> height(node.left) &gt;= 2 + height(node.right):</span><br><span class="line">            <span class="keyword">if</span> height(node.left.left) &gt;= height(node.left.right):</span><br><span class="line">                self.right_rotate(node)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                self.left_rotate(node.left)</span><br><span class="line">                self.right_rotate(node)</span><br><span class="line">        <span class="keyword">elif</span> height(node.right) &gt;= 2 + height(node.left):</span><br><span class="line">            <span class="keyword">if</span> height(node.right.right) &gt;= height(node.right.left):</span><br><span class="line">                self.left_rotate(node)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                self.right_rotate(node.right)</span><br><span class="line">                self.left_rotate(node)</span><br><span class="line">        node = node.parent</span><br></pre></td></tr></table></figure></p><h3 id="General"><a href="#General" class="headerlink" title="General"></a>General</h3><p><strong>Other balanced trees</strong>:</p><ul><li>B-Trees/2-3-4 Trees</li><li>BB[α] Trees </li><li>Red-black Trees </li><li>(A) — Splay-Trees </li><li>(R) — Skip Lists</li><li>(A) — Scapegoat Trees </li><li>(R) — Treaps<br>(R) = use random numbers to make decisions fast with high probability<br>(A) = “amortized”: adding up costs for several operations =⇒ fast on average</li></ul><p><strong>Data Structure (DS) vs Abstract Data Type (ADT)</strong></p><ul><li>ADT is a logical description and data structure is concrete. </li><li>ADT is the logical picture of the data and the operations to manipulate the component elements of the data. </li><li>Data structure is the actual representation of the data during the implementation and the algorithms to manipulate the data elements. </li><li>ADT is in the logical level and data structure is in the implementation level.</li></ul><p>There are many possible DSs for one ADT.<br>Some common ADTs: </p><ul><li>stack, queue, priority queue, dictionary, sequence, set</li></ul><p>Some common DSs used to implement the above ADTS: </p><ul><li>array, linked list, hash table (open, closed, circular hashing) </li><li>trees (binary search trees, heaps, AVL trees, 2-3 trees, tries, red/black trees, B-trees)</li></ul><p><br></p><p>Reference:<br><a href="https://www.tutorialspoint.com/data_structures_algorithms/avl_tree_algorithm.htm" target="_blank" rel="noopener">https://www.tutorialspoint.com/data_structures_algorithms/avl_tree_algorithm.htm</a><br><a href="https://www.geeksforgeeks.org/avl-tree-set-1-insertion/" target="_blank" rel="noopener">https://www.geeksforgeeks.org/avl-tree-set-1-insertion/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Recall the properties of binary search tree:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;each node has &lt;ul&gt;
&lt;li&gt;key&lt;/li&gt;
&lt;li&gt;left pointer&lt;/li&gt;
&lt;li&gt;right pointer&lt;/li&gt;
&lt;l
      
    
    </summary>
    
    
      <category term="Algorithm" scheme="http://tracyxinwang.site/blog/tags/Algorithm/"/>
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
  </entry>
  
  <entry>
    <title>Slurm General Command and Exit Code</title>
    <link href="http://tracyxinwang.site/blog/2018/11/13/slurm-exit-code/"/>
    <id>http://tracyxinwang.site/blog/2018/11/13/slurm-exit-code/</id>
    <published>2018-11-12T21:09:33.000Z</published>
    <updated>2018-11-15T00:04:06.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="General-command"><a href="#General-command" class="headerlink" title="General command"></a>General command</h3><p><strong>submit a job</strong><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sbatch myscript.sh</span><br><span class="line">sbatch --<span class="built_in">test</span>-only myscript.sh  <span class="comment"># test a job and find out when your job is estimated to run</span></span><br></pre></td></tr></table></figure></p><p><strong>Information of jobs for a user</strong><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">squeue -u &lt;username&gt;    <span class="comment"># List all current jobs for a user</span></span><br><span class="line">squeue -u &lt;username&gt; -t RUNNING <span class="comment"># List all running jobs for a user</span></span><br><span class="line">squeue -u &lt;username&gt; -t PENDING <span class="comment"># List all pending jobs for a user</span></span><br><span class="line">scontrol show jobid -dd &lt;jobid&gt; <span class="comment"># List detailed information for a job (useful for troubleshooting)</span></span><br><span class="line">sstat --format=AveCPU,AvePages,AveRSS,AveVMSize,JobID -j &lt;jobid&gt; --allsteps <span class="comment"># List status info for a currently running job</span></span><br></pre></td></tr></table></figure></p><p><strong>Controlling jobs</strong><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">scancel &lt;jobid&gt;   <span class="comment"># cancel one job</span></span><br><span class="line">scancel -u &lt;username&gt; <span class="comment"># cancel all the jobs for a user</span></span><br><span class="line">scancel -t PENDING -u &lt;username&gt; <span class="comment"># cancel all pending jobs for a user</span></span><br><span class="line">scontrol hold &lt;jobid&gt; <span class="comment"># pause a particular job</span></span><br><span class="line">scontrol requeue &lt;jobid&gt;    <span class="comment"># requeue (cancel and rerun) a particular job </span></span><br><span class="line">scancel &lt;jobid&gt;_&lt;index&gt; <span class="comment"># To cancel an indexed job in a job array</span></span><br></pre></td></tr></table></figure></p><h3 id="Exit-code"><a href="#Exit-code" class="headerlink" title="Exit code"></a>Exit code</h3><p>开始使用HPC时遇到很多问题，特别是用slurm deploy job的时候，如果在slurm文件中设置将开始，结束，失败的信息发送给自己邮箱时，它会针对每一种情况给一个code，这个code即表示一种状态。下面记录一些常见的 exit code 表明的意思。</p><p>The exit code from a batch job is a standard Unix termination signal.<br>Typically, exit code 0 means successful completion.<br>Codes 1-127 are generated from the job calling exit() with a non-zero value to indicate an error.<br>Exit codes 129-255 represent jobs terminated by Unix signals.<br>Each signal has a corresponding value which is indicated in the job exit code</p><h4 id="Job-Termination-Signals"><a href="#Job-Termination-Signals" class="headerlink" title="Job Termination Signals"></a>Job Termination Signals</h4><table><thead><tr><th>Signal Name</th><th>Signal Number</th><th>Exit Type</th><th>Reason</th></tr></thead><tbody><tr><td>SIGHUP</td><td>1</td><td>Term</td><td>Hangup detected on controlling terminal or death of controlling process</td></tr><tr><td>SIGINT</td><td>2</td><td>Term</td><td>Interrupt from keyboard</td></tr><tr><td>SIGQUIT</td><td>3</td><td>Core</td><td>Quit from keyboard</td></tr><tr><td>SIGILL</td><td>4</td><td>Core</td><td>Illegal Instruction</td></tr><tr><td>SIGABRT</td><td>6</td><td>Core</td><td>Abort signal from abort(3)</td></tr><tr><td>SIGFPE</td><td>8</td><td>Core</td><td>Floating point exception</td></tr><tr><td>SIGKILL</td><td>9</td><td>Term</td><td>Kill signal</td></tr><tr><td>SIGSEGV</td><td>11</td><td>Core</td><td>Invalid memory reference</td></tr><tr><td>SIGPIPE</td><td>13</td><td>Term</td><td>Broken pipe: write to pipe with no readers</td></tr><tr><td>SIGALRM</td><td>14</td><td>Term</td><td>Timer signal from alarm(2)</td></tr><tr><td>SIGTERM</td><td>15</td><td>Term</td><td>Termination signal</td></tr></tbody></table><h4 id="Job-Exit-Status"><a href="#Job-Exit-Status" class="headerlink" title="Job Exit Status"></a>Job Exit Status</h4><table><thead><tr><th>Exit Code</th><th>Reason</th></tr></thead><tbody><tr><td>9</td><td>Ran out of CPU time.</td></tr><tr><td>64</td><td>The job ended nicely for but your job was running out of CPU time. The solution is to submit the job to a queue with more resources (bigger CPU time limit).</td></tr><tr><td>125</td><td>An ErrMsg(severe) was reached in your job.</td></tr><tr><td>127</td><td>Something wrong with the machine?</td></tr><tr><td>130</td><td>The job ran out of CPU or swap time. If swap time is the culprit, check for memory leaks.</td></tr><tr><td>131</td><td>The job ran out of CPU or swap time. If swap time is the culprit, check for memory leaks.</td></tr><tr><td>134</td><td>The job is killed with an abort signal, and you probably got core dumped. Often this is caused either by an assert() or an ErrMsg(fatal) being hit in your job. There may be a run-time bug in your code. Use a debugger like gdb or Totalview to find out what’s wrong.</td></tr><tr><td>137</td><td>The job was killed because it exceeded the time limit.</td></tr><tr><td>139</td><td>Segmentation violation. Usually indicates a pointer error.</td></tr><tr><td>140</td><td>The job exceeded the “wall clock” time limit (as opposed to the CPU time limit).</td></tr></tbody></table><p>Reference:<br><a href="https://www.rc.fas.harvard.edu/resources/documentation/convenient-slurm-commands/" target="_blank" rel="noopener">https://www.rc.fas.harvard.edu/resources/documentation/convenient-slurm-commands/</a><br><a href="https://sites.google.com/a/case.edu/hpc-upgraded-cluster/cluster-faq/running-jobs/exit-code-status" target="_blank" rel="noopener">https://sites.google.com/a/case.edu/hpc-upgraded-cluster/cluster-faq/running-jobs/exit-code-status</a><br><a href="https://software.intel.com/en-us/fortran-compiler-developer-guide-and-reference-list-of-run-time-error-messages" target="_blank" rel="noopener">https://software.intel.com/en-us/fortran-compiler-developer-guide-and-reference-list-of-run-time-error-messages</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;General-command&quot;&gt;&lt;a href=&quot;#General-command&quot; class=&quot;headerlink&quot; title=&quot;General command&quot;&gt;&lt;/a&gt;General command&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;submit a j
      
    
    </summary>
    
    
      <category term="Notes" scheme="http://tracyxinwang.site/blog/tags/Notes/"/>
    
      <category term="Tools" scheme="http://tracyxinwang.site/blog/tags/Tools/"/>
    
  </entry>
  
  <entry>
    <title>MIT6006 Lec05 Binary search trees, BST sort</title>
    <link href="http://tracyxinwang.site/blog/2018/11/07/MIT6006-Lec05/"/>
    <id>http://tracyxinwang.site/blog/2018/11/07/MIT6006-Lec05/</id>
    <published>2018-11-06T22:28:20.000Z</published>
    <updated>2018-11-08T06:23:05.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Preliminary-things"><a href="#Preliminary-things" class="headerlink" title="Preliminary things"></a>Preliminary things</h3><h4 id="Difference-between-array-and-list"><a href="#Difference-between-array-and-list" class="headerlink" title="Difference between array and list"></a>Difference between array and list</h4><p><strong>Array</strong></p><ul><li>每个元素都有一个index, 通过index来操作该元素的所有动作。</li><li>Array 的大小是一开始就确定的，储存的个数不能超过这个最大限制。然而在实际当中，这个upper limit很少会被达到，但是分出去了就分出去了，不能拿来做别的事情，所以会造成内存的浪费</li><li>插入一个新元素会比较 expensive, 因为新元素之后的所有元素都需要移动。同理删除。</li><li>Array allow both direct and sequential access to element</li></ul><p><strong>List</strong></p><ul><li>是有个有序的集合，由指针(链表)来确定位置的，根据不同的implementation, 可分为 linked list 和 dynamic array</li><li>每个元素(node), 包含数据同时还有指向下一个元素的指针</li><li>大小是动态的，可随时变的</li><li>插入和删除操作花费较少</li><li>lists allow only sequential access. Therefore, cannot do binary search with linked lists.</li><li>Extra memory space for a pointer is required with each element of the list.</li></ul><p>A binary tree is made of nodes, where each node contains a “left” reference, a “right” reference, and a data element. </p><h3 id="Runway-Reservation-System-problem"><a href="#Runway-Reservation-System-problem" class="headerlink" title="Runway Reservation System problem"></a>Runway Reservation System problem</h3><ul><li>Airport with single (very busy) runway</li><li>Have “reservations” for future landings</li><li>When plane lands, it is removed from set of pending events</li><li>Reserve req specify “requested landing time” t</li><li>Add t to the set if no other landings are scheduled within k minutes either way. Assume that k can vary.</li><li>Algorithm: Keep R as a sorted list<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">init: R = [ ]</span><br><span class="line">req(t): if t &lt; now: return &quot;error&quot;</span><br><span class="line">for i in range (len(R)):</span><br><span class="line">    if abs(t-R[i]) &lt; k: return &quot;error&quot;</span><br><span class="line">R.append(t)</span><br><span class="line">R = sorted(R)</span><br><span class="line">land: t = R[0]</span><br><span class="line">if (t != now) return error</span><br><span class="line">R = R[1: ]          (drop R[0] from R)</span><br></pre></td></tr></table></figure></li></ul><p>If using sorted list:<br>Appending and sorting takes $Θ(nlg n)$ time. However, it is possible to insert new time/plane rather than append and sort but insertion takes $Θ(n)$ time. A k minute check can be done in O(1) once the insertion point is found.</p><p>If using Sorted array:<br>It is possible to do binary search to find place to insert in $O(lg n)$ time. Using binary search, we find the smallest i such that R[i] ≥ t, i.e., the next larger element. We then compare R[i] and R[i − 1] against t. Actual insertion however requires shifting elements which requires Θ(n) time.</p><p>If using Unsorted list/array:<br>k minute check takes O(n) time.</p><p>If using Min-Heap:<br>It is possible to insert in $O(lg n)$ time. However, the k minute check will require $O(n)$ time since we need to compare both sides of the heap.</p><p>If using Dictionary or Python Set:<br>Insertion is $O(1)$ time. k minute check takes $Ω(n)$ time</p><h3 id="Binary-Search-Trees-BST"><a href="#Binary-Search-Trees-BST" class="headerlink" title="Binary Search Trees (BST)"></a>Binary Search Trees (BST)</h3><p><strong>Properties</strong>:</p><ul><li>Each node x in the binary tree has a key $key(x)$.</li><li>Nodes other than the root have a parent p(x). </li><li>Nodes may have a left child left(x) and/or a right child right(x). These are pointers unlike in a heap</li><li>For any node x, for all nodes y in the left subtree of x, $key(y) ≤ key(x)$. For all nodes y in the right subtree of x $key(y) ≥ key(x)$.</li></ul><p><strong>Operations</strong>:</p><ul><li>insert(val): Follow left and right pointers till you find the position (or see the value)</li><li>find(val): Follow left and right pointers until you find it or hit NIL</li><li>findmin(): Key is to just go left till you cannot go left anymore.</li></ul><p><strong>Complexity</strong>:<br>All operations are $O(h)$ where h is height of the BST.</p><h4 id="Augmenting-the-BST-Structure"><a href="#Augmenting-the-BST-Structure" class="headerlink" title="Augmenting the BST Structure"></a>Augmenting the BST Structure</h4><p>When a data structure doesn’t support some of the operations that we need. Then we can often augment the data strucutre by adding a data member or two and an additional operation or two.</p><p>Rank(t): give the number of planes are scheduled to land at times ≤ t<br>Solution: by adding a subtree size memeber into the structure, like another key to the node</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;Preliminary-things&quot;&gt;&lt;a href=&quot;#Preliminary-things&quot; class=&quot;headerlink&quot; title=&quot;Preliminary things&quot;&gt;&lt;/a&gt;Preliminary things&lt;/h3&gt;&lt;h4 id=&quot;D
      
    
    </summary>
    
    
      <category term="Algorithm" scheme="http://tracyxinwang.site/blog/tags/Algorithm/"/>
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
  </entry>
  
  <entry>
    <title>MIT6006 Lec04 Priority queue and Heap</title>
    <link href="http://tracyxinwang.site/blog/2018/11/06/MIT6006-Lec04/"/>
    <id>http://tracyxinwang.site/blog/2018/11/06/MIT6006-Lec04/</id>
    <published>2018-11-06T02:48:56.000Z</published>
    <updated>2018-11-06T10:08:25.972Z</updated>
    
    <content type="html"><![CDATA[<p><br></p><h3 id="Priority-Queues"><a href="#Priority-Queues" class="headerlink" title="Priority Queues"></a>Priority Queues</h3><ul><li>Defination: A data structure implementing a set S of elements, each associated with a <strong>key</strong>.</li><li>Every element has its own key. And the key represents the priority of that element. Keys are not necessarily unique.</li><li>It supports the following operations:<ul><li><code>insert(S,x)</code>: insert element x into set S</li><li><code>max(S)</code>: return element of S with largest key</li><li><code>extract_max(S)</code>: return element of S with largest key and remove it from S</li><li><code>increase_key(S,x,k)</code>: increase the value of element x’ s key to new value k (assumed to be as large as current value)</li></ul></li></ul><h3 id="Heap"><a href="#Heap" class="headerlink" title="Heap"></a>Heap</h3><ul><li>Heap is an implementation of a priority queue</li><li>is also an <strong>array</strong> visualized as a nearly complete <em>binary tree</em></li><li>Heaps can be convert to max heap or min heap when sorting them.</li><li><strong>Max heap</strong>: the key of a node is ≥ than the keys of its children. (analogously as min heap)</li><li>Heap as a tree:<ul><li>Root of the tree: the first element (i=1) in the array</li><li>parent(i)=i/2: returns index of node’s parent</li><li>left(i)=2i: returns index of node’s left child</li><li>right(i)=2i+1: returns index of node’s right child</li><li>The height of a binary heap is $O(lg n)$</li></ul></li><li>Heap operations:<ul><li><code>build_max_heap</code>: produce a max-heap from an unordered array</li><li><code>max_heapify</code>: correct a single violation of the heap property in a subtree at its root</li><li><code>insert</code>, <code>extract_max</code>, <code>heapsort</code></li></ul></li></ul><p><strong>Max_heapify</strong>: </p><ul><li>the assumption is that the trees rooted at left(i) and right(i) are max-heaps. </li><li>If element A[i] violates the max-heap property, correct violation by “trickling” element A[i] down the tree, making the subtree rooted at index i a max-heap.</li><li>Pseudocode:  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">l = left(i)</span><br><span class="line">r = right(i)</span><br><span class="line"><span class="keyword">if</span> (l &lt;= heap-size(A) and A[l] &gt; A[i])</span><br><span class="line">    <span class="keyword">then</span> largest = l <span class="keyword">else</span> largest = i</span><br><span class="line"><span class="keyword">if</span> (r &lt;= heap-size(A) and A[r] &gt; A[largest])</span><br><span class="line">    <span class="keyword">then</span> largest = r</span><br><span class="line"><span class="keyword">if</span> largest != i</span><br><span class="line">    <span class="keyword">then</span> exchange A[i] and A[largest]</span><br><span class="line">Max_Heapify(A, largest)</span><br></pre></td></tr></table></figure></li></ul><p><strong>Build_Max_Heap</strong>:</p><ul><li>Converts A[1…n] to a max heap</li><li><p>Build_Max_Heap(A):</p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i=n/2 downto 1</span><br><span class="line"><span class="keyword">do</span> Max_Heapify(A, i)</span><br></pre></td></tr></table></figure></li><li><p>The reason to start at n/2 is that element A[n/2+1 … n] are all leaves. There is no need to build max_heap for leaves which has only one element (its own).</p></li><li>Time costs: $O(nlog n)$ via simple analysis</li><li>Observe however that Max_Heapify takes $O(1)$ for time for nodes that are one level above the leaves(叶子层的上一层，即倒数第二层)，$O(l)$ for the nodes that are $l$ levels above the leaves. There are n/4 nodes in level 1(即 倒数第二层), n/8 in level 2 (再往上的的一层) and so on till in $lg n$ level remains one root node.</li><li>Therefore, the total amount of work in the for loop is (括号里面的是那一层的Node个数):<br>$$\frac n4(1c) + \frac n8 (2c) + \frac n{16} (3c) + … + 1(lgn c)$$</li><li>set $\frac n4=2^k$简化上式可得：$c 2^k (\frac1{2^0}+\frac2{2^1}+\frac3{2^2}+ … + \frac{(k+1)}{2^k})$, 括号里面上界是个常数</li><li>Therefore, Build_max_heap is $O(n)$</li></ul><h3 id="Heap-sort"><a href="#Heap-sort" class="headerlink" title="Heap sort"></a>Heap sort</h3><ul><li>Sort strategy:<ol><li>Build Max Heap from unordered array;</li><li>Find maximum element A[1];</li><li>Swap elements A[n] and A[1]: now max element is at the end of the array!</li><li>Discard node n from heap (by decrementing heap-size variable)</li><li>New root may violate max heap property, but its children are max heaps. Run max_heapify to fix this.</li><li>Go to Step 2 unless heap is empty</li></ol></li><li>Running time:<ul><li>after n iterations the Heap is empty</li><li>every iteration involves a swap and a max_heapify operation; hence it takes O(log n) time</li><li>Overall $O(nlog n)$</li></ul></li><li>A nice demo here: <a href="https://www.geeksforgeeks.org/heap-sort/" target="_blank" rel="noopener">https://www.geeksforgeeks.org/heap-sort/</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3 id=&quot;Priority-Queues&quot;&gt;&lt;a href=&quot;#Priority-Queues&quot; class=&quot;headerlink&quot; title=&quot;Priority Queues&quot;&gt;&lt;/a&gt;Priority Queues&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;
      
    
    </summary>
    
    
      <category term="Algorithm" scheme="http://tracyxinwang.site/blog/tags/Algorithm/"/>
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
  </entry>
  
  <entry>
    <title>MATLAB 常用语法记录</title>
    <link href="http://tracyxinwang.site/blog/2018/11/06/notes-matlab/"/>
    <id>http://tracyxinwang.site/blog/2018/11/06/notes-matlab/</id>
    <published>2018-11-06T01:12:34.000Z</published>
    <updated>2018-11-25T22:28:21.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Matrix-处理"><a href="#Matrix-处理" class="headerlink" title="Matrix 处理"></a>Matrix 处理</h3><ul><li><p>将所有非零的元素变为1，为零的元素保持为0，使用 <code>~~</code>, 可用于二值化</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">A=~~A;</span><br></pre></td></tr></table></figure></li><li><p>Get indices of elements in upper triangle</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nNodes = size(adj,1);  % get the number of nodes in a matrix</span><br><span class="line">upperInds = find(triu(ones(nNodes),1));</span><br></pre></td></tr></table></figure></li><li><p>Sort the node strength and plot matrix by sorting results</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">stg = strengths_und(A)&apos;;</span><br><span class="line">[srtVals srtInds] = sort(stg);</span><br><span class="line">imagesc(log10(A(srtInds, srtInds)));</span><br></pre></td></tr></table></figure></li><li><p>Set infinite values to 0:</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">A(isinf(A))=0;</span><br></pre></td></tr></table></figure></li><li><p>Compute Euclidean distance and convert to matrix<br>  ···<br>  D = pdist(X)； % calculate the distance between pairs in X<br>  M = squareform(D) % convert to the symmetry matrix<br>  ···</p></li></ul><h4 id="画图"><a href="#画图" class="headerlink" title="画图"></a>画图</h4><ul><li><p>设置图像背景，位置：</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hf=figure; hf.Position=[100,350,600,300]; hf.Color=&apos;w&apos;;</span><br></pre></td></tr></table></figure></li><li><p>设置坐标轴用 <code>gca</code></p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ax = gca; % current axes</span><br><span class="line">ax.FontSize = 12;</span><br><span class="line">ax.XTick = [0 0.1000 0.2000 0.3000 0.4000 0.5000 0.6000 0.7000 0.8000 0.9000 1];</span><br><span class="line">ax.XTickLabel = [0.02 0.02];</span><br><span class="line">ax.XLim = [-2 2];</span><br></pre></td></tr></table></figure></li><li><p>去掉坐标轴，按像素实际大小画图</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">axis off; axis equal;</span><br></pre></td></tr></table></figure></li><li><p>Scatter plot matrix: diagonal are replaced with histogram plots of the data in the corresponding column of X. Off-diagonal parts are scatter plots of the columns of X against other columns of X. </p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X = randn(50,3); </span><br><span class="line">plotmatrix(X)</span><br></pre></td></tr></table></figure></li></ul><h3 id="Read-and-write-file"><a href="#Read-and-write-file" class="headerlink" title="Read and write file"></a>Read and write file</h3><ul><li><p>Read nii file</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hdr,data]=read(filename)</span><br></pre></td></tr></table></figure></li><li><p>Write to a txt file </p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dlmwrite(&apos;coords.txt&apos;,coords,&apos;delimiter&apos;,&apos; &apos;);</span><br><span class="line">dlmwrite(&apos;matrix.txt&apos;,A,&apos;delimiter&apos;,&apos; &apos;);</span><br></pre></td></tr></table></figure></li><li><p>Combine data into a table with column headers</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">att = array2table([ci stg degree clust], &apos;VariableNames&apos;, &#123;&apos;module&apos;,&apos;strength&apos;,&apos;degree&apos;,&apos;clustering&apos;&#125;);</span><br><span class="line">writetable(att, &apos;attributes.txt&apos;,&apos;delimiter&apos;,&apos; &apos;);</span><br></pre></td></tr></table></figure></li></ul><h3 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h3><ul><li><p>在命令行窗口输出</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fprintf(&apos;Subject: %0.3f\n&apos;,some_value);</span><br></pre></td></tr></table></figure></li><li><p>Get the running time of code</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tic</span><br><span class="line">code here</span><br><span class="line">toc</span><br></pre></td></tr></table></figure></li><li><p><code>diff</code> function: to calculate the incremental change between each pair of values in an array.</p></li><li><code>linspace</code> function: creates a vector of n equally spaced elements between any two values, x1 and x2. <code>x = linspace(x1,x2,n)</code></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;Matrix-处理&quot;&gt;&lt;a href=&quot;#Matrix-处理&quot; class=&quot;headerlink&quot; title=&quot;Matrix 处理&quot;&gt;&lt;/a&gt;Matrix 处理&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;将所有非零的元素变为1，为零的元素保持为0，使用 &lt;code&gt;~~
      
    
    </summary>
    
    
      <category term="Notes" scheme="http://tracyxinwang.site/blog/tags/Notes/"/>
    
      <category term="Matlab" scheme="http://tracyxinwang.site/blog/tags/Matlab/"/>
    
  </entry>
  
  <entry>
    <title>MIT6006 Lec03 插入排序，归并排序</title>
    <link href="http://tracyxinwang.site/blog/2018/11/05/MIT6006-Lec03/"/>
    <id>http://tracyxinwang.site/blog/2018/11/05/MIT6006-Lec03/</id>
    <published>2018-11-05T12:37:44.000Z</published>
    <updated>2018-11-05T10:23:06.030Z</updated>
    
    <content type="html"><![CDATA[<p>排序总的问题就是：<br>输入一个序列 <code>A[1···n]</code><br>要求输求它的递增排序之后的排列。</p><h3 id="插入排序-Insertion-sort"><a href="#插入排序-Insertion-sort" class="headerlink" title="插入排序 (Insertion sort)"></a>插入排序 (Insertion sort)</h3><p><strong>Pseudocode</strong><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> j = 2:n</span><br><span class="line">    insert key A[j] into the already sorted sub array A[1 ... j-1] by pairwise key-swaps down to its right position.</span><br></pre></td></tr></table></figure></p><p><strong>Complexity</strong>: $\theta(n^2)$<br>because at the worst case, it needs $\theta(n^2)$ compares and $\theta(n^2)$ swaps.</p><h4 id="Binary-Insertion-sort"><a href="#Binary-Insertion-sort" class="headerlink" title="Binary Insertion sort"></a>Binary Insertion sort</h4><p>注意到在一般的插入排序中，我们会得到一个已经排好序的子序列，那么这时其实就可以用二分查找法来替代之前的逐个compare，这样能减少compare的次数。<br><strong>Pseudocode</strong><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> j = 2:n</span><br><span class="line">    insert key A[j] into the already sorted sub array A[1 ... j-1]</span><br><span class="line">    Use binary search to find the right position</span><br></pre></td></tr></table></figure></p><p>二分查找法花费 $\theta(log n)$ 时间，插入之后移动元素花费 $\theta(n)$ 时间。<br><strong>Complexity</strong>:<br>$\theta(nlog n)$ comparisons, $\theta(n^2)$ swaps</p><h3 id="归并排序-Merge-Sort"><a href="#归并排序-Merge-Sort" class="headerlink" title="归并排序 (Merge Sort)"></a>归并排序 (Merge Sort)</h3><p>采用的是 divide and conquer 的思想。<br><strong>Pseudocode</strong><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">If n = 1, <span class="keyword">done</span> (nothing to sort)</span><br><span class="line">Otherwise, recursively sort A[1 ... n/2] and A[n/2+1 ... n]</span><br><span class="line"><span class="string">"Merge"</span> the two sorted sub-arrays</span><br></pre></td></tr></table></figure></p><p><strong>Complexity</strong>:<br>$\theta(n)$ to merge a total of n elements(linear time)<br>$T(n) = 2T(n/2) + \theta(n)$<br>After plotting the recursion tree, we can find that there are <code>1+lgn</code> layers, and <code>n</code> leaves in the tree. And for each layer, it totally costs <code>cn</code> time. Therefore, complexity is  $\theta(nlg n)$<br>可以看到，在这个树里面，每一层的complexity都是均等的<br><img src="/blog/images/MIT03_01.jpg" width="80%" height="60%"></p><h3 id="Solving-Recurrences"><a href="#Solving-Recurrences" class="headerlink" title="Solving Recurrences"></a>Solving Recurrences</h3><p>对于不同的recurrence tree来说，每一层不同的cost决定了它的complexity主要集中在哪里。<br>如上面的归并排序是每一层都占相等的复杂度。<br>下面是两个例子：<br><strong>叶子部分的计算占主要复杂度</strong>:</p><p><img src="/blog/images/MIT03_02.jpg" width="80%" height="60%"></p><p><strong>根部分的计算占主要复杂度</strong>:</p><p><img src="/blog/images/MIT03_03.jpg" width="80%" height="60%"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;排序总的问题就是：&lt;br&gt;输入一个序列 &lt;code&gt;A[1···n]&lt;/code&gt;&lt;br&gt;要求输求它的递增排序之后的排列。&lt;/p&gt;
&lt;h3 id=&quot;插入排序-Insertion-sort&quot;&gt;&lt;a href=&quot;#插入排序-Insertion-sort&quot; class=&quot;head
      
    
    </summary>
    
    
      <category term="Algorithm" scheme="http://tracyxinwang.site/blog/tags/Algorithm/"/>
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
  </entry>
  
  <entry>
    <title>猫本交流杂记（一）</title>
    <link href="http://tracyxinwang.site/blog/2018/11/04/life-in-Melbourne01/"/>
    <id>http://tracyxinwang.site/blog/2018/11/04/life-in-Melbourne01/</id>
    <published>2018-11-03T22:20:34.000Z</published>
    <updated>2018-11-04T00:03:51.000Z</updated>
    
    <content type="html"><![CDATA[<p>算下来来墨尔本接近半个月了，从10月16号落地到现在，对这边整个center和研究也有些感悟和感慨，就随手记一点吧。</p><p>今天主要想来说说这边搞研究和国内乃至香港搞研究的一个比较相反的现象。</p><p>有天晚上弄得比较晚（其实也就7点多，但办公室基本没人了…），我们三个中国人（两个PhD学生一个PostDoc）说一起出去吃，然后正好我们老板(澳洲土著)也在，他就说他也一起。这在国内应该是比较少见的，一般来说教授是很少跟自己的学生一起吃饭的，一起吃饭的情况大都是整个实验室聚餐这种。然后我们就一起出去吃了，在一个中国馆子里，期间老板一直负责给我们倒茶水… 看来他已经习惯了中国的饭桌文化。。。</p><p>饭间大家讨论到国内各个阶层都追求学位这个现象，说不管怎么样，大家都想努力地去拿本科甚至研究生的学位，因为这在某种程度上代表着一种地位，也意味着将来出来工资的高收入。土著老板就很不解，他说现实社会实际上是哪怕没有读过书的人，也能赚大钱，做生意会做得很好，为什么还要去拿学位，赚钱不就是这个目的吗，那达到这个目的的方式并不一定要读书啊，你可以说 “Hey look, I have a new car. I don’t care if I have that degree”。这就反应了中外国家思维和心态上的不同，实际上也是社会发展程度的一种映射。</p><p>在澳洲，不管你做什么，你都能挣很多钱，很多体力或者技工的活儿，挣得不比一个教授的工资少，反而真的是一些白领阶层，才是挣得最少的。对大多数人来说，还没有到“兼济天下”这种情怀，那么其实挣钱就是他们的最终目的，只要能挣钱就行，还读什么书呢，不读书都比你读那么多年的书还挣得多，何必呢。所以在澳洲，那些读研究生的，甚至读PhD的，真的是对科研的热爱才会去做的，因为或许他们有更好的选择去挣大钱，但他们还是想搞搞研究，因为这样他们才觉得真的快乐。所以这也是为什么他们能做出很好的成果的原因吧，毕竟是因为热爱，是真的想去探索。</p><p>但在国内和香港不一样，读PhD的目的是为了挣钱，是为了将来有更好的生活，这是社会和人口决定了的，根本还没有精力去追求更高层次的热爱，因为你需要去考虑生活甚至生存。这也是为什么很多PhD读得很痛苦(包括我自己)，读到一半不读了，或者读着读着跑去学cs了。如果每天考虑的是我什么时候才能毕业，做哪个方向更赚钱，那你又怎么有时间去考虑如何把科研做到极致这种事情呢？</p><p>还是有点遗憾吧。少了真正对某个事情的激情和热情，人生会少了很多乐趣的。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;算下来来墨尔本接近半个月了，从10月16号落地到现在，对这边整个center和研究也有些感悟和感慨，就随手记一点吧。&lt;/p&gt;
&lt;p&gt;今天主要想来说说这边搞研究和国内乃至香港搞研究的一个比较相反的现象。&lt;/p&gt;
&lt;p&gt;有天晚上弄得比较晚（其实也就7点多，但办公室基本没人了…）
      
    
    </summary>
    
    
      <category term="杂文" scheme="http://tracyxinwang.site/blog/tags/%E6%9D%82%E6%96%87/"/>
    
      <category term="碎碎念" scheme="http://tracyxinwang.site/blog/tags/%E7%A2%8E%E7%A2%8E%E5%BF%B5/"/>
    
  </entry>
  
  <entry>
    <title>Notes - NodeJS 学习（一）</title>
    <link href="http://tracyxinwang.site/blog/2018/11/04/NodeJS-learning01/"/>
    <id>http://tracyxinwang.site/blog/2018/11/04/NodeJS-learning01/</id>
    <published>2018-11-03T22:16:34.000Z</published>
    <updated>2018-11-04T00:11:51.430Z</updated>
    
    <content type="html"><![CDATA[<p>The following are just some notes when I learn NodeJS. Most of the contents are taken from others. The references have been listed in the end.<br>The reason I want to learn it is just because that I need to write codes for my websites…</p><hr><h2 id="NodeJS-Basics"><a href="#NodeJS-Basics" class="headerlink" title="NodeJS Basics"></a>NodeJS Basics</h2><h3 id="What-is-NodeJS"><a href="#What-is-NodeJS" class="headerlink" title="What is NodeJS?"></a>What is NodeJS?</h3><p>在了解NodeJS之前，先要了解JS，JS就是JavaScript, 是一种脚本语言(scripting language)，它运行在浏览器中。那什么是脚本语言呢? 脚本语言其实也是一种编程语言(programming language). 传统的编程语言是会有这几个步骤的：编写-编译-链接-运行(edit-compile-link-run)。脚本语言与一般的编程语言的区别在于，他们没有编译(compilation)这个过程，而是通过一种解释的形式来运行。通常来讲，编译型的语言会运行得比解释型语言快，因为他们先转化为及其语言，并且编译器只会读和分析一次代码，最后汇总所有的errors出来。但解释型语言则会在每次遇到一个错误的时候都停下来，而非汇总。<br>扯远了，那JS是一个脚本语言的话，就需要一个<strong>解析器</strong>才能运行，对于写在HTML页面里的JS，浏览器充当了解析器的角色。而对于需要独立运行的JS，NodeJS就是一个解析器。<br>任何操作系统下安装NodeJS本质上做的事情都是把NodeJS执行程序复制到一个目录，然后保证这个目录在系统PATH环境变量下，以便终端下可以使用node命令。</p><h3 id="安装及运行"><a href="#安装及运行" class="headerlink" title="安装及运行"></a>安装及运行</h3><h4 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h4><p>在Windows下，在<a href="https://nodejs.org/en/" target="_blank" rel="noopener">官网</a>上下载好后，直接运行.msi安装文件即可</p><h4 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h4><ul><li>在终端运行：Windows下，cmd进入终端，输入 <code>node</code> 就可以进入交互模式了，及之后的运行环境都是在NodeJS下，想退出的话输入 <code>.exit</code></li><li>运行JS文件：当要运行大段代码时，在终端编写代码不是很方便，这时就可以先写一个JS文件(以.js结尾储存)，然后再运行这个文件，假如JS文件名为”hello.js”, 在命令行输入 <code>node hello.js</code> 就可以运行这个脚本程序了。</li></ul><h3 id="模块"><a href="#模块" class="headerlink" title="模块"></a>模块</h3><ul><li>在编写大型程序时，一般都会将程序模块化，及分成一个一个的子程序。这些子程序在js中就是一个一个的不同的js文件，每个文件就是一个模块，文件路径就是模块名。</li><li>在编写每个模块时，都有<code>require</code>、<code>exports</code>、<code>module</code> 三个预先定义好的变量可供使用。</li><li><strong>require</strong><ul><li>用于在当前模块中加载和使用别的模块，传入一个模块名，返回一个模块导出对象。</li><li>模块名可使用相对路径（以./开头），或者是绝对路径（以/或C:之类的盘符开头）。</li><li>另外，模块名中的.js扩展名可以省略</li><li>e.g. <code>var foo1 = require(&#39;./foo&#39;);</code>, <code>var foo2 = require(&#39;./foo.js&#39;);</code>, <code>var foo3 = require(&#39;/home/user/foo&#39;);</code>, <code>var foo4 = require(&#39;/home/user/foo.js&#39;);</code> 都是指导入同一个模块</li></ul></li><li><strong>exports</strong><ul><li>是当前模块的导出对象，用于导出模块公有方法和属性。</li><li>别的模块通过require函数使用当前模块时得到的就是当前模块的exports对象。</li></ul></li><li><strong>module</strong><ul><li>通过<code>module</code>对象可以访问到当前模块的一些相关信息，但最多的用途是替换当前模块的导出对象。</li></ul></li><li><strong>模块初始化</strong>: 一个模块中的JS代码仅在模块第一次被使用时执行一次，并在执行过程中初始化模块的导出对象。之后，缓存起来的导出对象被重复利用。简单点，所有模块都只初始化一次。</li><li><strong>主模块</strong>：<ul><li>即 负责调度组成整个程序的其它模块完成工作。</li><li>通过命令行参数传递给NodeJS以启动程序的模块被称为主模块。</li></ul></li></ul><h2 id="代码的组织和部署"><a href="#代码的组织和部署" class="headerlink" title="代码的组织和部署"></a>代码的组织和部署</h2><h3 id="模块路径的解析"><a href="#模块路径的解析" class="headerlink" title="模块路径的解析"></a>模块路径的解析</h3><p>我们在写程序时会用到 <code>require</code> 来告诉程序需要用到哪些模块，让你程序就会去找这些模块，找这些模块的过程就叫做路径解析。那怎么去找呢，分两种情况：</p><ul><li>如果是内置模块，即自带的那种，就不做路径解析</li><li>node_module目录：这是NodeJS定义的一个专门用来存放模块的目录，在加载某个非内置模块时，NodeJS就会去找 <code>node_module</code>这个文件夹。其实在用Hexo创建静态网页时，你就会发现在你创建的hexo项目下就有个<code>node_modules</code> 文件夹。</li><li>NODE_PATH环境变量：NodeJS允许通过<code>NODE_PATH</code>环境变量来指定额外的模块搜索路径。<h3 id="包-Package"><a href="#包-Package" class="headerlink" title="包(Package)"></a>包(Package)</h3>JS模块的基本单位是单个JS文件，但复杂些的模块往往由多个子模块组成。为了便于管理和使用，我们可以把由多个子模块组成的大模块称做包，并把所有子模块放在同一个目录里。<br>在组成一个包的所有子模块中，需要有一个入口模块，入口模块的导出对象被作为包的导出对象。</li><li>在其它模块里使用包的时候，需要加载包的入口模块。可以直接使用require加上入口模块名称的路径来加载。但是这样不简洁，要让包使用起来更像是单个模块的话，就将模块的文件名设为<code>index.js</code>，这样即使在require路径上不出现index这个名称，程序也会知道这个<code>index.js</code>就是入口模块。</li><li>使用<code>package.json</code> 可以自定义入口模块的文件名和存放位置，即：在包目录下包含一个<code>package.json</code> 文件，并在其中指定入口模块的路径:<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="string">"name"</span>: modulename</span><br><span class="line">    <span class="string">"main"</span>: <span class="string">"./lib/main.js"</span> <span class="comment"># 这里就指定入口模块的路径</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h3 id="工程目录"><a href="#工程目录" class="headerlink" title="工程目录"></a>工程目录</h3><p>标准如下：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">- /home/user/workspace/node-echo/   <span class="comment"># 工程目录</span></span><br><span class="line">    - bin/                          <span class="comment"># 存放命令行相关代码</span></span><br><span class="line">        node-echo</span><br><span class="line">    + doc/                          <span class="comment"># 存放文档</span></span><br><span class="line">    - lib/                          <span class="comment"># 存放API相关代码</span></span><br><span class="line">        echo.js</span><br><span class="line">    - node_modules/                 <span class="comment"># 存放三方包</span></span><br><span class="line">        + argv/</span><br><span class="line">    + tests/                        <span class="comment"># 存放测试用例</span></span><br><span class="line">    package.json                    <span class="comment"># 元数据文件</span></span><br><span class="line">    README.md                       <span class="comment"># 说明文件</span></span><br></pre></td></tr></table></figure></p><h3 id="关于NPM"><a href="#关于NPM" class="headerlink" title="关于NPM"></a>关于NPM</h3><p>NPM是随同NodeJS一起安装的包管理工具，能解决NodeJS代码部署上的很多问题，常见的使用场景有以下几种：</p><ul><li>允许用户从NPM服务器下载别人编写的三方包到本地使用。</li><li>允许用户从NPM服务器下载并安装别人编写的命令行程序到本地使用。</li><li>允许用户将自己编写的包或命令行程序上传到NPM服务器供别人使用。</li></ul><p><a href="http://nqdeng.github.io/7-days-nodejs/#2.5" target="_blank" rel="noopener">七天学会NodeJS</a>上在NPM这个讲解上很详细，推荐看一看。</p><p><br></p><p>Reference:<br><a href="http://nqdeng.github.io/7-days-nodejs/" target="_blank" rel="noopener">http://nqdeng.github.io/7-days-nodejs/</a><br><a href="https://www.geeksforgeeks.org/whats-the-difference-between-scripting-and-programming-languages/" target="_blank" rel="noopener">https://www.geeksforgeeks.org/whats-the-difference-between-scripting-and-programming-languages/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;The following are just some notes when I learn NodeJS. Most of the contents are taken from others. The references have been listed in the
      
    
    </summary>
    
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
      <category term="NodeJS" scheme="http://tracyxinwang.site/blog/tags/NodeJS/"/>
    
  </entry>
  
  <entry>
    <title>MIT6006 Lec02 Models of Computation</title>
    <link href="http://tracyxinwang.site/blog/2018/11/03/MIT6006-Lec02/"/>
    <id>http://tracyxinwang.site/blog/2018/11/03/MIT6006-Lec02/</id>
    <published>2018-11-02T23:45:44.000Z</published>
    <updated>2018-11-03T04:40:14.518Z</updated>
    
    <content type="html"><![CDATA[<h3 id="What-is-model-of-computation"><a href="#What-is-model-of-computation" class="headerlink" title="What is model of computation?"></a>What is model of computation?</h3><p>Model of computation specifies</p><ul><li>what <strong>operations</strong> an algorithm is allowed</li><li><strong>cost</strong> (time, space, . . . ) of each operation</li><li>cost of algorithm = sum of operation costs</li></ul><p>The followings are two kinds of models of computation.</p><h3 id="Random-Access-Machine-RAM"><a href="#Random-Access-Machine-RAM" class="headerlink" title="Random Access Machine (RAM)"></a>Random Access Machine (RAM)</h3><ul><li>It is modeled by a big array. </li><li>For each word, it registers $\theta(1)$</li><li>In $\theta(1)$ time, it can<ul><li>load word</li><li>compute (+,-,*,/,&amp;,|,^) on registers</li><li>store register $r_j$ into memory</li></ul></li><li>What is a word: <ul><li>assume basic objects (e.g. int) fit in word</li></ul></li><li>It is realistic and powerful → implement abstractions</li></ul><h3 id="Pointer-machine"><a href="#Pointer-machine" class="headerlink" title="Pointer machine"></a>Pointer machine</h3><ul><li>can dynamically allocated objects</li><li>object has $O(1)$ fields</li><li>field = word (e.g., int) or pointer to object/null (a.k.a. reference)</li><li>weaker than RAM</li></ul><h3 id="Python-model"><a href="#Python-model" class="headerlink" title="Python model"></a>Python model</h3><p>Python lets you use either mode of thinking, e.g.</p><ul><li>“list” is acutually an array in RAM:<br>  &emsp; &nbsp; L[i] = L[j] + 5: this operation only costs $\theta(1)$ time (constant time)</li><li>object with $O(1)$ attributes (including references) is like a pointer machine<br>  &emsp; &nbsp; $x=x.next$ costs $\theta(1)$ time</li></ul><p>The following are some operations and their costs in Python. To determine their cost, imagine implementation in terms of the above two models(RAM or Pointer). </p><ol><li><strong>list</strong><br> (a) L.append(x): $\theta(1)$ time.  (It uses table doubling)<br> (b) L = L1+L2 ≡<br> &emsp; L = []: cost $\theta(1)$ time to build a list<br> &emsp; for x in L1: L.append(x) costs $\theta(1)$. Totally in L1 is $\theta(|L1|)$<br> &emsp; for x in L2: L.append(x) costs $\theta(1)$. Totally in L2 is $\theta(|L2|)$<br> Therefore, L = L1+L2 costs $\theta(1+|L1|+|L2|)$ time<br> (c) L1.extend(L2) ≡<br>  &emsp; for x in L2: L1.append(x) costs θ(1). Totally $\theta(|L2|)$<br>  &emsp; ≡ L1+ = L2<br> Therefore, costs θ(1 + |L2|) time<br> (d) L2 = L1[i : j] ≡<br>   &emsp; L2 = []: θ(1)<br>   &emsp; for k in range(i, j): L2.append(L1[i]) costs θ(1)<br>  Therefore, costs $θ(j − i + 1) = O(|L|)$<br> (e) len(L):  $θ(1)$ time - since list stores its length in a field<br> (f) L.sort(): $θ(|L|log |L|)$ - via comparison sort </li><li><strong>tuple, str</strong>: similar</li><li><strong>dict</strong>: via hashing, costs $θ(1)$ time</li><li><strong>set</strong>: similar (think of as dict without vals)</li><li><strong>heapq</strong>: heappush &amp; heappop - via heaps → $θ(log(n))$ time</li><li><strong>long</strong>: via Karatsuba algorithm<br> &emsp; x + y → O(|x| + |y|) time where |y| reflects # words<br> &emsp; x ∗ y → O((|x| + |y|)log(3)) ≈ O((|x| + |y|)1.58) time</li></ol><h3 id="Document-Distance-Problem-—-compute-d-D1-D2"><a href="#Document-Distance-Problem-—-compute-d-D1-D2" class="headerlink" title="Document Distance Problem — compute d(D1, D2)"></a>Document Distance Problem — compute d(D1, D2)</h3><p>The problem is acutually to find similarity in documents, and have application in detecting duplicates, plagiarism, and also in web search (D2 = query).<br>In this problem, we define word as the sequence of alphanumeric characters, and document as a sequence of words (ignore space, punctuation).</p><p>The idea is to define distance in terms of <strong>shared words</strong>. Think of document D as a vector:<br>If three axis are defined as three words: the, dog, cat<br>Then vector v1 could be “the cat”, vector v2 could be “the dog”, vector v3 could be “cat dog”</p><p>After looking them as vectors, then we can apply mathematical methods to calculate the distance between these vectors like angle </p><p>The algorithm can be formed as follows:</p><ol><li>split each document into words</li><li>count word frequencies (document vectors)</li><li>compute dot product (&amp; divide)</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;What-is-model-of-computation&quot;&gt;&lt;a href=&quot;#What-is-model-of-computation&quot; class=&quot;headerlink&quot; title=&quot;What is model of computation?&quot;&gt;&lt;/a&gt;W
      
    
    </summary>
    
    
      <category term="Algorithm" scheme="http://tracyxinwang.site/blog/tags/Algorithm/"/>
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
  </entry>
  
  <entry>
    <title>Hexo deploy 出现问题</title>
    <link href="http://tracyxinwang.site/blog/2018/10/30/problem-hexo-deploy/"/>
    <id>http://tracyxinwang.site/blog/2018/10/30/problem-hexo-deploy/</id>
    <published>2018-10-30T02:54:31.000Z</published>
    <updated>2018-10-30T00:18:32.000Z</updated>
    
    <content type="html"><![CDATA[<p>也不知道怎么回事办公室的电脑突然重启了，可能是更新吧，但是更新完了回来发现hexo generate 和 deploy 并不能使用了<br>最开始报的错是 <code>Node 不是内部或外部命令</code>，一看是 node.js 的环境变量没有配置，很奇怪，之前明明是OK的，然后我就在环境变量里面配置了一下node，步骤如下：</p><ul><li>右键<code>我的电脑-属性-高级系统设置</code></li><li>找到下面有个<code>环境变量</code>的选择框，点进去</li><li>此时出来的对话框中有上下两个部分，上面的部分属于<code>用户变量</code>，找到里面有一行是 <code>path</code>，点击<code>编辑</code></li><li>新建一个变量，把node.js所在的路径拷进去就行了，我的是 <code>D:\Program Files\nodejs</code></li></ul><p>然后 <code>hexo generate</code> 就可以了，deploy的时候发现出现以下问题：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">FATAL Something<span class="string">'s wrong. Maybe you can find the solution here: http://hexo.io/docs/troubleshooting.html</span></span><br><span class="line"><span class="string">Error: spawn git ENOENT</span></span><br><span class="line"><span class="string">at notFoundError (C:\Users\XXX\hexo\node_modules\cross-spawn\lib\enoent.js:11:11)</span></span><br><span class="line"><span class="string">at verifyENOENT (C:\Users\XXX\hexo\node_modules\cross-spawn\lib\enoent.js:46:16)</span></span><br><span class="line"><span class="string">at ChildProcess.cp.emit (C:\Users\XXX\hexo\node_modules\cross-spawn\lib\enoent.js:33:19)</span></span><br><span class="line"><span class="string">at Process.ChildProcess._handle.onexit (internal/child_process.js:198:12)</span></span><br></pre></td></tr></table></figure></p><p>那个XXX是hexo所在文件的路径，这里就不放出来了。<br>解决这个的问题最直接的办法就是直接在hexo的当前文件夹下，运行 <code>git bash</code> 然后在bash 处运行 <code>hexo deploy</code>…</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;也不知道怎么回事办公室的电脑突然重启了，可能是更新吧，但是更新完了回来发现hexo generate 和 deploy 并不能使用了&lt;br&gt;最开始报的错是 &lt;code&gt;Node 不是内部或外部命令&lt;/code&gt;，一看是 node.js 的环境变量没有配置，很奇怪，之前明明是
      
    
    </summary>
    
    
      <category term="Hexo" scheme="http://tracyxinwang.site/blog/tags/Hexo/"/>
    
  </entry>
  
  <entry>
    <title>Algorithm - 模拟退火 Simulated Annealing</title>
    <link href="http://tracyxinwang.site/blog/2018/10/29/simulated-annealing/"/>
    <id>http://tracyxinwang.site/blog/2018/10/29/simulated-annealing/</id>
    <published>2018-10-29T01:01:51.000Z</published>
    <updated>2018-10-30T00:19:20.843Z</updated>
    
    <content type="html"><![CDATA[<p>模拟退火（SA）是拿来找给定函数的近似全局最优的。一般当搜索空间是离散的时，经常使用它。模拟退火算法最初是受到金属加工时退火过程的启发来的。在真正的金属冶炼过程中，通过给金属降温，金属的形态就会固定。而在模拟退火中，我们会设置 “温度” 这个变量，来模拟这个过程。 初始时，将其设置为高，然后在算法运行时让它慢慢“冷却”。当这个变量“温度”很高时，算法会更允许接受比当前解更差的解(即高温时，金属可以改变的力度和形状可以更大)。这能够让算法不局限在之前发现的任何local optimum上。随着温度的降低，接受更差解的机会就越小，因此允许算法逐渐集中在搜索空间的一个区域，来找到近最优解。这个渐进的“冷却”过程能够让模拟退火算法在处理包含大量局部最优解的大问题时非常有效地找到接近的最优解。</p><h3 id="Acceptance-Function"><a href="#Acceptance-Function" class="headerlink" title="Acceptance Function:"></a>Acceptance Function:</h3><p>决定一个solution是否被接受的步骤如下：</p><ol><li>看下一个解是否优于当前解，如果是，则无条件接受</li><li>如果不是，根据以下几个方面考虑要不要接受：<ul><li>下一个解有多差？</li><li>当前系统的 “温度” 有多高？<br>数学表达式如下：<br>$$exp(\frac{solutionEnergy - neighborEnergy}{Temperature})$$<br>即：系统能量变得越小，温度越高，越会接受这个解。是否接受解根据一个随机的概率来的</li></ul></li></ol><p>算法描述如下：</p><ol><li>设置温度变量初始值，随机初始化一个解</li><li>循环直到停止条件达到：一般为系统足够”冷却” 或 最优的解已经找到<ul><li>通过较小地改变当前解来确定下一个解</li><li>决定是否跳去下一个解（用上面的Acception function）</li></ul></li><li>降低温度，继续循环</li></ol><h3 id="Pseudo-Code"><a href="#Pseudo-Code" class="headerlink" title="Pseudo Code"></a>Pseudo Code</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">int temperature = m;</span><br><span class="line">create a collection of best solutions found</span><br><span class="line"><span class="keyword">while</span> (temperature meets the condition)&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (accept(curr_sol, next_sol, temperature)) curr_sol = next_sol;</span><br><span class="line">    <span class="keyword">if</span> (curr_sol &lt; best) best = add curr_sol to best collection;</span><br><span class="line">    temperature *= (1-coolingRate) </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">accept(curr_sol, next_sol, temperature)&#123;</span><br><span class="line">    <span class="keyword">if</span> (next_sol &lt; curr_sol) <span class="built_in">return</span> <span class="literal">true</span>;</span><br><span class="line">    <span class="built_in">return</span> exp((curr_sol-next_col)/temperature) &gt; rand() <span class="comment"># 以一个随机的概率接受</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><br></p><p>Reference:<br><a href="http://www.theprojectspot.com/tutorial-post/simulated-annealing-algorithm-for-beginners/6" target="_blank" rel="noopener">http://www.theprojectspot.com/tutorial-post/simulated-annealing-algorithm-for-beginners/6</a><br><a href="http://mathworld.wolfram.com/SimulatedAnnealing.html" target="_blank" rel="noopener">http://mathworld.wolfram.com/SimulatedAnnealing.html</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;模拟退火（SA）是拿来找给定函数的近似全局最优的。一般当搜索空间是离散的时，经常使用它。模拟退火算法最初是受到金属加工时退火过程的启发来的。在真正的金属冶炼过程中，通过给金属降温，金属的形态就会固定。而在模拟退火中，我们会设置 “温度” 这个变量，来模拟这个过程。 初始时，
      
    
    </summary>
    
    
      <category term="Algorithm" scheme="http://tracyxinwang.site/blog/tags/Algorithm/"/>
    
      <category term="Learning" scheme="http://tracyxinwang.site/blog/tags/Learning/"/>
    
  </entry>
  
  <entry>
    <title>DTI Basics</title>
    <link href="http://tracyxinwang.site/blog/2018/10/23/DTI-basics/"/>
    <id>http://tracyxinwang.site/blog/2018/10/23/DTI-basics/</id>
    <published>2018-10-22T23:01:51.000Z</published>
    <updated>2018-10-28T03:30:43.000Z</updated>
    
    <content type="html"><![CDATA[<p>You will also need to acquire a reference image with no diffusion information to calculate the ADC value (divide diffusion scan by reference scan). You can vary the amount of diffusion weighting (level of sensitivity to diffusion). The amount of diffusion weighting is measured by the b-value. If the b-value equals 0, there is no diffusion weighting (reference scan). If the diffusion value is very high, you can get greater resolution, but also more noise. The standard b-value for adults is 1000. In children, you typically use 600. If looking outside the brain, typically around 500.</p><p>converted to NIfTI format and includes the b-values and gradient idrections: .bval and .bvec</p><p> mean B0 image is not sensitive to diffusion direction.<br>in diffusion image, the brightness varies dramatically in the white matter depending on the alignment of the fibers. More diffusion yields a darker pixel because you lose signal as the water molecule can go anywhere. Higher ADC values mean it can go very far without interruption, and it takes the signal with it. This is not necessarily related to anisotropy. </p><p>Eddy current correction of DTI data is analogous to motion correction of fMRI data.</p><h3 id="Processing-Data-with-FSL’s-FDT-Diffusion"><a href="#Processing-Data-with-FSL’s-FDT-Diffusion" class="headerlink" title="Processing Data with FSL’s FDT Diffusion"></a>Processing Data with FSL’s FDT Diffusion</h3><p>The reference volume is typically 0 (this is the volume with a b-value of 0, dcm2nii should automatically ensure that the initial volume is the volume with zero b-value, but you should ensure this is correct with your data which you can do by viewing the volumes with MRIcron).</p><p>The basic processing pipeline has the following elements:<br>Convert data from scanner to scalar image<br>Run distortion correction<br>EPI distortion correction with fieldmap/TOPUP<br>Eddy current correction<br>Brain extraction<br>Tensor fitting<br>Produce scalars (FA, MD, AD, RD, RGB)</p><p>Advanced processing:<br>Normalization<br>Scalar normalization, or<br>Tensor normalization<br>Fiber tracking<br>Deterministic, or<br>Probabilistic<br>Whole brain analysis<br>Voxel-based analysis, or<br>Track-based analysis</p><p>步骤：FA -&gt; Tensors -&gt; Fiber tracking -&gt; white matter delineation</p><p><a href="http://www.cabiatl.com/Resources/Course/tutorial/html/dti.html" target="_blank" rel="noopener">http://www.cabiatl.com/Resources/Course/tutorial/html/dti.html</a><br><a href="http://brainimaging.waisman.wisc.edu/~tromp/DTI_101.pdf" target="_blank" rel="noopener">http://brainimaging.waisman.wisc.edu/~tromp/DTI_101.pdf</a><br><a href="http://www.diffusion-imaging.com/2015/10/dti-tutorial-1-from-scanner-to-tensor.html" target="_blank" rel="noopener">http://www.diffusion-imaging.com/2015/10/dti-tutorial-1-from-scanner-to-tensor.html</a><br><a href="https://mrtrix.readthedocs.io/en/latest/quantitative_structural_connectivity/ismrm_hcp_tutorial.html" target="_blank" rel="noopener">https://mrtrix.readthedocs.io/en/latest/quantitative_structural_connectivity/ismrm_hcp_tutorial.html</a><br><a href="http://dbic.dartmouth.edu/wiki/index.php/Diffusion_Tensor_Imaging_Analysis" target="_blank" rel="noopener">http://dbic.dartmouth.edu/wiki/index.php/Diffusion_Tensor_Imaging_Analysis</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;You will also need to acquire a reference image with no diffusion information to calculate the ADC value (divide diffusion scan by refere
      
    
    </summary>
    
    
      <category term="Brain" scheme="http://tracyxinwang.site/blog/tags/Brain/"/>
    
      <category term="MRI" scheme="http://tracyxinwang.site/blog/tags/MRI/"/>
    
  </entry>
  
  <entry>
    <title>Panda软件使用笔记</title>
    <link href="http://tracyxinwang.site/blog/2018/10/19/panda-use/"/>
    <id>http://tracyxinwang.site/blog/2018/10/19/panda-use/</id>
    <published>2018-10-18T23:01:51.000Z</published>
    <updated>2018-10-18T23:45:42.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="开始使用之前"><a href="#开始使用之前" class="headerlink" title="开始使用之前"></a>开始使用之前</h3><ul><li>将Panda的文件夹安装在MATLAB的路径当中</li><li>MATLAB必须从 terminal 处打开，不能用shortcut的图标打开</li></ul><h3 id="文件格式准备"><a href="#文件格式准备" class="headerlink" title="文件格式准备"></a>文件格式准备</h3><ul><li>subject name folder - DTI folder - DTI files 这种格式</li><li>DTI files 应该有三个文件：B value file(bval), b vector file(bvec), nii file</li><li>用 MRIcron 可以直接将 Dicom 的原始文件 convert 过去</li></ul><h3 id="Full-pipeline"><a href="#Full-pipeline" class="headerlink" title="Full pipeline"></a>Full pipeline</h3><ul><li>Pipeline mode: 如果只是一台电脑的话就选 batch; Max_Queued 是根据电脑的核数来的，会自动识别，所以不用改</li><li>Diffusion parameters: <ul><li>Resampling resolution:  作者推荐使用 $2×2×2mm^3$， 较高的resolution 会耗费处理时间</li><li>删除raw NII file 以节约空间</li><li>f(skull reovel): 去除DTI image中的brain tissue, 选用default值 0.25</li><li>cropping gap(mm): 就是图像外面的空白大小，选用默认值 3mm</li><li>Orientation patch: </li><li>剩下全是默认</li></ul></li></ul><h3 id="Tracking-amp-Network-parameters"><a href="#Tracking-amp-Network-parameters" class="headerlink" title="Tracking &amp; Network parameters"></a>Tracking &amp; Network parameters</h3><ul><li>Deterministic fiber tracking: <ul><li>Propagation algorithm: FACT</li><li>Angle threshold: 45</li><li>FA_threshold: 0.2~1</li></ul></li><li><p>Network node definition</p><ul><li>选择 parcellated native space: 这里我们使用 Freesurfer generate 出来的atlas.</li><li>需注意这个atlas需要是跟DTI data coregister 之后的，不然会fail掉，因为两个图像不match, 所以需要先生成DTI的file，再拿这个file去跟atlas做 coregistration.</li><li>生成DTI file: 此时 ‘Network Node Definition’ 及以下都不选择，运行到上面的fiber traking就能生成想要的文件，生成的文件是<code>trackvis</code> folder 下的<code>dti_fa_color.nii.gz</code></li><li>Coregistraion: 找到Freesurfer 生成的文件，用AFNI的suma function之后，会有一个 SUMA 的文件夹，该文件夹下面应该有一个 <code>aparc+aseg_REN_all.nii.gz</code>和<code>aparc.a2009s+aseg_REN_all.nii.gz</code>的文件，这两个文件就是我们要coregister的，可以任选一个，分别代表不同的T1 segmentation的atlas. 将 <code>dti_fa_color.nii.gz</code> 复制到该 SUMA 文件夹下</li><li><p>Coregistration 的代码如下:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">3dcalc -a dti_fa_color.nii.gz -expr <span class="string">'a'</span> -prefix dti_fa_color</span><br><span class="line">align_epi_anat.py -anat aparc+aseg_REN_all.nii.gz -epi dti_fa_color+orig -epi_base 0 -anat_has_skull no -epi_strip 3dAutomask -volreg off -tshift off -big_move</span><br><span class="line">3dAllineate -1Dmatrix_apply aparc+aseg_REN_all_al_mat.aff12.1D -input aparc+aseg_REN_all.nii.gz -prefix aparc+aseg_REN_all_reg -NN -final NN</span><br><span class="line">3dcalc -a aparc+aseg_REN_all_reg+orig -expr <span class="string">'a'</span> -short -prefix aparc+aseg_REN_all_short</span><br><span class="line">3dfractionize -template dti_fa_color+orig -input aparc+aseg_REN_all_short+orig -clip 0.2 -preserve -prefix aparc+aseg_REN_all_coreg</span><br><span class="line">3dAFNItoNIFTI -prefix aparc+aseg_REN_all_coreg aparc+aseg_REN_all_coreg+orig</span><br></pre></td></tr></table></figure></li><li><p>得到的 <code>aparc+aseg_REN_all_coreg</code> 就是要放在 <code>parcellated native space</code> 处的文件。选择好之后再运行一遍就OK。</p></li></ul></li><li>Network construction: 用 deterministic</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;开始使用之前&quot;&gt;&lt;a href=&quot;#开始使用之前&quot; class=&quot;headerlink&quot; title=&quot;开始使用之前&quot;&gt;&lt;/a&gt;开始使用之前&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;将Panda的文件夹安装在MATLAB的路径当中&lt;/li&gt;
&lt;li&gt;MATLAB必须从 term
      
    
    </summary>
    
    
      <category term="Tools" scheme="http://tracyxinwang.site/blog/tags/Tools/"/>
    
      <category term="Brain" scheme="http://tracyxinwang.site/blog/tags/Brain/"/>
    
  </entry>
  
  <entry>
    <title>Problem solve - `GLIBCXX_3.4.21&#39; not found</title>
    <link href="http://tracyxinwang.site/blog/2018/10/18/problem-matlab-gcc/"/>
    <id>http://tracyxinwang.site/blog/2018/10/18/problem-matlab-gcc/</id>
    <published>2018-10-18T04:11:37.000Z</published>
    <updated>2018-10-18T04:26:43.000Z</updated>
    
    <content type="html"><![CDATA[<p>在才开始使用Panda的过程中遇到了一个问题，这个问题之前遇到过，后来解决了也没再管过，没想到过了接近半年之后还会再使用Panda，搞了半天才找到解决办法，觉得还是真的要记录下来每个问题及当时的解决方法，保不准下一次又遇到了。。。</p><p>问题如下：<br>运行之后直接出现error:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/<span class="built_in">local</span>/MATLAB/R2016b/sys/os/glnxa64/libstdc++.so.6: version `GLIBCXX_3.4.21<span class="string">' not found (required by /usr/share/fsl/5.0/bin/fslchfiletype_exe</span></span><br></pre></td></tr></table></figure></p><p>首先 not found 有两种情况：</p><ol><li>这个 GLIBCXX_3.4.21 本来就不存在</li><li>这个 GLIBCXX_3.4.21 存在，但是matlab找不到，没有链接过去</li></ol><p>在terminal处先通过以下代码看这个到底有没有：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">strings /usr/lib/libstdc++.so.6 | grep GLIBCXX</span><br></pre></td></tr></table></figure></p><p>下面会出来一串相关的存在的 GLIBCXX. 找下有没有MATLAB说的那个 `GLIBCXX_3.4.21’。</p><p>如果存在的话，那就说明是matlab 链接的问题，只需要在terminal处用以下方式打开matlab就行了：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LD_PRELOAD=<span class="string">"/usr/lib/x86_64-linux-gnu/libstdc++.so.6"</span> matlab</span><br></pre></td></tr></table></figure></p><p>如果不存在的话，执行以下代码：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install libstdc++6</span><br><span class="line">sudo add-apt-repository ppa:ubuntu-toolchain-r/<span class="built_in">test</span> </span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get dist-upgrade</span><br></pre></td></tr></table></figure></p><p><br><br>Reference:<br><a href="https://askubuntu.com/questions/719028/version-glibcxx-3-4-21-not-found" target="_blank" rel="noopener">https://askubuntu.com/questions/719028/version-glibcxx-3-4-21-not-found</a><br><a href="https://stackoverflow.com/questions/44773296/libstdc-so-6-version-glibcxx-3-4-20-not-found" target="_blank" rel="noopener">https://stackoverflow.com/questions/44773296/libstdc-so-6-version-glibcxx-3-4-20-not-found</a><br><a href="https://askubuntu.com/questions/575505/glibcxx-3-4-20-not-found-how-to-fix-this-error" target="_blank" rel="noopener">https://askubuntu.com/questions/575505/glibcxx-3-4-20-not-found-how-to-fix-this-error</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在才开始使用Panda的过程中遇到了一个问题，这个问题之前遇到过，后来解决了也没再管过，没想到过了接近半年之后还会再使用Panda，搞了半天才找到解决办法，觉得还是真的要记录下来每个问题及当时的解决方法，保不准下一次又遇到了。。。&lt;/p&gt;
&lt;p&gt;问题如下：&lt;br&gt;运行之后直
      
    
    </summary>
    
    
      <category term="Linux" scheme="http://tracyxinwang.site/blog/tags/Linux/"/>
    
      <category term="Matlab" scheme="http://tracyxinwang.site/blog/tags/Matlab/"/>
    
  </entry>
  
  <entry>
    <title>写GRF，答辩BMI的一些心得</title>
    <link href="http://tracyxinwang.site/blog/2018/10/11/GRF-BMI-thoughts/"/>
    <id>http://tracyxinwang.site/blog/2018/10/11/GRF-BMI-thoughts/</id>
    <published>2018-10-11T07:24:54.000Z</published>
    <updated>2018-10-11T12:59:23.587Z</updated>
    
    <content type="html"><![CDATA[<p>到今天(2018.10.11)为止，帮老板写 GRF proposal 和 Brain Mind Institute(BMI) 申 funding 的答辩就基本告一段落了，被 criticize 了很多吧。这里记录一下这个过程的一些心得，这些是我觉得不只是写proposal，对开始做一件事情时，整个人的逻辑和思考方式都是有帮助的：</p><p><strong>GRF</strong>:</p><ul><li>每次只 <strong>highlight 一个最多两个新颖的点</strong>：有些时候可能自己想法很多，觉得这样不错，那样也不错，都是非常前卫cutting-edge那种感觉，然后很兴奋，想把他们都加进去。但是有几点你要考虑：<ol><li>Reviewer 不完全是你这个方向的，他可能并不能理解你那些前卫的想法，你要考虑这个剧本的观众是谁，他们能不能完全 get 到你的 point, 如果不能，那你这个剧本再怎么梦幻都是失败的，因为你首先需要观众的认可。一个人嗨没用，你要让一群人都嗨起来。</li><li>加入多个新鲜的元素意味着，危险。这个危险有两个方面，一是apply到人上面的东西，涉及到伦理人情实验时长subject的心情等等客观因素，作为一个investigator, 首先要保证的就是安全无害，当多个元素加入时，这种风险就会增大，这是必须要注意的， 人是第一要素。第二个方面是实验失败的风险，多个元素会使对照变得显得相当困难，连初中生都知道在设计生物实验时一定要有对照组，你怎么就忘了呢？没有对照，一切结果都是不能让人信服的。</li></ol></li><li><strong>描述细节</strong>：在写的过程中，很容易写得很宽泛，特别是 abstract 和 introduction 部分, 全程不说你要具体怎么做，只是说明你要去optimize, 要去 maximize 一个东西， 最后结果可以多叼多叼。别人看完了还是不知道你到底要怎么去optimize, maxmize, 你倒是给点操作步骤啊。所以这里我的总结是，少用形容词，少点假大空，最好的句式是：<strong>列出要用到哪些东西，表明用什么方法，之后怎么去改变，会有什么样的结果</strong>。</li><li><strong>写下的每一个数字，要有来源和依据</strong>：比如样本你要多少个，那这个数字是怎么来的，从文献呢还是经验呢，这个要列出来，No magic number。另一类数字就是你的一些 preliminary study 的结果，这些数字，你要知道它的物理意义，单位，还要用最通俗的语言解释给别人听，它的变化意味着什么。</li><li>关于<strong>题目的选取</strong>：google search 一下别人是怎么起名字的，这个我觉得对 non-native speaker 是很有用的。比如你起的这个到底是不是常用的，要是search 一下发现别人根本没人用这个词，或者这个词search出去导向的是别的研究方向，那就尴尬了，别人会觉得你不是内行人。</li><li>在文中适当表明一下这个技术有多新，多前沿，可以考虑指出世界上第一次做这个方向，采用这个方法等等是在哪个年份。。。比如2016, 2017，那就显得高端前沿了。</li><li>每一个稍微专业的词，都一定要解释清楚，保证你要传达的信息能够被准确理解</li><li>小到Reference中的journal斜体，缩写，作者名字，都是应该注意的。</li></ul><p><br></p><p><strong>BMI 答辩</strong>：</p><ul><li><strong>对你画出的每一个图，图里面的每一个字负责</strong>：前后一致，文字与图内容一致，并且保证你放上去的图，你都能完全解释给卖菜的大妈听懂。</li><li>PPT 少一点字啊喂：我承认没有花时间去准备，但这并不能成为你降低自己表达能力要求的借口。</li><li><strong>关注你的听众</strong>：他们的background是什么，他们懂你的术语吗？不懂就一定要提前想到，然后过程中解释保证他们能听懂，还是那句话，交流就表示要有信息输出，而这个信息一定要能被准确传达和理解</li><li>关于回答问题：如果回答完一次后发现对方仍然在问相同或相似的问题，可能不是你的回答有问题，而是你们在某些内容上的认知不一样，这个时候就需要回到你觉得他在问什么上，你觉得的和他觉得的，可能并不是一个东西。考虑：他为什么这样问，这样问的前提是基于什么来的（或者简单点，这个问题的词汇构成是什么，你的哪一部分解释会指向这些词汇），是不是之前哪里让他对整个事情（问题中的一些词汇）有点误解？</li></ul><p><br></p><p>大概就这样了，愿世界少点 proposal。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;到今天(2018.10.11)为止，帮老板写 GRF proposal 和 Brain Mind Institute(BMI) 申 funding 的答辩就基本告一段落了，被 criticize 了很多吧。这里记录一下这个过程的一些心得，这些是我觉得不只是写proposal
      
    
    </summary>
    
    
      <category term="杂文" scheme="http://tracyxinwang.site/blog/tags/%E6%9D%82%E6%96%87/"/>
    
      <category term="碎碎念" scheme="http://tracyxinwang.site/blog/tags/%E7%A2%8E%E7%A2%8E%E5%BF%B5/"/>
    
  </entry>
  
  <entry>
    <title>Notes of Neural Masses and Cortical Fields</title>
    <link href="http://tracyxinwang.site/blog/2018/10/09/NeuralMass2008PlosComp/"/>
    <id>http://tracyxinwang.site/blog/2018/10/09/NeuralMass2008PlosComp/</id>
    <published>2018-10-09T01:28:47.000Z</published>
    <updated>2018-10-11T11:48:41.366Z</updated>
    
    <content type="html"><![CDATA[<p>This is a summary of paper <a href="https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1000092" target="_blank" rel="noopener">The Dynamic Brain: From Spiking Neurons to Neural Masses and Cortical Fields</a></p><p>This paper mainly talks about a variety of computational approaches that have been used to characterize the <strong>dynamics of the cortex</strong>.</p><ul><li>The <strong>central theme</strong>: the activity in populations of neurons can be understood by reducing the degrees of freedom from many to few.</li><li>The way to achieve that is: to <strong>reduce the large population of spiking neurons to a distribution function</strong> describing their probabilistic evolution, which <strong>captures the likely distribution of neuronal states at a given time</strong>. </li><li>This can be further <strong>reduced to a single variable</strong> describing the <strong>mean firing rate</strong>.</li></ul><p><br></p><p><strong>Neural Mass models</strong>: capture the dynamics of a neuronal population. </p><blockquote><p>The theory based: Full probability distribution function can be represented by a set of scalars that parameterize it parsimoniously. These parameters are equivalent to the moments of the distribution.)</p></blockquote><p><strong>Neural Field Models</strong>: investigate how neuronal activity unfolds on the spatially continuous cortical sheet by involving differential operators with both temporal and spatial terms.</p><blockquote><p>The theory based: Neuronal activity depends on its current state as well as spatial gradients, which allow its spread horizontally across the cortical surface.</p></blockquote><p><br></p><h3 id="Mean-Field-Models"><a href="#Mean-Field-Models" class="headerlink" title="Mean-Field Models"></a>Mean-Field Models</h3><p>This part provides an overview of mean-field models of neuronal dynamics and their derivation from models of spiking neurons. </p><ul><li>mainly based on the <strong>mean-field approximation</strong></li><li>are formulated using concepts from <strong>statistical physics</strong>.</li><li>suited to data which reflect the behavior of a population of neurons, such as EEG, MEG and fMRI.</li></ul><h4 id="Ensemble-density-models"><a href="#Ensemble-density-models" class="headerlink" title="Ensemble density models"></a>Ensemble density models</h4><ul><li>Ensemble models attempt to model the dynamics of large (theoretically infinite) populations of neurons</li><li>use phase space to represent the neuron attribute space. Each attribute induces a dimension in the phase space of a neuron.</li><li>Three attributes will be included: post-synaptic membrane depolarization, $V$, capacitive current, $I$, and the time since the last action potential, $T$. (therefore, it is a three dimensional phase space)</li><li>The state of each neuron is a point $ν = {V,I,T} ∈ ℜ^3$</li><li>The density of neurons populate the space can be represented as: $p(ν,t)$<ul><li>As the state of each neuron evolves, the points will flow through phase space, and the ensemble density $p(ν,t)$ will evolve until it reaches some steady state or equilibrium.</li><li>$p(ν,t)$ is a scalar function returning the probability density at each point in phase space. </li></ul></li><li>the density dynamics conform to a simple equation: the <strong>Fokker-Planck equation</strong>:<ul><li>This equation comprises a flow and a dispersion term</li><li>phase flow, $f(ν,t)$ describes the dynamics</li><li>dispersion, $D(ν,t)$, describes the random fluctuations<br>$$\dot p = - \nabla \cdot (f-D\nabla)p \equiv \frac{\partial p}{\partial t} = tr(-\frac{\partial (fp)}{\partial v}+\frac{\partial}{\partial v}(D \frac {\partial p}{\partial v}))$$</li></ul></li><li>This level of description is usually framed as a <strong>stochastic differential equation</strong> (Langevin equation) that describes how the states evolve as functions of each other and some random fluctuations with $dv = f(v)dt + \sigma d \omega$.<ul><li>$D = \frac 12 \sigma^2$</li><li>$\omega$ is a standard Wiener process,i.e. $w(t)−w(t+Δt)∼N(0, Δt)$</li></ul></li><li>The density dynamics can be written as a linear operator or Jacobian Q:<br>$$\dot p = Qp$$ $$Q = \nabla \cdot (D \nabla - f)$$</li><li>For any model of neuronal dynamics, specified as a stochastic differential equation, there is a deterministic linear equation that can be integrated to generate ensemble dynamics. </li></ul><h4 id="From-spiking-neurons-to-mean-field-models"><a href="#From-spiking-neurons-to-mean-field-models" class="headerlink" title="From spiking neurons to mean-field models"></a>From spiking neurons to mean-field models</h4><ul><li>For a single neuron, we can assume the spiking dynamics as the $leaky integrate-and-fire (LIF)$ model. </li><li>In the LIF model, each neuron i can be fully described in terms of a single internal variable, namely the depolarization $V_i(t)$ of the neural membrane. </li><li>The basic circuit of a LIF model consists of a capacitor, $C$, in parallel with a resistor, $R$, driven by a synaptic current.</li><li>When the voltage across the capacitor reaches a threshold $θ$, the circuit is shunted (reset) and a $δ$ pulse (spike) is generated and transmitted to other neurons. </li><li>The subthreshold membrane potential of each neuron evolves according to a simple RC circuit, with a time constant $τ = RC$ given by the following equation:<ul><li>$I_i(t)$ is the total synaptic current flow into the cell i</li><li>$V_L$ is the leak or resting potential of the cell in the absence of external afferent inputs<br>$$\tau \frac{dV_i(t)}{dt} = -[V_i(t)-V_L] + RI_i(t)$$</li></ul></li><li>The total synaptic current coming into the cell i is therefore given by the sum of the contributions of δ-spikes produced at presynaptic neurons. </li><li>Assume that $N$ neurons synapse onto cell i and that $J_{ij}$ is the efficacy of synapse j, then the total synaptic afferent current is given by<ul><li>$t_j^{(k)}$ is the emission time of the kth spike from the jth presynaptic neuron.<br>$$RI_i(t) = \tau \sum^N_{j=1} J_{ij} \sum_k \delta (t-t_j^{(k)})$$</li></ul></li><li>Substitute the above equation gets:<ul><li>H(t) is the Heaviside function (H(t) = 1 if t&gt;0, and H(t) = 0 if t&lt;0) (acutally is a step function)<br>$$V_i(t) = V_L + \sum^N_{j=1} J_{ij} \int^t_0 e^{-s/\tau} \sum_k \delta (t-s-t_j^{(k)})ds<br>= V_L + \sum^N_{j=1} J_{ij} e^{-(t-t_j^{(k)})/\tau} \sum_k H(t-t_j^{(k)})$$</li></ul></li></ul><h4 id="The-population-density-approach"><a href="#The-population-density-approach" class="headerlink" title="The population density approach"></a>The population density approach</h4><p>A cortical column has $O(10^4)$−$O(10^8)$ neurons which are massively interconnected (on average, a neuron makes contact with $O(10^4)$ other neurons). The underlying dynamics of such networks can be described explicitly by the set of coupled differential equations. However, direct simulations of these equations will be very complex and computationally expensive. Therefore, we adopt the <strong>population density approach</strong>, using the Fokker-Planck formalism. <em>The Fokker-Planck equation summarizes the flow and dispersion of states over phase space in a way that is a natural summary of population dynamics in genetics.</em> The following will show how to derive the Fokker-Planck equation for neuronal dynamics.</p><ul><li>Individual IF neurons are grouped together into populations of statistically similar neurons.</li><li>Then use <strong>probability density function</strong> to describe the distribution of neuronal states (i.e., membrane potential) over the population.</li><li>Key <strong>assumption</strong>: the afferent input currents impinging on neurons in one population are uncorrelated<ul><li>In general, neurons with the same state $V(t)$ at a given time $t$ have a different history because of random fluctuations in the input current $I(t)$.</li><li>The main source of randomness is from fluctuations in recurrent currents and fluctuations in the external currents</li></ul></li><li>Then the dynamics are described by the evolution of the probability density function:<ul><li>which is the <strong>fraction of neurons at time $t$ that have a membrane potential $V(t)$ in the interval $[ν,ν+dν]$</strong><br>$$p(v, t)dv = Prob\{V(t)\in [v, v+dv]\}$$</li></ul></li><li>The evolution of the population density is given by the <strong>Chapman-Kolmogorov equation</strong>:<ul><li>$ρ(ε|ν) = Prob\{V(t+dt) = ν+ε|V(t) = ν\}$ is the conditional probability that generates an infinitesimal change $ε = V(t+dt)−V(t)$ in the infinitesimal interval $dt$.<br>$$p(v, t+dt) = \int^{+\infty}_{-\infty} p(v-\varepsilon,t)\rho(\varepsilon|v-\varepsilon)d\varepsilon$$</li></ul></li><li>The Chapman-Kolmogorov equation can be written in a differential form by performing a Taylor expansion in $p(ν′,t) ρ(ε|ν′)$ around $ν′ = ν$:<ul><li>assume that $p(ν′,t)$ and $ρ(ε| ν′)$ are infinitely many times differentiable in $ν$<br>$$p(v’,t)\rho (\varepsilon|v’) = \sum^{\infty}_{k=0} \frac{(-\varepsilon)^k}{k!} \frac{\partial^k}{\partial v’^k} [p(v’,t)\rho(\varepsilon|v’)] \mid {v’=v}$$</li></ul></li><li>Combine the above equatin and can get:<ul><li>$〈…〉ν$ denotes the average with respect to $ρ(ε| ν)$ at a given $ν$<br>$$p(v,t+dt) = \sum^\infty_{k=0} \frac{(-1)^k}{k!} \frac{\partial^k}{\partial v^k} [p(v,t)\langle \varepsilon^k \rangle _v]$$</li></ul></li><li>Take the limit for $dt \to 2$:<br>$$\frac{\partial p(v,t)}{\partial t} = \sum^\infty_{k=1} \frac{(-1)^k}{k!} \frac{\partial^k}{\partial v^k} [p(v,t)lim_{dt \to 0 }\frac 1{dt} \langle \varepsilon^k \rangle_v]$$</li></ul><h4 id="The-diffusion-approximation"><a href="#The-diffusion-approximation" class="headerlink" title="The diffusion approximation"></a>The diffusion approximation</h4><ul><li>The above temporal evolution requires the moments $〈ε^k〉_υ$. </li><li>These moments can be calculated by the mean-field approximation</li><li>The mean-field approximation replaces the time-averaged discharge rate of individual cells with a common time-dependent population activity </li><li>Therefore, infinitesimal change, $dV(t)$, in the membrane potential of all neurons is:<ul><li>$N$ is the number of neurons</li><li>$〈J〉_J$ denotes the average of the synaptic weights in the population.</li><li>$Q(t)$ is the mean population firing rate and determined by the proportion of active neurons by counting the number of spikes $n_{spikes}(t,t+dt)$ in a small time interval dt and dividing by N and by dt: $Q(t) = lim_{dt \to 0} \frac{n_{spikes}(t,t+dt)}{Ndt}$<br>$$dV(t) = \langle J\rangle_J NQ(t) dt - \frac{V(t)-V_L}{\tau}dt$$</li></ul></li><li>The first two moments in the Kramers-Moyal expansion are called <strong>drift</strong> and <strong>diffusion coefficients</strong>, respectively as follows:<br>$$M^{(1)} = lim_{dt \to 0} \frac1{dt} \langle \varepsilon\rangle_v =\langle J\rangle_J NQ(t) - \frac{v-V_L}{\tau} = \frac{\mu(t)}{\tau} - \frac{v-V_L}{\tau}$$ $$M^{(2)} = lim_{dt \to 0} \frac1{dt} \langle \varepsilon^2 \rangle_v =\langle J^2 \rangle_J NQ(t) = \frac{\sigma(t)^2}{\tau}$$</li><li>The diffusion approximation allows to omit all higher orders k&gt;2 in the Kramers-Moyal expansion. The resulting differential equation describing the temporal evolution of the population density is called the Fokker-Planck equation:<br>$$\frac{\partial p(v,t)}{\partial t} = \frac1{2\tau} \sigma^2 (t) \frac{\partial^2p(v,t)}{\partial v^2} + \frac{\partial}{\partial v}[(\frac{v-V_L-\mu(t)}{\tau})p(v,t)]$$</li><li>If the <strong>drift is linear</strong> and the <strong>diffusion coefficient, $σ^2(t)$, is given by a constant</strong>, the Fokker-Planck equation describes a well-known stochastic process called the <strong>Ornstein-Uhlenbeck process</strong>. And the input afferent currents are given by<ul><li>$ω(t)$ is a white noise process<br>$$RI(t) = \mu(t) + \sigma \sqrt \tau \omega(t)$$</li></ul></li></ul><h4 id="The-mean-field-model"><a href="#The-mean-field-model" class="headerlink" title="The mean-field model"></a>The mean-field model</h4><h3 id="Neural-Modes-and-Masses"><a href="#Neural-Modes-and-Masses" class="headerlink" title="Neural Modes and Masses"></a>Neural Modes and Masses</h3><h3 id="Neural-Field-Models"><a href="#Neural-Field-Models" class="headerlink" title="Neural Field Models"></a>Neural Field Models</h3>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;This is a summary of paper &lt;a href=&quot;https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1000092&quot; target=&quot;_blank&quot; rel=&quot;
      
    
    </summary>
    
    
      <category term="Notes" scheme="http://tracyxinwang.site/blog/tags/Notes/"/>
    
      <category term="Brain" scheme="http://tracyxinwang.site/blog/tags/Brain/"/>
    
  </entry>
  
  <entry>
    <title>Laplacian Matrix and Spectral Clustering</title>
    <link href="http://tracyxinwang.site/blog/2018/10/05/Laplacian-matrix/"/>
    <id>http://tracyxinwang.site/blog/2018/10/05/Laplacian-matrix/</id>
    <published>2018-10-05T02:34:08.000Z</published>
    <updated>2018-11-15T03:48:24.000Z</updated>
    
    <content type="html"><![CDATA[<p>When I was reading paper, some people used this Laplacian metrix as a small step in their network analysis. I then found some papers and tutorials regarding this topic to have a general idea of what it is. The followings are some summary for reference.</p><p>Either Laplacian graph or spectral clustering is in the field of spectral graph theory. It studies the properties of graphs via the eigenvalues and eigenvectors of their associated graph matrices: the adjacency matrix and the graph Laplacian and its variants.</p><p>The most important application of the Laplacian is spectral clustering that corresponds to a computationally tractable solution to the graph partitionning problem.<br>Another application is spectral matching that solves for graph matching.</p><h3 id="Basic-information"><a href="#Basic-information" class="headerlink" title="Basic information:"></a>Basic information:</h3><p><strong>Degree matrix</strong>: a diagonal matrix which contains information about the degree of each vertex — the sum of weights of all edges attached to that vertex. The value of diagonal is the degree of the vertex.<br><strong>Similarity function</strong>: also called similarity measures, to quantify the similarity between two objects and is the basic and preliminary thing to do clustering. Denoted as $s_{ij}$ between point i and point j. Some examples: Cosine similarity, kernel functions, Gaussian similarity ($s(x_i, x_j) = exp(-|x_i-x_j|^2/2\sigma^2)$).<br><strong>Similarity graph</strong>: to model the local neighborhood relationships between the data points. There are several similarity graphs can be chosen:</p><ul><li><strong>ε-neighborhood graph</strong>: connect all points whose pairwise distances that are smaller than ε. The ε-neighborhood graph is usually considered as an unweighted graph. (以数值来说话)</li><li><strong>k-nearest neighbor graphs</strong>: connect vertex $v_i$ with vertex $v_j$ if $v_j$ is among the k-nearest neighbors of $v_i$. (Attention: this definition can lead to a directed graph, as the neighborhood relationship is not symmetric, e.g. vertex $v_j$ can be the k-th nearest neighbor of $v_i$ but $v_i$ may not be the k-th nearest neighbor of $v_j$) (以个数来说话)</li><li><strong>fully connected graph</strong>: simply connect all points with positive similarity with each other, and weight all edges by $s_{ij}$. As the graph should represent the local neighborhood relationships, this construction is only useful if the similarity function itself models local neighborhoods, e.g. Gaussian similarity function. </li></ul><p><br></p><h3 id="Graph-Laplacian-and-properties"><a href="#Graph-Laplacian-and-properties" class="headerlink" title="Graph Laplacian and properties"></a>Graph Laplacian and properties</h3><h4 id="The-unnormalized-Laplacian-matrix"><a href="#The-unnormalized-Laplacian-matrix" class="headerlink" title="The unnormalized Laplacian matrix:"></a>The unnormalized Laplacian matrix:</h4><p>$$ L = D - A $$<br>where, D is the degree matrix and A is the adjacency matrix of the graph.</p><p><strong>Property of the unnormalized laplacian matrix</strong>:</p><ul><li>For every vector $f\in R^n$: $f’Lf=\frac12\sum_{i,j=1}^nw_{ij}(f_i-f_j)^2$</li><li>L is symmetric and positive semi-definite</li><li>The smallest eigenvalue of L is 0, the corresponding eigenvextor is the constant one vector 1.</li><li>L has $n$ non-negative, real-valued eigenvalues $0=\lambda_1 \le \lambda_2 \le … \le \lambda_n$</li></ul><p><br></p><h4 id="The-normalized-Laplacian"><a href="#The-normalized-Laplacian" class="headerlink" title="The normalized Laplacian:"></a>The normalized Laplacian:</h4><p>There are two matrices that are called normalized graph Laplacians in literature:<br>$$L_{sym} = D^{-1/2}LD^{-1/2} = I - D^{-1/2}WD^{-1/2}$$<br>$$L_{rm} = D^{-1}L = I - D^{-1}W$$<br>The first matrix is denoted by $L_{sym}$ as it is symmetric matrix.<br>The seond one is denoted by $L_{rm}$ as it is closely related to a random walk.</p><p><strong>Property of the normalized laplacian matrix</strong>:</p><ul><li>For every vector $f\in R^n$: $f’L_{sym}f=\frac12\sum_{i,j=1}^nw_{ij}(\frac{f_i}{\sqrt {d_i}} - \frac{f_j}{\sqrt {d_j}})^2$</li><li>$\lambda$ is an eigenvalue of $L_{rw}$ with eigenvector $u$ if and only if $\lambda$ is an eigenvalue of $L_{sym}$ with eigenvector $w=D^{1/2}u$</li><li>$\lambda$ is an eigenvalue of $L_{rw}$ with eigenvector $u$ if and only if $\lambda$  and $u$  solve the generalized eigenproblem $Lu = λDu$</li><li>0 is an eigenvalue of $L_{rw}$ with the constant one vector 1 as eigenvector. 0 is an eigenvalue of $L_{sym}$ with eigenvector $D^{1/2}1$.</li><li>$L_{sym}$ and $L_{rw}$ are positive semi-definite and have $n$ nonnegative real-valued eigenvalues $0 = λ_1 ≤···≤ λ_n$.</li></ul><p><br></p><h3 id="Spectral-clustering-algorithms"><a href="#Spectral-clustering-algorithms" class="headerlink" title="Spectral clustering algorithms"></a>Spectral clustering algorithms</h3><p>Assume the data consists of $n$ “points” $x_1,…,x_n$ which can be arbitrary objects. We measure their pairwise similarities $s_{ij} = s(x_i,x_j)$ by some similarity function which is symmetric and non-negative, and we denote the corresponding similarity matrixby $S = (s_{ij} )_{i,j=1,…,n}$.</p><h4 id="Unnormalized-spectral-clustering"><a href="#Unnormalized-spectral-clustering" class="headerlink" title="Unnormalized spectral clustering"></a>Unnormalized spectral clustering</h4><p><strong>Input</strong>: Similarity matrix $S ∈ R^{n×n}$, number k of clusters to construct.</p><blockquote><ol><li>Construct a similarity graph by one of similarity functions. Let $W$ be its weighted adjacency matrix.</li><li>Compute the unnormalized Laplacian $L$.</li><li>Compute the first $k$ eigenvectors $u_1,…,u_k$ of $L$</li><li>Let $U ∈ R^{n×k}$ be the matrix containing the vectors $u_1,…,u_k$ as columns.</li><li>For $i = 1,…,n$, let $y_i ∈ R^k$ be the vector corresponding to the i-th row of $U$</li><li>Cluster the points $(y_i)_{i=1,…,n}$ in $R^k$ with the k-means algorithm into clusters $C_1,…,C_k$</li></ol></blockquote><p><strong>Output</strong>: Clusters $A_1,…,A_k$ with $A_i =\{j|y_j ∈ C_i\}$.</p><p><br></p><h4 id="Normalized-spectral-clustering-using-L-rw"><a href="#Normalized-spectral-clustering-using-L-rw" class="headerlink" title="Normalized spectral clustering using $L_{rw}$"></a>Normalized spectral clustering using $L_{rw}$</h4><p><strong>Input</strong>: Similarity matrix $S ∈ R^{n×n}$, number k of clusters to construct.</p><blockquote><ol><li>Construct a similarity graph by one of similarity functions. Let $W$ be its weighted adjacency matrix.</li><li>Compute the unnormalized Laplacian $L$.</li><li>Compute the first k generalized eigenvectors $u_1,…,u_k$ of the generalized eigenproblem $Lu=λDu$</li><li>Let $U ∈ R^{n×k}$ be the matrix containing the vectors $u_1,…,u_k$ as columns.</li><li>For $i = 1,…,n$, let $y_i ∈ R^k$ be the vector corresponding to the i-th row of $U$</li><li>Cluster the points $(y_i)_{i=1,…,n}$ in $R^k$ with the k-means algorithm into clusters $C_1,…,C_k$</li></ol></blockquote><p><strong>Output</strong>: Clusters $A_1,…,A_k$ with $A_i =\{j|y_j ∈ C_i\}$.</p><p><br></p><h4 id="Normalized-spectral-clustering-using-L-sym"><a href="#Normalized-spectral-clustering-using-L-sym" class="headerlink" title="Normalized spectral clustering using $L_{sym}$"></a>Normalized spectral clustering using $L_{sym}$</h4><p><strong>Input</strong>: Similarity matrix $S ∈ R^{n×n}$, number k of clusters to construct.</p><blockquote><ol><li>Construct a similarity graph by one of similarity functions. Let $W$ be its weighted adjacency matrix.</li><li>Compute the normalized Laplacian $L_{sym}$.</li><li>Compute the first k eigenvectors $u_1,…,u_k$ of $L_{sym}$</li><li>Form the matrix $T ∈ R^{n×k}$ from $U$ by normalizing the rows to norm 1,that is set $t_{ij} =u_{ij}/(\sum_k u_{ik}^2)^{1/2}$.</li><li>For $i = 1,…,n$, let $y_i ∈ R^k$ be the vector corresponding to the i-th row of $T$</li><li>Cluster the points $(y_i)_{i=1,…,n}$ in $R^k$ with the k-means algorithm into clusters $C_1,…,C_k$</li></ol></blockquote><p><strong>Output</strong>: Clusters $A_1,…,A_k$ with $A_i =\{j|y_j ∈ C_i\}$.</p><p><br></p><p><strong>Attention</strong>: Eigenvalues will always be ordered increasingly, respecting multiplicities. Therefore, “the first k eigenvectors” refers to the eigenvectors corresponding to the k smallest eigenvalues.</p><p><br></p><p>Reference:<br><a href="https://www.sciencedirect.com/science/article/pii/S1053811917305463" target="_blank" rel="noopener">https://www.sciencedirect.com/science/article/pii/S1053811917305463</a><br><a href="https://link.springer.com/content/pdf/10.1007%2Fs11222-007-9033-z.pdf" target="_blank" rel="noopener">https://link.springer.com/content/pdf/10.1007%2Fs11222-007-9033-z.pdf</a><br><a href="http://www2.imm.dtu.dk/projects/manifold/Papers/Laplacian.pdf" target="_blank" rel="noopener">http://www2.imm.dtu.dk/projects/manifold/Papers/Laplacian.pdf</a><br><a href="https://csustan.csustan.edu/~tom/Clustering/GraphLaplacian-tutorial.pdf" target="_blank" rel="noopener">https://csustan.csustan.edu/~tom/Clustering/GraphLaplacian-tutorial.pdf</a><br><a href="https://www.youtube.com/watch?v=FRZvgNvALJ4" target="_blank" rel="noopener">https://www.youtube.com/watch?v=FRZvgNvALJ4</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;When I was reading paper, some people used this Laplacian metrix as a small step in their network analysis. I then found some papers and 
      
    
    </summary>
    
    
      <category term="Notes" scheme="http://tracyxinwang.site/blog/tags/Notes/"/>
    
      <category term="Algorithm" scheme="http://tracyxinwang.site/blog/tags/Algorithm/"/>
    
  </entry>
  
  <entry>
    <title>思维模型总结</title>
    <link href="http://tracyxinwang.site/blog/2018/10/03/thinking-system/"/>
    <id>http://tracyxinwang.site/blog/2018/10/03/thinking-system/</id>
    <published>2018-10-03T13:09:45.000Z</published>
    <updated>2018-10-04T04:52:40.540Z</updated>
    
    <content type="html"><![CDATA[<p><em>大部分内容来源于L先生说，此处是一些个人总结。</em></p><p>思维模型(Mental model): 每个人认知世界、思考问题的基本模式和习惯</p><p>Keywords: <strong>本质，规律，原则</strong></p><p>本质：一个事物在变化的过程中，或者穷尽各种可能性的前提下，所维持不变的那一部分。</p><p>For example:<br>公司的本质是整合资源。无论什么行业、什么领域，只要资源存在错配和空缺，公司就得以存在；而一旦资源能高效运作、对接起来，公司就没必要存在。<br>汽车的本质是出行。在这个过程中，保证便捷、安全、高效，才是汽车最核心的存在理由。其他一切，都只是建筑在这个本质上面的浅层需求罢了。</p><h3 id="二阶模型"><a href="#二阶模型" class="headerlink" title="二阶模型"></a>二阶模型</h3><ul><li>如果这样做，短时间内会得到什么样的结果 （一阶）</li><li>如果得到了这个结果，在较长时间后，会产生哪些新的可能性和结果？（二阶）</li></ul><p>本质上是个可能性分析的问题，有必要时可跟概率进行联系。</p><h3 id="整体思维"><a href="#整体思维" class="headerlink" title="整体思维"></a>整体思维</h3><p>整体思维基于两个假设：</p><ul><li>一切事物在底层上都是相互联系的</li><li>整体能够提供比个体本身更多的信息<br><br></li></ul><p>关于整体思维的训练方式：</p><ul><li>它的背景和场景是什么</li><li>它为什么出现</li><li>它的出现带来了什么，导致了什么？</li></ul><p>其实这个思维方式可以理解成 3W 问题，即：Where, Why, What. 对于要研究的对象，建立联系图，挖掘底层的东西，并与自己的所知道的系统进行联系。</p><h3 id="系统思维"><a href="#系统思维" class="headerlink" title="系统思维"></a>系统思维</h3><p>系统就是「元素」和「结构」的组合。把一定的元素，通过不同的结构、方式组合起来，使它们具备整体性，这就构成了一个「系统」。</p><p>基于的假设：系统就是一个<em>转换</em> (transformation)的过程。<br>即，系统的存在，一定是因为它达成了一种「转换」：能将某些不够好的、无序的状态，转变成更优的、有序的状态。</p><p>从工程上来讲，a system has input and output. 如果以系统思维来思考问题的话，其实就是理解什么是input, system中的transfer function 指代的是什么，以及output 可以有哪些情况。</p><p>系统思维在生活中的应用：公司可以看作系统，城市可以看做系统，一个餐饮店，一个班级，一个公众号，都可以看做一个完备的、小小的系统。</p><hr><p>关于寻求本质的一些思维模型：</p><p><strong>输入 - 输出模型(IO模型)</strong><br>问： 一个行为、过程和系统，它的初始形态是什么？它的最终形态又是什么？<br>去关注：一样事物，它变化之前是什么，变化之后又是什么？</p><blockquote><p>不要去关注产品，而是要去关注：消费者想通过这个产品，达到一种什么样的状态？我们有没有什么方法帮助他们达到这个状态？这就是创新的要义。</p></blockquote><p><br></p><p><strong>供给 - 需求模型(SD模型)</strong><br>问：它们为什么可以连接起来？彼此的供给和需求是什么？</p><ul><li>我有什么？</li><li>谁需要这些东西？</li><li>我如何能把已有的东西，转变为别人需要的东西？<br><br></li></ul><p><strong>动力 - 阻力模型(PO模型)</strong><br>很多问题的本质，其实都是动力和阻力的博弈。动力超过阻力，改变就会发生，行为就会成立，反之，就会停滞。<br>问：推动一件事情的动力是什么？如果它发生了，阻力又是什么？<br><br></p><p><strong>改变 - 不变模型(CS模型)</strong><br>对于生活中的现象和事实，问：经历了这些复杂的过程，它改变的是什么？不变的又是什么？<br>这些不变的东西，很可能就是它所赖以持存、构成其本质的部分。</p><p>当你接触到一个陌生领域时，多搜集一些相关的材料去观察：在这些材料里面，有没有哪几个关键词、哪几个概念，是一直都存在，没有改变过的？如果有，它们往往就是这个领域的关键节点。试着去把它们「连接」起来，就可以找到的是这个领域的本质。</p><p><br></p><p>Reference：<br>L先生说，36氪</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;em&gt;大部分内容来源于L先生说，此处是一些个人总结。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;思维模型(Mental model): 每个人认知世界、思考问题的基本模式和习惯&lt;/p&gt;
&lt;p&gt;Keywords: &lt;strong&gt;本质，规律，原则&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;本质：一个事
      
    
    </summary>
    
    
      <category term="思考" scheme="http://tracyxinwang.site/blog/tags/%E6%80%9D%E8%80%83/"/>
    
      <category term="思维模型" scheme="http://tracyxinwang.site/blog/tags/%E6%80%9D%E7%BB%B4%E6%A8%A1%E5%9E%8B/"/>
    
  </entry>
  
  <entry>
    <title>关于拼多多上市的思考</title>
    <link href="http://tracyxinwang.site/blog/2018/09/30/PinDuoDuo/"/>
    <id>http://tracyxinwang.site/blog/2018/09/30/PinDuoDuo/</id>
    <published>2018-09-30T01:18:53.000Z</published>
    <updated>2018-09-30T01:38:58.856Z</updated>
    
    <content type="html"><![CDATA[<p>拼多多上市了。其实之前一直没有听说过这个拼多多，唯一的一次是因为我的妈妈发过来一条链接， 说要买个东西。 我当时想这是什么鬼，说你要买就在淘宝上买好了，为什么要在这个拼多多上买？ 她说大家一起拼可以很便宜，然后说周围的人都在上面买。我就很好奇，下载了这个软件，看上面到底有些什么。 然后发现价格确实挺低的，之后也没再管过，觉得这只是小APP在地方城市的小打小闹。直到那天看到它上市的新闻，瞬间惊呆了，我就在想到底它是凭什么上市的。 同时它的市值一度超过了网易，那网易这么容易被超过，又是为什么呢？ 当然这又是另外一个话题了，留着我以后去探究探究网易。这里我主要想来思考一下拼多多到底靠的是什么上市。 </p><p>先来说说网上整体的评价：一部分人不看好，觉得它太low了，卖得都是假货，迟早要垮。另一部分人觉得，它至少让生活在中国最底层的人学会了网购这件事情，多了一样选择性，而这部分人的体量是很大的，也不能忽视他们的消费能力。</p><p>先不说看好还是不看好吧，什么事情都有两面性，你也不能以一种标准去捧或者杀一个企业和它的前景。我就说说我看到的东西和思考的东西，再从这里面来找出他凭借的是什么上市的吧。</p><p><strong>观点一</strong>：PDD渗透的是五环外的中国，平行世界中的另外80%的人群，主打的也是三四五线的城市。<br><strong>思考</strong>：虽说主打的是三四五线城市，但是根据最后的比例分级图来看，一二线其实和淘宝的流量是差不多的。当然这可能是显得有点奇怪的，因为按照一般的思路来说，大家会觉得一二线的市民是不会去上面买东西的。所以首先这个一二线的划分标准，我觉得是需要注意一下的，一二线城市，包不包含周边附属区县？然后还有另外一个要注意的是，其实哪怕就是一二线城市本身，他们所容纳的三线以下人群也绝对是占大数的。所以一二线城市的三线以下人群买的东西，是会寄到一二线城市的，那这个肯定是算在一二线的消费组成里面的。所以这个是需要注意的。<br><img src="/blog/images/pdd_1.png" width="50%" height="50%"><br>那么其实我是更倾向用平行世界的80%的人群消费来描述，而不是按一二三线这种城市来划分。我没有比较过到底一二线城市的外来务工人口与本地人口的比例，也没有比较过一二线城市与三四线城市的人口比例(当然用数据说话是再好不过了)，但是有一点可以肯定，非土著一二线的人口肯定是大得多的。捡便宜是中国老一辈的习惯，就是喜欢买便宜的，而对于新一代的，如果在没有被提高认知之前，他们也会是这种思维模式，所以不管年龄层次，在便宜这一点上，就能带来大的网络流量了。</p><p><strong>观点二</strong>：假货，山寨<br><strong>思考</strong>：这个确实是，当我的妈妈说起这个软件的时候，我的第一反应就是骗人的，没好货。当时看的一些观点当中，有个人说的我觉得特别好，他说PDD解决的是低收入人群有与没有的事情，还没有到解决商品好与差的地步。这个我觉得是说的很中肯的，我们不能拿我们的认知去跟最底层的人们比较，就像很多谦虚的知识分子经常说，你不能拿你有的东西，觉得别人也是理所当然的有一样。的确假货，欺骗消费者这些东西，我们是该摒弃的，如果是作为一家还算是有良心的企业的话，到之后肯定会解决这个事情的，因为这影响到声誉，而中国的生意人是最看中声誉这个东西了的，更何况还上市了。但是我们忽略了一点，企业的目的是赚钱，在能够引入大量流量下，是绝对可能做出暂时回避假货这种东西而默许其存在这种事情的。毕竟风头过了，好好转个型树立一下品牌，又是一条好汉。所以我觉得这也是资本不去把这个当作一个致命点而不看好PDD的其中一个原因。只要能赚钱，我管你怎么赚。“互联网和移动互联网万年不变的思维，是先有海量用户，然后才是分级。” PDD也不可能做教育了客户如何网购然后把这些客户白白送给淘宝京东这种傻事情的。</p><p><strong>观点三</strong>：“中国接近一半的人口，还没有接入互联网；还有4.5亿人完全没有被纳入正规金融体系，超过9亿人没有贷款记录，仅有大概2亿人拥有信用卡；贫富差距巨大，穷人很多很多。”<br><strong>思考</strong>：中国的贫富差距是很大，同时贫富的人口比例差距也是很大的，但是我们要把这个事情往金融体系，信用卡这上面套，我觉得还有很长的路要走。而且不是说中国就一定要往这条路上走，我个人觉得在中国信用卡这种玩法在下层人口上是很难玩得起来的，中国肯定会有一种新的玩法出现，能够囊括各阶层的人群。花呗算是一种，但还没有完全跳出信用卡的维度。而且还有一点就是传统的乡土人情，老一辈的思想就是不要借钱，不能负债，负债和借钱是一件很不光荣的事情，这涉及到思想文化的根基，传统的教育和文化让人们觉得这是一件很“没面子”的事情，而不是觉得这本来就是一种金融方式，没有对与错。说到这里，我还是觉得现阶段大众的金融经济知识都是很欠缺的，包括我自己。</p><h4 id="几个有趣的，还值得思考的现象："><a href="#几个有趣的，还值得思考的现象：" class="headerlink" title="几个有趣的，还值得思考的现象："></a>几个有趣的，还值得思考的现象：</h4><ol><li><p>拼多多在上海和纽约两地同时敲钟，但拼多多创始人黄峥没有去纽约敲钟。没有敲钟就算了，毕竟还有好多大企业的老总都没有去敲钟，但是连纽约都不去就有点厉害了。毕竟现在上市套现的套路太多了。。。不管装没装，这个创始人表现得还是比较淡定的，一定程度上说明他的眼界根本不在此，他觉得其实就是个小事。我在想到底是什么赋予一个创始人这样的心境，直到我看到他顺风顺水的简历，见过的大佬和他自身的实力，我觉得这是必然的，我也隐约觉得PDD说不定还真的能做出一点颠覆性的东西。而且黄峥的手上竟然有拼多多 50.7%的股权，不得不说很厉害。。。这说明他其实是对PDD的未来已经有想法的人，毕竟通过谷歌早就实现财富自由了，剩下的追求就是人生的事业了。</p></li><li><p>PDD把社交分享玩法玩得很溜，共同的特点都是门槛低、传播广。<br>陆奇加入PDD也是让人吃了一惊，属于独立董事，按官方说法是他目前不存在负责点什么的问题。不过黄峥有提到说考虑分布式人工智能的系统，即 做个模拟社交网络：”假设你的手机里有一个小秘书，在做购买决策时你的小秘书能够代替你去问你朋友的小秘书，这个手机的智能网络一定程度上模拟了人跟其他社会成员的交互。模拟这个网络有两个好处。第一，能够避免传统人工智能的偏好牢笼，不会因为你看了一张美女图，就一直给你推荐美女图。我们的分布式AI要做的是，如果你的人工智能里面有朋友连接，其实你的朋友就扮演了一个不停往里面输入有效信息的角色。第二，我们试图模拟群体的传播，比如把一件衣服、某一个特殊设计扔到一个群里，我们可以看它会以多快的速度传播、有多大的量，由此去预测一件衣服会不会变成流行款、多大程度上成为流行款，是1000件、2000件，还是5000件、1万件的流行？如果我们能精确地预测出这个数字，就可以让上游厂商提前安排产销，服装库存的问题就能够得到很大的缓解。” 以上的话出自黄峥，这个场景是挺有意思的，黄峥本身是做计算机的，他当然知道整个技术的关键点，如果能与PDD拿到的数据结合的话，那在社交这个上面的玩法，就可以多得多了，毕竟现在微信建立起来的社交，已经让人看到这个方向的留存度高，面积大了。</p></li><li><p>腾讯是拼多多第二大股东，持股比例高达 18.5%。<br>关于大公司(BAT)的站队还是躲不掉哈哈哈，腾讯的流量接口肯定是帮了拼多多很多的。目前看来基本是朝AT两方站队了，校招宣讲的时候也有注意到这两方旗下的部署基本涵盖整个互联网界了。这是一个很有意思的事情，我一直在想到底互联网公司还能活多久，虽然新一代互联网公司也在飞奔，但是还是没能完全离得了大公司，加上AI类公司的崛起且还没落地，也迫使互联网公司all in AI. 那这样下去的话，传统互联网公司部署足够远见的话，是不是还是可以延续很长一段命呢？但是有句话说的好，“君以此兴，必以此亡”。</p></li><li><p>网易也投了拼多多的。。<br><img src="/blog/images/pdd_2.png" width="50%" height="50%"><br>之前有新闻说网易严选会与PDD合作，看到这个投资历史，也不难解释了，毕竟丁磊也投了PDD，而且当年还是丁磊向段永平引荐的黄峥。</p></li></ol><h4 id="一些其他引申的思考"><a href="#一些其他引申的思考" class="headerlink" title="一些其他引申的思考"></a>一些其他引申的思考</h4><ol><li><p>电子设备的普及及重要程度：<br>电脑-手机-？<br>下一个是什么呢？我个人更倾向手表和眼镜这类可穿戴的设备</p></li><li><p>互联网时代，大家都这样说<br>BAT-TMD-MMP<br>BAT大家都知道，TMD头条美团滴滴，MMP是美团小米和拼多多<br>小米是很有意思的，其实到现在为止我都对小米印象不好，可能就是源于那个时候红米的饥饿营销。但是人是会变的，企业也是，我们不能拿一层不变的眼光去看待一个企业。小米目前的生态链与3C行业的结合，我觉得也是值得去深入研究的，这个先挖一个坑在这以后找时间填吧。</p></li></ol><p>Reference:<br><a href="http://www.qdaily.com/articles/55654.html" target="_blank" rel="noopener">http://www.qdaily.com/articles/55654.html</a><br><a href="https://www.huxiu.com/article/253176.html" target="_blank" rel="noopener">https://www.huxiu.com/article/253176.html</a><br><a href="https://www.zhihu.com/question/287038344" target="_blank" rel="noopener">https://www.zhihu.com/question/287038344</a><br><a href="https://xueqiu.com/6942182748/111174319" target="_blank" rel="noopener">https://xueqiu.com/6942182748/111174319</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;拼多多上市了。其实之前一直没有听说过这个拼多多，唯一的一次是因为我的妈妈发过来一条链接， 说要买个东西。 我当时想这是什么鬼，说你要买就在淘宝上买好了，为什么要在这个拼多多上买？ 她说大家一起拼可以很便宜，然后说周围的人都在上面买。我就很好奇，下载了这个软件，看上面到底有些
      
    
    </summary>
    
    
      <category term="杂文" scheme="http://tracyxinwang.site/blog/tags/%E6%9D%82%E6%96%87/"/>
    
      <category term="碎碎念" scheme="http://tracyxinwang.site/blog/tags/%E7%A2%8E%E7%A2%8E%E5%BF%B5/"/>
    
      <category term="思考" scheme="http://tracyxinwang.site/blog/tags/%E6%80%9D%E8%80%83/"/>
    
  </entry>
  
  <entry>
    <title>Ubuntu与Windows共享资源</title>
    <link href="http://tracyxinwang.site/blog/2018/09/27/SMB-Samba/"/>
    <id>http://tracyxinwang.site/blog/2018/09/27/SMB-Samba/</id>
    <published>2018-09-27T03:01:34.000Z</published>
    <updated>2018-09-27T07:17:38.733Z</updated>
    
    <content type="html"><![CDATA[<p>事情又是这样的，想与实验室一台公用的Linux server和自己的windows的共享资源，毕竟数据拿硬盘拷来拷去太麻烦了。Linux 下有Samba软件可以提供与Windows共享，所以打算用这个来搞一下。</p><h2 id="以下在-Linux-上操作"><a href="#以下在-Linux-上操作" class="headerlink" title="以下在 Linux 上操作"></a>以下在 Linux 上操作</h2><h3 id="安装samba："><a href="#安装samba：" class="headerlink" title="安装samba："></a>安装samba：</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install samba</span><br></pre></td></tr></table></figure><h3 id="创建共享文件夹"><a href="#创建共享文件夹" class="headerlink" title="创建共享文件夹"></a>创建共享文件夹</h3><p>在home路径下创建一个你想共享的文件夹，名字自定，e.g. <code>DataShare</code>, 然后修改文件夹权限确保共享：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo chmod 777 /home/DataShare</span><br></pre></td></tr></table></figure></p><p>777表示将全部权限都放出来。</p><h3 id="修改samba配置文件"><a href="#修改samba配置文件" class="headerlink" title="修改samba配置文件"></a>修改samba配置文件</h3><p>为防止更改失败，先备份一下原文件：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp /etc/smaba/smb.conf /etc/samba/smb.conf.orig</span><br></pre></td></tr></table></figure></p><p>接下来修改配置文件<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo nano /etc/samba/smb.conf</span><br></pre></td></tr></table></figure></p><p>在文件最下面加上一下内容：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[share]</span><br><span class="line">path = /home/Datashare</span><br><span class="line">writable = yes</span><br><span class="line">avaliable = yes</span><br><span class="line">browseable = yes</span><br></pre></td></tr></table></figure></p><p>解释一下上面的内容，[share]指这个共享文件夹的别名，之后在window接入下会直接使用这个别名，用之前的名字实测并不可以。</p><h3 id="设置samba用户名"><a href="#设置samba用户名" class="headerlink" title="设置samba用户名"></a>设置samba用户名</h3><p>注意在设置之前，这个用户名一定是本身就已经是 linux 下的一个user, 不然会创建失败，所以最好先在linux下添加一个user:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo adduser shareuser</span><br></pre></td></tr></table></figure></p><p>然后会让你输入密码，记住这个密码，因为在之后设置samba用户时也需要同样的密码。<br>然后设置samba的登录密码：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo touch /etc/samba/smbpasswd</span><br><span class="line">sudo smbpasswd -a shareuser</span><br></pre></td></tr></table></figure></p><p><code>touch</code>是指保存账户信息，<code>shareuser</code> 就是你要添加的用户名，之后会让你输入密码，这个密码就是之前创建user的那个密码。</p><h3 id="启动samba服务器并测试"><a href="#启动samba服务器并测试" class="headerlink" title="启动samba服务器并测试"></a>启动samba服务器并测试</h3><p>启动：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo /etc/init.d/samba restart</span><br></pre></td></tr></table></figure></p><p>测试：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">testparm</span><br></pre></td></tr></table></figure></p><h3 id="加入开机启动"><a href="#加入开机启动" class="headerlink" title="加入开机启动"></a>加入开机启动</h3><p>这部分我没有加，先留在这里备用<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">systemctl <span class="built_in">enable</span> smb.service</span><br><span class="line">systemctl <span class="built_in">enable</span> nmb.service</span><br><span class="line">systemctl start smb.service</span><br><span class="line">systemctl start nmb.service</span><br></pre></td></tr></table></figure></p><h3 id="查看Ubuntu的-IP"><a href="#查看Ubuntu的-IP" class="headerlink" title="查看Ubuntu的 IP"></a>查看Ubuntu的 IP</h3><p>是为了在windows上访问的时候添加使用：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ifconfig</span><br></pre></td></tr></table></figure></p><p>出来一串的东西，找到ip记下来就好了。</p><h2 id="以下在Windows上操作"><a href="#以下在Windows上操作" class="headerlink" title="以下在Windows上操作"></a>以下在Windows上操作</h2><p>打开<code>我的电脑</code>，左边导航栏下面有个 <code>网络</code>, 右键选择 <code>映射网络驱动</code>，然后会让你输入samba服务器的地址和文件夹：</p><ul><li>驱动器选择默认的 z 就好</li><li>文件夹： <code>\\192.168.3.78\share</code>, 其中前面的ip就是你的linux的ip, 后面的<code>share</code>就是你创建共享文件夹的别名，同时注意斜杠不要打反了。。。</li><li>勾选 <code>使用其他凭据连接</code>,没有选的话可能会以默认的用户名登入，这样机会导致失败。因为当前的用户是你linux下的用户，名称并不匹配</li></ul><p>点击完成之后会要求输入网络凭据，用户名和密码就是你之前在linux下新添加的那个用户名和密码。点击确定之后就会连接，不出意外的话在此电脑下的网络位置里面，就能看到一个叫 <code>share</code>的z盘了。在里面拖放文件，就会发现可以自由共享了。简直不能再Nice！</p><!-- 下在局域网中可以通过 [SMB(Server Message Block)](https://wiki2.org/en/Server_Message_Block) 协议传输文件, 是微软当初提出来的，后来又称 CIFS（Common Internet File System）。--><p>Reference:<br><a href="https://www.cnblogs.com/gzdaijie/p/5194033.html" target="_blank" rel="noopener">https://www.cnblogs.com/gzdaijie/p/5194033.html</a><br><a href="https://ywnz.com/linuxjc/2636.html" target="_blank" rel="noopener">https://ywnz.com/linuxjc/2636.html</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;事情又是这样的，想与实验室一台公用的Linux server和自己的windows的共享资源，毕竟数据拿硬盘拷来拷去太麻烦了。Linux 下有Samba软件可以提供与Windows共享，所以打算用这个来搞一下。&lt;/p&gt;
&lt;h2 id=&quot;以下在-Linux-上操作&quot;&gt;&lt;a h
      
    
    </summary>
    
    
      <category term="Linux" scheme="http://tracyxinwang.site/blog/tags/Linux/"/>
    
      <category term="Samba" scheme="http://tracyxinwang.site/blog/tags/Samba/"/>
    
  </entry>
  
  <entry>
    <title>Playing with Orange Pi - Setting up the system</title>
    <link href="http://tracyxinwang.site/blog/2018/09/27/OrangePi1/"/>
    <id>http://tracyxinwang.site/blog/2018/09/27/OrangePi1/</id>
    <published>2018-09-27T00:04:24.000Z</published>
    <updated>2018-09-27T02:28:51.617Z</updated>
    
    <content type="html"><![CDATA[<p>起因是这样的，想建一个本地的服务器，通过内网穿透的方法，让我在外边的时候也能接入到我实验室的电脑，下载资料或者拷数据。弼哥告诉我用树莓派或者其他的一些派就能做到，于是买了最便宜的<a href="http://www.orangepi.cn/" target="_blank" rel="noopener">香橙派</a>，原因嘛，emm…自然是我喜欢吃橙子多过喜欢吃莓，并不是因为香橙派便宜（呵呵哒）。。。</p><p>本篇文章主要记录拿到香橙派之后的初始配置。</p><h3 id="准备清单"><a href="#准备清单" class="headerlink" title="准备清单"></a>准备清单</h3><ul><li>Orange Pi PC 2: 来自淘宝</li><li>带HDMI的显示器: 用于初始设置时候看</li><li>带USB接口的键盘：开机需要用户名密码OK?</li><li>网线</li><li>圆孔那种电源线：我能说我买的这块板子不支持 Micro-USB 吗。。</li><li>TF卡及读卡器</li></ul><h2 id="将操作系统写入TF卡"><a href="#将操作系统写入TF卡" class="headerlink" title="将操作系统写入TF卡"></a>将操作系统写入TF卡</h2><p>新到的派是没有操作系统的，既然作为一个小主机，那必然是需要操作系统来支持的。整个过程大致是这样的，操作系统的镜像将会被拷入TF卡，然后将TF卡插入派里面，启动派就OK了。</p><h3 id="操作系统的下载"><a href="#操作系统的下载" class="headerlink" title="操作系统的下载"></a>操作系统的下载</h3><p>操作系统是通过 <a href="https://www.openmediavault.org/" target="_blank" rel="noopener">openmediavault</a> 镜像下载的, 以下简称OMV。</p><blockquote><p>OMV 是个开源的基于Debian Linux的下一代网络附加存储(network attached storage (NAS))解决方案。(来自官网)<br>可用于家庭环境或小型的办公环境等场景。</p></blockquote><p>也就是说，我们可以直接下载这个OMV，它已经集成了Linux系统，并且还包含其他拓展，方便后续的使用。</p><p>进入官网后，点击下载，因为我们是会讲它写入TF卡中，所以这里我们下载ISO镜像，<a href="https://sourceforge.net/projects/openmediavault/files/" target="_blank" rel="noopener">点进去</a>之后会发现有很多可适用的文件，点击第一个 “OMV 4.x for Single Board Computers”, <a href="https://sourceforge.net/projects/openmediavault/files/OMV%204.x%20for%20Single%20Board%20Computers/" target="_blank" rel="noopener">进去</a>之后会发现竟然有Orange Pi对应的安装包！找到那个 <code>OMV_4_Orange_Pi_PC_2.img.xz</code> 下载下来就好了。至此，操作系统下载部分完成。</p><h3 id="操作系统写入"><a href="#操作系统写入" class="headerlink" title="操作系统写入"></a>操作系统写入</h3><p>下载完之后，就是要将该操作系统写入到TF卡中了。写入软件用的是 <a href="https://etcher.io/" target="_blank" rel="noopener">Etcher</a>, 没有什么特别的原因，就是简单，只有三步，多余的统统不要。。。 下载Etcher的安装包并安装好之后，打开该软件</p><ul><li>第一步是 <code>Select image</code>, 就选择刚刚下载的那个OMV的镜像</li><li>第二步是 <code>Select drive</code>, 默认为你的TF卡已经插入电脑并且能看到，选择你的TF卡对应的盘，注意不要选错了。。选到自己电脑本身的盘的话就GG了。。。</li><li>第三步就是 <code>Flash!</code>, 然后你就静等它写入并最后看到完成就好了。然后退出TF卡，放到Orange Pi对应的口中去。</li></ul><p>这个过程中要注意的是，因为这个TF卡在被写入过程中是会被软件反复插拔的， windows 就会弹出一些提醒，不用管那些提醒，都叉掉。<br>至此操作系统写入部分完成。</p><h2 id="启动-Orange-Pi-并配置"><a href="#启动-Orange-Pi-并配置" class="headerlink" title="启动 Orange Pi 并配置"></a>启动 Orange Pi 并配置</h2><h3 id="硬件连接"><a href="#硬件连接" class="headerlink" title="硬件连接"></a>硬件连接</h3><p>如下图：<br><img src="/blog/images/pi_1.jpg" width="50%" height="50%"></p><ul><li>电源是那个圆孔的</li><li>HDMI接你的显示器</li><li>USB那个接的键盘</li></ul><h3 id="更改密码"><a href="#更改密码" class="headerlink" title="更改密码"></a>更改密码</h3><p>接入显示器之后就看到出现一串关于OMV的一些东西，最下面是这个:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">orangepipc2 login:</span><br></pre></td></tr></table></figure></p><p>这个即是要你输入用户名，初始用户名是 <code>root</code>，输入之后出现这个：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Password:</span><br></pre></td></tr></table></figure></p><p>那就是要你输入密码了，初始密码为 <code>openmediavault</code>. 注意Linux系统下输入密码是不会显示的，自我感觉输完之后按回车就行了。然后会要求你更改初始密码：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">(current) UNIX password:</span><br><span class="line">Enter new UNIX password:</span><br><span class="line">Retype new UNIX password:</span><br></pre></td></tr></table></figure></p><p>以此输入就可以了。接下来你就会看到一个大大的 <code>OrangePiPC2</code> 的字样。。接着一些Welcome和系统的基本配置信息，如内存，CPU等等<br>最下面是Linux的命令行界面了：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">roo@orangepipc2:~<span class="comment"># _</span></span><br></pre></td></tr></table></figure></p><p>这就表示你可以完全操作这个系统了</p><h2 id="设置-SSH-登录"><a href="#设置-SSH-登录" class="headerlink" title="设置 SSH 登录"></a>设置 SSH 登录</h2><p>因为我们现在是接入显示器来看这个操作界面的，但是为了这么个小PC专门搞个显示器是有点不太合适的。Linux系统的一大好处就是可以通过SSH远程登录操作，所以这里记录设置SSH设置。</p><h3 id="查看IP-并设置为固定IP"><a href="#查看IP-并设置为固定IP" class="headerlink" title="查看IP 并设置为固定IP"></a>查看IP 并设置为固定IP</h3><p>首先请插上网线。。。要远程登录，就需要主机的IP地址，插好网线后，输入<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ip a</span><br></pre></td></tr></table></figure></p><p>然后就能看到出来下面这种：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1: lo XXX</span><br><span class="line">2: eth0: XXX</span><br><span class="line">    link/ether XXX</span><br><span class="line">    inet 192.168.3.78/24 brd XXX</span><br><span class="line">    inet6 XXX</span><br></pre></td></tr></table></figure></p><p>XXX 是省略的内容。。。那个<code>eth0</code>下面的<code>inet</code>后面的就是派的ip地址了。由于这个IP是动态的，加入哪天这个IP变了，那我们就SSH不上了，所以最好是设置一个静态的IP，步骤如下：<br>输入：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nano /etc/network/interfaces</span><br></pre></td></tr></table></figure></p><p>然后就会打开一个文件，找到如下字行并修改：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">iface eth0 inet static</span><br><span class="line">address 193.168.3.222</span><br><span class="line">netmask 255.255.255.0</span><br><span class="line">gateway 192.168.3.1</span><br></pre></td></tr></table></figure></p><p>即改为static 的，同时改下面的地址为你想要的网址，子网掩码，网关都设置为跟你目前所在的局域网对应<strong>一致</strong>就行了。<br>更改好之后，按住 <code>ctrl+x</code> 就能退出编辑页面了，然后会提示你是否保存，输入<code>Y</code>再回车就好了。一定不要把文件名改了！直接回车！<br>更改网络之后需要重启主机才能生效，输入 <code>reboot</code> 就好了</p><h3 id="设置SSH"><a href="#设置SSH" class="headerlink" title="设置SSH"></a>设置SSH</h3><p>正常情况下，linux是不会让远程登录的，所以需要更改配置。输入<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo nano /etc/ssh/sshd_config</span><br></pre></td></tr></table></figure></p><p>找到下面有个 <code>PermitRootLogin</code>, 更改为<code>yes</code>，表明你可以以root身份进入系统，当然这样做是很冒险的，最好的办法是新建一个账户，通过那个账户来远程登录，但是目前基础版的话我就这样设置了。改完之后 <code>ctrl+x</code> 并保存就好了，然后重启ssh 服务：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo service ssh restart</span><br></pre></td></tr></table></figure></p><h3 id="远程登录"><a href="#远程登录" class="headerlink" title="远程登录"></a>远程登录</h3><p>设置完ssh就该来试试远程登录的效果了！在我Windows下，我用的是 <a href="https://mobaxterm.mobatek.net/" target="_blank" rel="noopener">MobaXterm</a> 软件来登录的，当然传统的<code>WinSCP</code>, <code>Putty</code> 都是可以的。<br>打开MobaXterm软件，点击<code>New session</code>, <code>Remote host</code>输入派的IP:192.168.3.222, 勾选<code>Specify name</code> 并写上 <code>root</code>, <code>Port</code>口保持22不变。然后就可以接入了，需要你输入密码，之后就能远程控制了！</p><p>需要主要的是，如果遇到 <code>Access denied</code> 情况，那就可能是SSH那里没有更改对，或者密码跟用户名不对应。<br>前面说了，最安全的方法是新建一个账户，用这个账户登，这样的话，这里的name就应该是那个账户名，密码也应该是那个密码。</p><h2 id="关闭-Orange-Pi"><a href="#关闭-Orange-Pi" class="headerlink" title="关闭 Orange Pi"></a>关闭 Orange Pi</h2><p>在shell 里面直接输入<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo shutdown -h now</span><br></pre></td></tr></table></figure></p><p>Reference:<br><a href="http://www.orangepi.cn/quickstartcn/startcn_2e17631567a387efd2a3d252fa79.html" target="_blank" rel="noopener">Orange Pi website</a><br><a href="https://www.instructables.com/id/Orange-Pi-Plus-2-Armbian/" target="_blank" rel="noopener">https://www.instructables.com/id/Orange-Pi-Plus-2-Armbian/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;起因是这样的，想建一个本地的服务器，通过内网穿透的方法，让我在外边的时候也能接入到我实验室的电脑，下载资料或者拷数据。弼哥告诉我用树莓派或者其他的一些派就能做到，于是买了最便宜的&lt;a href=&quot;http://www.orangepi.cn/&quot; target=&quot;_blank
      
    
    </summary>
    
    
      <category term="Linux" scheme="http://tracyxinwang.site/blog/tags/Linux/"/>
    
      <category term="OrangePi" scheme="http://tracyxinwang.site/blog/tags/OrangePi/"/>
    
  </entry>
  
  <entry>
    <title>My First Post - 献给Hexo</title>
    <link href="http://tracyxinwang.site/blog/2018/09/25/My-First-Post/"/>
    <id>http://tracyxinwang.site/blog/2018/09/25/My-First-Post/</id>
    <published>2018-09-25T00:23:14.000Z</published>
    <updated>2018-11-15T03:48:50.000Z</updated>
    
    <content type="html"><![CDATA[<p>在网上查找资料的时候偶然看到有人提到用Hexo来写博客，界面非常简洁，而且支持 markdown 解析，瞬间打算在我<a href="http://tracyxinwang.site/">个人的学术网站</a>上加入这个blog页面。之前写博客都是在现成的博客网站上写的，比如 网易的 和 <a href="https://blog.csdn.net/u013036695" target="_blank" rel="noopener">CSDN</a> 这种还算比较大型的技术博客，无奈广告实在是太多了，后来转战 google 的 blog，但是它的编辑页面实在是难用，就放弃了。所以现在打算试试这个 Hexo。</p><p>Hexo 用官方的来说就是一个快速，简洁且高效的博客框架。我用了大概不到一天的时间，就从安装到部署搞定了，虽然过程很崎岖，掉了很多坑。。。但是总体还是觉得挺不错的，所以接下来我会大致叙述一下整个过程，希望能够让看到的朋友少掉坑。</p><p>先附上<a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>网址，也有<a href="https://hexo.io/zh-cn/docs/" target="_blank" rel="noopener">中文</a>的。个人觉得基本上按照网页上的指导，前面的步骤基本都是没问题的。由于我是一开始就打算在我个人网页中加入这个博客页面作为一个子页面，所以我是在 coding.net 而非 git 上面建库。另外操作系统是win10.</p><h3 id="准备工作及环境"><a href="#准备工作及环境" class="headerlink" title="准备工作及环境"></a>准备工作及环境</h3><ol><li>在 coding 上新建一个项目库，命名 “blog”，同时设置 <a href="https://coding.net/pages/" target="_blank" rel="noopener">Pages服务</a></li><li>在电脑上一个你觉得不错的位置新建一个文件夹，命名随意，这个名字没太大关系，我命名为”Hexo_blog”, 这文件夹是用来放所有跟你这个博客相关的东西的。</li></ol><h3 id="安装及配置"><a href="#安装及配置" class="headerlink" title="安装及配置"></a>安装及配置</h3><h4 id="安装前提"><a href="#安装前提" class="headerlink" title="安装前提"></a>安装前提</h4><p>须有 <a href="https://nodejs.org/en/" target="_blank" rel="noopener">Node.js</a> 和 <a href="https://git-scm.com/" target="_blank" rel="noopener">Git</a></p><ul><li>Node.js 安装：在官网下载好你电脑对应的版本之后，点安装包进行安装，在接近最后一步是，选择 “Add to PATH” 选项进行安装</li><li>git 安装：略</li></ul><h4 id="安装-Hexo"><a href="#安装-Hexo" class="headerlink" title="安装 Hexo:"></a>安装 Hexo:</h4><p>使用 npm 安装 Hexo:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ npm install -g hexo-cli</span><br></pre></td></tr></table></figure></p><h4 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h4><ol><li><p>新建框架<br> 去到你刚刚创建的那个要放所有Hexo东西的文件夹下，执行以下命令：</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ hexo init</span><br><span class="line">$ npm install</span><br></pre></td></tr></table></figure><p> 这个命令就是告诉hexo这里要建一个框架，然后它就会生成整个框架所需要的材料。<br> 新建完成后，可以看见有很多的文件夹，具体每个文件夹啥作用请看<a href="https://hexo.io/zh-cn/docs/setup" target="_blank" rel="noopener">官网</a>。这里面有一个叫 _config.yml 的东西，非常重要，是你整个博客配置的基础。</p></li><li><p>基本配置(只列出可能有坑的地方)：</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">language: zh-Hans</span><br><span class="line">url: http://yoursite.com/blog</span><br><span class="line">root: /blog/</span><br></pre></td></tr></table></figure><p> 前面说了我是打算我个人网站子页面下加入这个blog，所以那个url, 对我来说是后面加上这个子目录名字，然后root那个地方也需要改成，如果你本身是一个网页来的(比如git的页面)，那就不用设置这个root了。其他的配置具体可参见<a href="https://hexo.io/zh-cn/docs/configuration" target="_blank" rel="noopener">网页</a>。最后关于主题(theme)和部署(deploy)的，接下来讲。</p></li></ol><h4 id="主题-theme-的确定"><a href="#主题-theme-的确定" class="headerlink" title="主题(theme)的确定"></a>主题(theme)的确定</h4><p>主题顾名思义就是你的博客的风格，Hexo有很多模板可供选择，要使用哪个模板，就需要将该主题拷贝到themes文件夹下，然后在_config.yml 更改主题的名字。我用的是 <a href="https://github.com/litten/hexo-theme-yilia" target="_blank" rel="noopener">yilia</a> 的主题，下面以此为例写步骤：</p><ul><li><p>进入你放创建的hexo文件夹(e.g. Hexo_blog)下, 使用如下命令安装：</p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git <span class="built_in">clone</span> https://github.com/litten/hexo-theme-yilia.git themes/yilia</span><br></pre></td></tr></table></figure><p>  这需要你先找到该主题的github，也可以直接下载然后解压到你的themes文件夹下</p></li><li>进入Hexo_blog 下面那个 _config.yml， 修改 ‘themes: yilia’</li><li>进入Hexo_blog/themes/yilia, 里面也有一个 _config.yml, 在上面更改你想命名的主页的menu和其他的基本个人设置</li></ul><h3 id="开写你的第一篇博客"><a href="#开写你的第一篇博客" class="headerlink" title="开写你的第一篇博客"></a>开写你的第一篇博客</h3><p>这个很简单，直接执行：<br> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new  my-first-post</span><br></pre></td></tr></table></figure></p><p>那个 my-first-post 是你的文章题目。所有的文章都会被放在 /source/posts 文件夹下。在这个文件夹下你可以看到一个 my-first-post.md 的文件。打开这个文件然后就在下面用markdown的语法就写好了。</p><h3 id="在本地查看并生成静态网页"><a href="#在本地查看并生成静态网页" class="headerlink" title="在本地查看并生成静态网页"></a>在本地查看并生成静态网页</h3><ol><li><p>由于有文件的改动，所以需要先生成静态文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo g</span><br></pre></td></tr></table></figure></li><li><p>生成之后可以hexo server来查看新建的文章或者网站：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo s</span><br></pre></td></tr></table></figure></li></ol><p>然后就能看到说在 <a href="http://localhost:4000" target="_blank" rel="noopener">http://localhost:4000</a> 下可以打开。如果一切都没问题，那么就可以部署到真的网页上面了。</p><h3 id="部署-（这部分很让我头疼）"><a href="#部署-（这部分很让我头疼）" class="headerlink" title="部署 （这部分很让我头疼）"></a>部署 （这部分很让我头疼）</h3><p>先说步骤：</p><p>1.git-SSH 配置：</p><pre><code>- 查看你的git user.email: &apos;git config user.email&apos;- 假如得到的email是 xx@gamil.com, 生成这个email对应的密匙: &apos;ssh-keygen -t rsa -C &quot;xx@gmail.com&quot;&apos;- 接下来会让你enter file to save the key，enter passphrase, enter passphrase again, 可以不需要设置这些秘密啥的，所以每一个问题出现，都按enter, 即连续3个回车。- 然后会得到两个文件 &apos;id_rsa&apos; 和 &apos;id_tsa.pub&apos;- 复制刚刚生成的密匙(其中xx/xx是你密匙生成的位置，在上一步骤中会显示)： &apos;clip &lt; xx/xx/id_rsa.pub&apos;- 在准备步骤中新建的那个库下，打开设置-添加公匙，将刚刚复制的内容粘贴到上面，至此，配置完成。- 检查是否真的完成：输入&apos;ssh -T xx@gmail.com&apos;，然后选择 &apos;yes&apos;, 接着看到 Hi XX, You&apos;ve successfully authenticated 等等，就表明已经设置成功了</code></pre><p>2._config.yml 文件deploy的更改：<br>    应该是在最下面，有个deploy，在下面写上你的库的ssh地址等如下：</p><pre><code><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">deploy:</span><br><span class="line">  <span class="built_in">type</span>: git</span><br><span class="line">  repo: git@git.coding.net:XX/blog.git</span><br><span class="line">  branch: master</span><br><span class="line">  message: update my blog.</span><br></pre></td></tr></table></figure></code></pre><p>3.部署：<br>先下载deployer: ‘npm install hexo-deployer-git –save’<br>然后执行：</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo d</span><br></pre></td></tr></table></figure><p>然后就可以看你的网页有没有变化了。</p><p>由于我是打算直接在我的个人网站下直接建一个子网页，所以一开始一直想的是deploy到我之前的那个库里面，我以为是直接添加到那个git repo 里面就好，没想到一deploy之后，发现之前的内容全没有了，然后才意识到应该是force push上去的，没有pull等过程，所以直接啥都没有了，没办法我又只好force push 我之前的网站内容上去，才将原网页复原。由于我不知道怎么可以只deploy到一个子folder里面去，所以我又新建了一个库叫blog，也就是文章开头写的那样。然后将这个库的地址作为deploy的git 地址，才可以。我发现coding上可以直接设置子静态页面，所以我也直接就将这个网页的地址链接到我原个人网站上，算是间接完成吧。</p><p>同时这过程中遇到一些问题，列出来纪念一下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Error: Host key verification failed.</span><br><span class="line">fatal: Could not read from remote repository.</span><br><span class="line">Please make sure you have the correct access rights and the repository exists.</span><br></pre></td></tr></table></figure></p><p>需设置SSH密匙来进行。且注意需删除之前生成的 git 那个文件夹。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在网上查找资料的时候偶然看到有人提到用Hexo来写博客，界面非常简洁，而且支持 markdown 解析，瞬间打算在我&lt;a href=&quot;http://tracyxinwang.site/&quot;&gt;个人的学术网站&lt;/a&gt;上加入这个blog页面。之前写博客都是在现成的博客网站上写的，比
      
    
    </summary>
    
    
      <category term="杂文" scheme="http://tracyxinwang.site/blog/tags/%E6%9D%82%E6%96%87/"/>
    
      <category term="碎碎念" scheme="http://tracyxinwang.site/blog/tags/%E7%A2%8E%E7%A2%8E%E5%BF%B5/"/>
    
      <category term="Hexo" scheme="http://tracyxinwang.site/blog/tags/Hexo/"/>
    
  </entry>
  
  <entry>
    <title>Markdown Template</title>
    <link href="http://tracyxinwang.site/blog/2018/09/24/hello-world/"/>
    <id>http://tracyxinwang.site/blog/2018/09/24/hello-world/</id>
    <published>2018-09-24T11:37:10.728Z</published>
    <updated>2018-09-27T02:24:32.588Z</updated>
    
    <content type="html"><![CDATA[<p>This is just a markdown template for me to take a reference when I write blogs.</p><h2 id="About-lists"><a href="#About-lists" class="headerlink" title="About lists"></a>About lists</h2><h3 id="Unordered-lists"><a href="#Unordered-lists" class="headerlink" title="Unordered lists"></a>Unordered lists</h3><ul><li>list 1<ul><li>list 1.1</li><li>list 1.2</li><li>list 1.3</li></ul></li><li>list 2</li><li>list 3</li></ul><h3 id="Ordered-lists"><a href="#Ordered-lists" class="headerlink" title="Ordered lists"></a>Ordered lists</h3><ol><li>list 1<ol><li>list 1.1</li><li>list 1.2</li></ol></li><li>list 2</li><li>list 3</li></ol><h2 id="About-citation"><a href="#About-citation" class="headerlink" title="About citation"></a>About citation</h2><blockquote><p>This is a citation from others</p></blockquote><h2 id="About-font-formatting"><a href="#About-font-formatting" class="headerlink" title="About font formatting"></a>About font formatting</h2><h3 id="This-is-a-italic-sentence"><a href="#This-is-a-italic-sentence" class="headerlink" title="This is a italic sentence."></a>This is a <em>italic</em> sentence.</h3><h3 id="This-is-a-bold-sentence"><a href="#This-is-a-bold-sentence" class="headerlink" title="This is a bold sentence."></a>This is a <strong>bold</strong> sentence.</h3><p>And be careful that there is no space between the text and the symbol.</p><h2 id="Links-and-figures"><a href="#Links-and-figures" class="headerlink" title="Links and figures"></a>Links and figures</h2><h3 id="Here-is-a-link-link"><a href="#Here-is-a-link-link" class="headerlink" title="Here is a link: link"></a>Here is a link: <a href="https://hexo.io" target="_blank" rel="noopener">link</a></h3><h3 id="Here-is-a-figure"><a href="#Here-is-a-figure" class="headerlink" title="Here is a figure: "></a>Here is a figure: <img src="https://hexo.io" alt="figure link"></h3><p>The following is a dividing line</p><hr><h2 id="Insert-a-table"><a href="#Insert-a-table" class="headerlink" title="Insert a table"></a>Insert a table</h2><table><thead><tr><th>header 1</th><th>header 2</th></tr></thead><tbody><tr><td>(1,1)</td><td>(1,2)</td></tr><tr><td>(2,1)</td><td>(2,2)</td></tr></tbody></table><h2 id="Insert-a-to-do-list"><a href="#Insert-a-to-do-list" class="headerlink" title="Insert a to-do list"></a>Insert a to-do list</h2><ul><li style="list-style: none"><input type="checkbox"> To do 1<ul><li style="list-style: none"><input type="checkbox"> To do 1.1</li><li style="list-style: none"><input type="checkbox"> To do 1.2</li></ul></li><li style="list-style: none"><input type="checkbox"> To do 2</li><li style="list-style: none"><input type="checkbox" checked> Finished 1</li><li style="list-style: none"><input type="checkbox" checked> Finshed 2</li></ul><p>Be careful that the clicked one should be small x inside.</p><h2 id="Add-code"><a href="#Add-code" class="headerlink" title="Add code"></a>Add code</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><h2 id="Add-math"><a href="#Add-math" class="headerlink" title="Add math"></a>Add math</h2><p>$$x+y=z$$</p><p>$x+y=z$</p><p>You need to turn the mathjax as “true” to make sure that it works.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;This is just a markdown template for me to take a reference when I write blogs.&lt;/p&gt;
&lt;h2 id=&quot;About-lists&quot;&gt;&lt;a href=&quot;#About-lists&quot; class=&quot;he
      
    
    </summary>
    
    
  </entry>
  
</feed>
